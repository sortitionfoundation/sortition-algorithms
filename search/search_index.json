{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sortition Algorithms Documentation","text":"<p>Welcome to the documentation for sortition-algorithms - a Python library for democratic lotteries and stratified random selection.</p>"},{"location":"#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling, sortition uses stratified random selection to ensure demographic balance while maintaining the randomness essential for fairness.</p> <p>This library provides algorithms for:</p> <ul> <li>Citizens' Assemblies: Representative groups for policy deliberation</li> <li>Deliberative Polls: Research panels reflecting population diversity</li> <li>Jury Selection: Fair selection respecting demographic quotas</li> <li>Participatory Democracy: Community engagement with guaranteed representation</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install the library\npip install sortition-algorithms\n\n# Basic selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"#documentation-guide","title":"Documentation Guide","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Quick Start Guide - Get up and running in minutes with practical examples</li> <li>Core Concepts - Understand sortition, features, quotas, and address checking</li> <li>Installation &amp; Setup - Install the library and optional dependencies</li> </ul>"},{"location":"#using-the-library","title":"Using the Library","text":"<ul> <li>CLI Usage - Command line interface for common operations</li> <li>Data Adapters - Working with CSV, Google Sheets, and custom data sources</li> <li>API Reference - Extended documentation of key functions and classes</li> <li>Modules - Complete documentation of all functions and classes</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Advanced Usage - Performance optimization, complex scenarios, and troubleshooting</li> <li>Algorithm Deep Dive - Understanding maximin, nash, and leximin algorithms</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#stratified-selection","title":"\ud83c\udfaf Stratified Selection","text":"<p>Ensures demographic representativeness while maintaining randomness - no more accidentally all-male or all-young panels.</p>"},{"location":"#household-diversity","title":"\ud83c\udfe0 Household Diversity","text":"<p>Optional address checking prevents multiple selections from the same household, ensuring geographic and social diversity.</p>"},{"location":"#multiple-algorithms","title":"\u2696\ufe0f Multiple Algorithms","text":"<p>Choose from maximin (default), nash, leximin, or legacy algorithms based on your fairness requirements.</p>"},{"location":"#flexible-data-sources","title":"\ud83d\udcca Flexible Data Sources","text":"<p>Works seamlessly with CSV files, Google Sheets, or custom data adapters for databases and APIs.</p>"},{"location":"#full-transparency","title":"\ud83d\udd0d Full Transparency","text":"<p>Detailed reporting shows exactly how quotas were met and provides audit trails for democratic accountability.</p>"},{"location":"#common-use-cases","title":"Common Use Cases","text":""},{"location":"#academic-research","title":"Academic Research","text":"<pre><code>from sortition_algorithms import run_stratification, Settings\n\n# Reproducible results for research\nsettings = Settings(\n    random_number_seed=42,\n    selection_algorithm=\"leximin\"  # Strongest fairness guarantees\n)\nsuccess, panels, msgs = run_stratification(features, people, 150, settings)\n</code></pre>"},{"location":"#citizen-assemblies","title":"Citizen Assemblies","text":"<pre><code># Ensure household diversity for community representation\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"],\n    selection_algorithm=\"maximin\"\n)\n</code></pre>"},{"location":"#large-scale-surveys","title":"Large-Scale Surveys","text":"<pre><code># Batch processing with CLI\npython -m sortition_algorithms csv \\\n  --features-csv national_demographics.csv \\\n  --people-csv voter_registry.csv \\\n  --number-wanted 2000 \\\n  --settings survey_config.toml\n</code></pre>"},{"location":"#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Best For Strengths Requirements Maximin General use, citizen assemblies Fair to minorities, intuitive None Nash Large diverse pools Balanced overall representation None Leximin Academic research Strongest fairness guarantees Gurobi license Legacy Historical compatibility Backwards compatible None <p>Read more about the algorithms.</p>"},{"location":"#real-world-applications","title":"Real-World Applications","text":""},{"location":"#government-democracy","title":"Government &amp; Democracy","text":"<ul> <li>Ireland's Citizens' Assembly: Used sortition for constitutional reform discussions</li> <li>French Citizens' Convention: 150 citizens selected to address climate change</li> <li>UK Citizens' Assemblies: Local and national policy deliberation</li> </ul>"},{"location":"#research-academia","title":"Research &amp; Academia","text":"<ul> <li>Deliberative Polling: Stanford's Center for Deliberative Democracy</li> <li>Policy Research: Representative samples for social science studies</li> <li>Market Research: Demographically balanced focus groups</li> </ul>"},{"location":"#community-engagement","title":"Community Engagement","text":"<ul> <li>Participatory Budgeting: Community members deciding local spending</li> <li>Planning Consultations: Representative input on development projects</li> <li>Local Government: Advisory panels for municipal decisions</li> </ul>"},{"location":"#support-community","title":"Support &amp; Community","text":""},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Troubleshooting Guide - Solutions to common problems</li> <li>GitHub Issues - Report bugs or request features</li> <li>Discussion Forum - Community support and questions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Contributing Guide - How to contribute to the project</li> <li>Development Setup - Set up your development environment</li> </ul>"},{"location":"#research-citations","title":"Research &amp; Citations","text":"<ul> <li>Core Paper - Academic foundation for the algorithms</li> <li>Related Research - Additional academic resources</li> </ul>"},{"location":"#license-usage","title":"License &amp; Usage","text":"<p>This library is open source under the GPL License. You're free to use it for:</p> <ul> <li>\u2705 Academic research and education</li> <li>\u2705 Government and civic applications</li> <li>\u2705 Commercial projects and consulting</li> <li>\u2705 Community organizing and activism</li> </ul> <p>Note: The leximin algorithm requires Gurobi, which has commercial licensing requirements. All other algorithms use open-source solvers.</p>"},{"location":"adapters/","title":"Data Adapters","text":"<p>Data adapters handle loading demographic data and candidate pools from various sources, and exporting selection results back to those sources. The library includes adapters for CSV files and Google Sheets, and you can write custom adapters for other data sources.</p>"},{"location":"adapters/#built-in-data-sources","title":"Built-in Data Sources","text":""},{"location":"adapters/#csvfiledatasource","title":"CSVFileDataSource","text":"<p>The most commonly used adapter for working with local CSV files.</p>"},{"location":"adapters/#basic-usage","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import CSVFileDataSource, SelectionData, Settings\nfrom pathlib import Path\n\ndata_source = CSVFileDataSource(\n    Path(\"demographics.csv\"),\n    Path(\"candidates.csv\"),\n    Path(\"selected.csv\"),\n    Path(\"remaining.csv\"),\n)\nselect_data = SelectionData(data_source)\n\n# Load data\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(Settings(), features)\n\n# Do Selection\n# ...\n\n# Export results (after running selection)\ndata_source.output_selected_remaining(selected_rows, remaining_rows)\n</code></pre>"},{"location":"adapters/#working-with-string-data","title":"Working with String Data","text":"<p>For data already in memory:</p> <pre><code># Load from string content\nfeatures_csv = \"\"\"feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\"\"\"\n\npeople_csv = \"\"\"id,Name,Gender\np001,Alice,Female\np002,Bob,Male\"\"\"\n\ndata_source = CSVStringDataSource(features_csv, people_csv)\nselect_data = SelectionData(data_source)\n\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(Settings(), features)\n</code></pre>"},{"location":"adapters/#full-csv-workflow-example","title":"Full CSV Workflow Example","text":"<pre><code>from sortition_algorithms import CSVFileDataSource, run_stratification, selected_remaining_tables, SelectionData, Settings\nfrom pathlib import Path\nimport csv\n\ndef csv_selection_workflow():\n    # Initialize\n    data_source = CSVFileDataSource(\n        Path(\"demographics.csv\"),\n        Path(\"candidates.csv\"),\n        Path(\"selected.csv\"),\n        Path(\"remaining.csv\"),\n    )\n    select_data = SelectionData(data_source)\n    settings = Settings()\n\n    # Load data\n    features, report = select_data.load_features()\n    print(report.as_text())\n    people, report = select_data.load_people(Settings(), features)\n    print(report.as_text())\n\n    # Run selection\n    success, panels, msgs = run_stratification(features, people, 100, settings)\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings\n        )\n\n        # Export results\n        data_source.output_selected_remaining(selected_rows, remaining_rows)\n        print(f\"Selected {len(panels[0])} people successfully\")\n    else:\n        print(\"Selection failed\")\n        print(\"\\n\".join(msgs))\n</code></pre>"},{"location":"adapters/#gsheetdatasource","title":"GSheetDataSource","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"adapters/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials and download JSON key</li> <li>Share Spreadsheet: Share your spreadsheet with the service account email address</li> </ol>"},{"location":"adapters/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import GSheetDataSource, SelectionData, Settings\nfrom pathlib import Path\n\n# Initialize with credentials\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"/secure/path/credentials.json\"),\n    gen_rem_tab=True,  # Generate remaining tab\n)\ndata_source.set_g_sheet_name(\"My Spreadsheet\")\nselect_data = SelectionData(data_source)\n\n# Load data from Google Sheet\nfeatures, report = select_data.load_features()\nprint(report.as_text())\n\npeople, report = select_data.load_people(settings, features)\nprint(report.as_text())\n\n# Configure output tabs\ndata_source.selected_tab_name_stub = \"Selected Panel\"\ndata_source.remaining_tab_name_stub = \"Reserve Pool\"\n\n# Export results (after running selection)\nselect_data.output_selected_remaining(selected_rows, remaining_rows, settings)\n</code></pre>"},{"location":"adapters/#full-google-sheets-workflow","title":"Full Google Sheets Workflow","text":"<pre><code>from sortition_algorithms import GSheetAdapter, run_stratification, selected_remaining_tables, Settings\nfrom pathlib import Path\n\ndef gsheet_selection_workflow():\n    # Initialize\n    adapter = GSheetAdapter(\n        auth_json_path=Path(\"credentials.json\"),\n        gen_rem_tab=True,\n    )\n    settings = Settings()\n\n    # Load data\n    adapter.set_g_sheet_name(\"Citizen Panel 2024\")\n    features, report = adapter.load_features(\"Demographics\")\n    if features is None:\n        print(\"Failed to load features:\", \"\\n\".join(msgs))\n        return\n\n    people, report = adapter.load_people(\"Candidates\", settings, features)\n    if people is None:\n        print(\"Failed to load people:\", \"\\n\".join(msgs))\n        return\n\n    # Run selection\n    success, panels, report = run_stratification(features, people, 120, settings)\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings\n        )\n\n        # Configure output\n        adapter.selected_tab_name = \"Selected Panel\"\n        adapter.remaining_tab_name = \"Reserve Pool\"\n\n        # Export to Google Sheets\n        dupes, _ = adapter.output_selected_remaining(selected_table, remaining_table, settings)\n\n        print(f\"Selected {len(panels[0])} people successfully\")\n        if dupes:\n            print(f\"Warning: {len(dupes)} people in remaining pool share addresses\")\n    else:\n        print(\"Selection failed:\", report.as_text())\n</code></pre>"},{"location":"adapters/#google-sheets-data-format","title":"Google Sheets Data Format","text":"<p>Your spreadsheet should be structured as follows:</p> <p>Demographics Tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Note that you can have other columns on the tab - the features import code will ignore them.</p> <p>Candidates Tab:</p> id Name Email Gender Age Location Address Postcode p001 Alice Smith alice@email.com Female 18-30 Urban 123 Main St 12345 p002 Bob Jones bob@email.com Male 31-50 Rural 456 Oak Ave 67890"},{"location":"adapters/#writing-custom-data-source-classes","title":"Writing custom Data Source classes","text":"<p>You can create custom data source classes for other data sources like Excel files, SQL databases, or APIs.</p>"},{"location":"adapters/#abstractdatasource","title":"AbstractDataSource","text":"<p>All data source classes should inherit from <code>AbstractDataSource</code> - and implement the methods it defines:</p> <pre><code>from sortition_algorithms import RunReport\n\nclass AbstractDataSource(abc.ABC):\n    @abc.abstractmethod\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]: ...\n\n    @abc.abstractmethod\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]: ...\n\n    @abc.abstractmethod\n    def write_selected(self, selected: list[list[str]]) -&gt; None: ...\n\n    @abc.abstractmethod\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None: ...\n\n    @abc.abstractmethod\n    def highlight_dupes(self, dupes: list[int]) -&gt; None: ...\n</code></pre>"},{"location":"adapters/#example-excel-data-source","title":"Example: Excel Data Source","text":"<p>Here's a complete example of an Excel adapter using the <code>openpyxl</code> library:</p> <pre><code>from pathlib import Path\nfrom typing import Any\nimport openpyxl\nfrom openpyxl.worksheet.worksheet import Worksheet\n\nfrom sortition_algorithms import AbstractDataSource, FeatureCollection, People, RunReport, SelectionError, Settings\nfrom sortition_algorithms.features import read_in_features\nfrom sortition_algorithms.people import read_in_people\n\nclass ExcelDataSource(AbstractDataSource):\n    \"\"\"DataSource for Excel files using openpyxl.\"\"\"\n\n    def __init__(self, excel_file: Path, feature_tab_name: str, people_tab_name: str) -&gt; None:\n        self.excel_file = excel_file\n        self.feature_tab_name = feature_tab_name\n        self.people_tab_name = people_tab_name\n        self.selected_tab_name = \"selected\"\n        self.remaining_tab_name = \"remaining\"\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        \"\"\"Load features data from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(self.excel_file)\n\n        if self.feature_tab_name not in workbook.sheetnames:\n            msg = f\"Sheet '{self.feature_tab_name}' not found in {excel_file}\"\n            report.add_line(msg)\n            raise SelectionError(msg, report)\n\n        sheet = workbook[self.feature_tab_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n        yield headers, data\n        # close the workbook\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        \"\"\"Load people from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(excel_file)\n\n        if self.people_tab_name not in workbook.sheetnames:\n            msg = f\"Sheet '{self.people_tab_name}' not found in {excel_file}\"\n            report.add_line(msg)\n            raise SelectionError(msg, report)\n\n        sheet = workbook[self.people_tab_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n\n        yield headers, data\n\n    def write_selected(self, selected: list[list[str]]) -&gt; None:\n        selected_ws = workbook.create_sheet(self.selected_tab_name)\n        self._write_data_to_sheet(selected_ws, selected_rows)\n        workbook.save(self.excel_file)\n\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None:\n        remaining_ws = workbook.create_sheet(self.remaining_tab_name)\n        self._write_data_to_sheet(remaining_ws, remaining_rows)\n        workbook.save(self.excel_file)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        # not implemented\n        pass\n\n    def _write_data_to_sheet(self, sheet: Worksheet, data: list[list[str]]) -&gt; None:\n        \"\"\"Write data rows to worksheet.\"\"\"\n        for row_idx, row_data in enumerate(data, 1):\n            for col_idx, cell_value in enumerate(row_data, 1):\n                sheet.cell(row=row_idx, column=col_idx, value=cell_value)\n\n        # Style header row\n        if data:\n            for cell in sheet[1]:\n                cell.font = openpyxl.styles.Font(bold=True)\n                cell.fill = openpyxl.styles.PatternFill(\"solid\", fgColor=\"CCCCCC\")\n\n# Usage example\ndef excel_workflow():\n    data_source = ExcelDataSource(\n        Path(\"selection_data.xlsx\"),\n        \"Demographics\",\n        \"Candidates\",\n    )\n    select_data = SelectionData(data_source)\n    settings = Settings()\n\n    # Load data\n    features, _ = select_data.load_features()\n    people, report = select_data.load_people(settings, features)\n\n    # Run selection (assuming you have the selection logic)\n    success, panels, report = run_stratification(...)\n\n    # Export results\n    select_data.output_selected_remaining(selected_table, remaining_table, settings)\n</code></pre>"},{"location":"adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Command line interface</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"advanced/","title":"Advanced Usage","text":"<p>This guide covers complex scenarios, optimization techniques, troubleshooting strategies, and advanced usage patterns for the sortition algorithms library.</p>"},{"location":"advanced/#algorithm-deep-dive","title":"Algorithm Deep Dive","text":"<p>Read more about the algorithms.</p>"},{"location":"advanced/#complex-scenarios","title":"Complex Scenarios","text":""},{"location":"advanced/#weighted-selection","title":"Weighted Selection","text":"<p>For scenarios where some demographic groups need stronger representation:</p> <pre><code>def create_weighted_features():\n    \"\"\"Create features with weighted quotas for underrepresented groups.\"\"\"\n\n    # Standard proportional representation\n    base_features = [\n        (\"Gender\", \"Male\", 45, 55),\n        (\"Gender\", \"Female\", 45, 55),\n        (\"Age\", \"18-30\", 20, 30),\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 25, 35),\n    ]\n\n    # Weighted to ensure representation of underrepresented groups\n    weighted_features = [\n        (\"Gender\", \"Male\", 40, 50),       # Slightly reduce majority\n        (\"Gender\", \"Female\", 45, 55),     # Maintain strong representation\n        (\"Gender\", \"Non-binary\", 5, 10),  # Ensure inclusion\n        (\"Age\", \"18-30\", 25, 35),         # Boost young representation\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 20, 30),\n    ]\n\n    return create_features_from_list(weighted_features)\n\ndef create_features_from_list(feature_list):\n    \"\"\"Helper to create FeatureCollection from tuples.\"\"\"\n    import csv\n    from io import StringIO\n\n    # Convert to CSV format\n    csv_content = \"feature,value,min,max\\n\"\n    for feature, value, min_val, max_val in feature_list:\n        csv_content += f\"{feature},{value},{min_val},{max_val}\\n\"\n\n    # Use CSV adapter to create FeatureCollection\n    data_source = CSVStringDataSource(csv_content, \"\")\n    select_data = SelectionData(data_source)\n    features, msgs = data_source.load_features()\n    return features\n</code></pre>"},{"location":"advanced/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"advanced/#common-error-patterns","title":"Common Error Patterns","text":""},{"location":"advanced/#infeasible-quotas","title":"Infeasible Quotas","text":"<p>Symptoms: <code>InfeasibleQuotasError</code> exception</p> <p>Diagnosis:</p> <pre><code>def diagnose_quota_feasibility(features: FeatureCollection, panel_size: int):\n    \"\"\"Analyze why quotas might be infeasible.\"\"\"\n\n    issues = []\n\n    max_value_of_minimums = minimum_selection(features)\n    if max_value_of_minimums &gt; panel_size:\n        issues.append(f\"Max value of minimums ({max_value_of_minimums}) exceeds panel size ({panel_size})\")\n\n    min_value_of_maximums = maximum_selection(features)\n    if min_value_of_maximums &lt; panel_size:\n        issues.append(f\"Min value of maximums ({min_value_of_maximums}) is less than panel size ({panel_size})\")\n\n    # Check for impossible individual quotas\n    for feature_name in features:\n        sum_of_min = sum(c.min for c in features[feature_name].values())\n        sum_of_max = sum(c.max for c in features[feature_name].values())\n\n        if sum_of_min &gt; panel_size:\n            issues.append(f\"{feature_name} sum of minimum ({sum_of_min}) exceeds panel size\")\n\n        if sum_of_max &lt; panel_size:\n            issues.append(f\"{feature_name} sum of maximum ({sum_of_max}) is less than panel size\")\n\n    for feature_name, value_name, fv_minmax in iterate_feature_collection(features):\n        if fv_minmax.max &lt; fv_minmax.min:\n            issues.append(f\"{feature_name}:{value_name} max ({fv_minmax.max}) &lt; min ({fv_minmax.min})\")\n\n    return issues\n\ndef suggest_quota_fixes(features: FeatureCollection, people: People, panel_size: int):\n    \"\"\"Suggest quota adjustments to make selection feasible.\"\"\"\n\n    suggestions = []\n\n    # Count available people per category\n    availability = {}\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n        for feature_name in features:\n            value = person_data.get(feature_name, \"Unknown\")\n            key = (feature_name, value)\n            availability[key] = availability.get(key, 0) + 1\n\n    # Suggest adjustments\n    for feature_name, value_name, fv_minmax in iterate_feature_collection(features):\n        available = availability.get((feature_name, value_name), 0)\n\n        if fv_minmax.min &gt; available:\n            suggestions.append(\n                f\"Reduce {feature_name}:{value_name} minimum from {fv_minmax.min} to {available} \"\n                f\"(only {available} candidates available)\"\n            )\n\n    return suggestions\n</code></pre> <p>Solutions:</p> <ol> <li>Reduce minimum quotas: Lower the minimum requirements</li> <li>Increase maximum quotas: Allow more flexibility</li> <li>Expand candidate pool: Recruit more candidates in underrepresented categories</li> <li>Adjust panel size: Sometimes a smaller or larger panel works better</li> </ol>"},{"location":"advanced/#data-quality-issues","title":"Data Quality Issues","text":"<p>Symptoms: Unexpected selection results, warnings about data inconsistencies</p> <p>Diagnosis:</p> <pre><code>from collection import Counter, defaultdict\n\ndef audit_data_quality(people: People, features: FeatureCollection):\n    \"\"\"Comprehensive data quality audit.\"\"\"\n\n    issues = []\n\n    # Check for missing demographic data\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature in features:\n            if feature not in person_data or not person_data[feature].strip():\n                issues.append(f\"Person {person_id} missing {feature}\")\n\n    # Check for unexpected feature values\n    expected_values = {name: set(features[name].keys()]) for name in features}\n\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature_name, values in expected_values.items():\n            actual_val = person_data.get(feature_name, \"\")\n            if actual_val and actual_val not in values:\n                issues.append(\n                    f\"Person {person_id} has unexpected {feature_name} value: '{actual_val}'\"\n                )\n\n    # Check for duplicate IDs\n    count_ids = Counter(people)\n    for person_id, count in count_ids.items():\n        if count &gt; 1:\n            issues.append(f\"Duplicate person ID: {person_id}\")\n\n    return issues\n\ndef clean_data_automatically(people_data: list[dict], features: FeatureCollection):\n    \"\"\"Automatically clean common data issues.\"\"\"\n\n    cleaned_data = []\n\n    for person in people_data:\n        cleaned_person = {}\n\n        for key, value in person.items():\n            # Strip whitespace\n            if isinstance(value, str):\n                value = value.strip()\n\n            # Standardize case for categorical variables\n            if key in features:\n                # Convert to title case for consistency\n                value = value.title() if value else \"\"\n\n            cleaned_person[key] = value\n\n        # Skip records with missing required data\n        required_fields = [\"id\"] + list(features.keys())\n        if all(cleaned_person.get(field) for field in required_fields):\n            cleaned_data.append(cleaned_person)\n\n    return cleaned_data\n</code></pre>"},{"location":"advanced/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"advanced/#development-best-practices","title":"Development Best Practices","text":"<ol> <li>Always validate inputs: Check data quality before running selections</li> <li>Use appropriate random seeds: Fixed seeds for testing, None for production</li> <li>Handle errors gracefully: Provide meaningful error messages and recovery options</li> <li>Test with edge cases: Small pools, extreme quotas, missing data</li> <li>Monitor performance: Track memory usage and runtime for large datasets</li> </ol>"},{"location":"advanced/#production-best-practices","title":"Production Best Practices","text":"<ol> <li>Implement comprehensive logging: Track all selection attempts and results</li> <li>Set up monitoring and alerting: Detect failures and performance issues</li> <li>Use version control for configurations: Track changes to quotas and settings</li> <li>Backup candidate data: Ensure data persistence and recoverability</li> <li>Document selection criteria: Maintain audit trails for transparency</li> </ol>"},{"location":"advanced/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>API Reference - Complete function documentation</li> <li>Data Adapters - Working with different data sources</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete documentation for all public functions and classes in the sortition-algorithms library.</p>"},{"location":"api-reference/#core-functions","title":"Core Functions","text":""},{"location":"api-reference/#run_stratification","title":"run_stratification()","text":"<p>Main function for running stratified random selection with retry logic.</p> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[bool, list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features</code>: FeatureCollection with min/max quotas for each feature value</li> <li><code>people</code>: People object containing the pool of candidates</li> <li><code>number_people_wanted</code>: Desired size of the panel</li> <li><code>settings</code>: Settings object containing configuration</li> <li><code>test_selection</code>: If True, don't randomize (for testing only)</li> <li><code>number_selections</code>: Number of panels to return (usually 1)</li> </ul> <p>Returns:</p> <ul> <li><code>success</code>: Whether selection succeeded within max attempts</li> <li><code>selected_committees</code>: List of committees (frozensets of person IDs)</li> <li><code>output_lines</code>: Debug and status messages</li> </ul> <p>Raises:</p> <ul> <li><code>InfeasibleQuotasError</code>: If quotas cannot be satisfied</li> <li><code>SelectionError</code>: For various failure cases</li> <li><code>ValueError</code>: For invalid parameters</li> <li><code>RuntimeError</code>: If required solver is not available</li> </ul> <p>Example:</p> <pre><code>success, panels, messages = run_stratification(\n    features, people, 100, Settings()\n)\nif success:\n    selected_people = panels[0]  # frozenset of IDs\n</code></pre>"},{"location":"api-reference/#find_random_sample","title":"find_random_sample()","text":"<p>Lower-level algorithm function for finding random committees.</p> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>selection_algorithm</code>: One of \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li>Other parameters same as <code>run_stratification()</code></li> </ul> <p>Returns:</p> <ul> <li><code>committee_lottery</code>: List of committees (may contain duplicates)</li> <li><code>output_lines</code>: Debug strings</li> </ul> <p>Example:</p> <pre><code>committees, messages = find_random_sample(\n    features, people, 50, settings, \"nash\"\n)\n</code></pre>"},{"location":"api-reference/#selected_remaining_tables","title":"selected_remaining_tables()","text":"<p>Format selection results for export to CSV or other formats.</p> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>full_people</code>: Original People object</li> <li><code>people_selected</code>: Single frozenset of selected person IDs</li> <li><code>features</code>: FeatureCollection used for selection</li> <li><code>settings</code>: Settings object</li> </ul> <p>Returns:</p> <ul> <li><code>selected_rows</code>: Table with selected people data</li> <li><code>remaining_rows</code>: Table with remaining people data</li> <li><code>output_lines</code>: Additional information messages</li> </ul> <p>Example:</p> <pre><code>selected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panel, features, settings\n)\n\n# Write to CSV\nimport csv\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    csv.writer(f).writerows(selected_table)\n</code></pre>"},{"location":"api-reference/#data-loading-functions","title":"Data Loading Functions","text":""},{"location":"api-reference/#read_in_features","title":"read_in_features()","text":"<p>Load feature definitions from a CSV file.</p> <pre><code>def read_in_features(features_file: str | Path) -&gt; FeatureCollection:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_file</code>: Path to CSV file with feature definitions</li> </ul> <p>Expected CSV format:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\n</code></pre> <p>Returns:</p> <ul> <li><code>FeatureCollection</code>: Nested dict containing all features and quotas</li> </ul> <p>Example:</p> <pre><code>features = read_in_features(\"demographics.csv\")\n</code></pre>"},{"location":"api-reference/#read_in_people","title":"read_in_people()","text":"<p>Load candidate pool from a CSV file.</p> <pre><code>def read_in_people(\n    people_file: str | Path,\n    settings: Settings,\n    features: FeatureCollection\n) -&gt; People:\n</code></pre> <p>Parameters:</p> <ul> <li><code>people_file</code>: Path to CSV file with candidate data</li> <li><code>settings</code>: Settings object for configuration</li> <li><code>features</code>: FeatureCollection for validation</li> </ul> <p>Expected CSV format:</p> <pre><code>id,Name,Gender,Age,Email\np001,Alice,Female,18-30,alice@example.com\np002,Bob,Male,31-50,bob@example.com\n</code></pre> <p>Returns:</p> <ul> <li><code>People</code>: Object containing candidate pool</li> </ul> <p>Example:</p> <pre><code>people = read_in_people(\"candidates.csv\", settings, features)\n</code></pre>"},{"location":"api-reference/#settings-class","title":"Settings Class","text":"<p>Configuration object for customizing selection behavior.</p> <pre><code>class Settings:\n    def __init__(\n        self,\n        random_number_seed: int | None = None,\n        check_same_address: bool = False,\n        check_same_address_columns: list[str] | None = None,\n        selection_algorithm: str = \"maximin\",\n        max_attempts: int = 10,\n        columns_to_keep: list[str] | None = None,\n        id_column: str = \"id\",\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>random_number_seed</code>: Fixed seed for reproducible results (None or 0 = random)</li> <li><code>check_same_address</code>: Enable household diversity checking</li> <li><code>check_same_address_columns</code>: Columns that define an address</li> <li><code>selection_algorithm</code>: \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li><code>max_attempts</code>: Maximum selection retry attempts</li> <li><code>columns_to_keep</code>: Additional columns to include in output</li> <li><code>id_column</code>: Name of the ID column in people data</li> </ul> <p>Class Methods:</p>"},{"location":"api-reference/#settingsload_from_file","title":"Settings.load_from_file()","text":"<pre><code>@classmethod\ndef load_from_file(\n    cls,\n    settings_file_path: Path\n) -&gt; tuple[Settings, RunReport]:\n</code></pre> <p>Load settings from a TOML file.</p> <p>Example settings.toml:</p> <pre><code>id_column = \"my_id\"\nrandom_number_seed = 0\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\nselection_algorithm = \"maximin\"\nmax_attempts = 10\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <p>Returns:</p> <ul> <li><code>Settings</code>: Configured settings object</li> <li><code>str</code>: Status message</li> </ul> <p>Example:</p> <pre><code>settings, report = Settings.load_from_file(Path(\"config.toml\"))\nprint(report.as_text())  # \"Settings loaded from config.toml\"\n</code></pre>"},{"location":"api-reference/#runreport-class","title":"RunReport Class","text":"<p>The <code>RunReport</code> class provides structured reporting for sortition operations. Most library functions return a <code>RunReport</code> alongside their main results, containing status messages, warnings, and formatted output.</p> <pre><code>class RunReport:\n    def as_text(self, include_logged: bool = True) -&gt; str\n    def as_html(self, include_logged: bool = True) -&gt; str\n</code></pre>"},{"location":"api-reference/#output-methods","title":"Output Methods","text":""},{"location":"api-reference/#as_text","title":"as_text()","text":"<p>Returns the report as formatted plain text.</p> <p>Parameters:</p> <ul> <li><code>include_logged</code>: If <code>False</code>, excludes messages that were already sent to the logging system (useful when the user has already seen logged messages during execution)</li> </ul>"},{"location":"api-reference/#as_html","title":"as_html()","text":"<p>Returns the report as HTML with styling for different message importance levels (normal, important, critical).</p> <p>Parameters:</p> <ul> <li><code>include_logged</code>: Same as <code>as_text()</code></li> </ul>"},{"location":"api-reference/#usage-pattern","title":"Usage Pattern","text":"<p>Most library functions return a tuple containing results and a <code>RunReport</code>:</p> <pre><code># Loading data\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\nprint(report.as_text())\n\npeople, report = adapter.load_people_from_file(Path(\"people.csv\"), settings, features)\nprint(report.as_text())\n\n# Running selection\nsuccess, panels, report = run_stratification(features, people, 100, settings)\n\n# Display as text\nprint(report.as_text())\n\n# Or generate HTML for web display\nhtml_content = report.as_html()\n\n# Exclude already-logged messages if user saw them during execution\nsummary = report.as_text(include_logged=False)\n</code></pre>"},{"location":"api-reference/#logging-integration","title":"Logging Integration","text":"<p>Some report messages are also sent to the logging system in real-time. If your application displays log messages to users during execution, you can use <code>include_logged=False</code> to avoid showing duplicate messages in the final report.</p>"},{"location":"api-reference/#custom-logging","title":"Custom Logging","text":"<p>The library uses Python's standard logging system with two loggers:</p> <ul> <li><code>sortition_algorithms_user</code> - Messages intended for end users</li> <li><code>sortition_algorithms</code> - Debug messages for developers</li> </ul>"},{"location":"api-reference/#setting-up-custom-log-handlers","title":"Setting Up Custom Log Handlers","text":"<p>You can redirect logging output using <code>override_logging_handlers()</code>:</p> <pre><code>from sortition_algorithms.utils import override_logging_handlers\nimport logging\n\n# Create custom handlers\nuser_handler = logging.StreamHandler()\nuser_handler.setFormatter(logging.Formatter('USER: %(message)s'))\n\ndebug_handler = logging.FileHandler('debug.log')\ndebug_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n\n# Apply custom handlers\noverride_logging_handlers([user_handler], [debug_handler])\n</code></pre>"},{"location":"api-reference/#custom-loghandler-example","title":"Custom LogHandler Example","text":"<p>Here's a custom handler that captures messages for further processing:</p> <pre><code>import logging\nfrom typing import List\n\nclass MessageCollector(logging.Handler):\n    \"\"\"Custom handler that collects log messages in memory.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.messages: List[str] = []\n\n    def emit(self, record: logging.LogRecord) -&gt; None:\n        \"\"\"Called for each log message.\"\"\"\n        msg = self.format(record)\n        self.messages.append(msg)\n\n    def get_messages(self) -&gt; List[str]:\n        \"\"\"Return all collected messages.\"\"\"\n        return self.messages.copy()\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear collected messages.\"\"\"\n        self.messages.clear()\n\n# Usage\ncollector = MessageCollector()\noverride_logging_handlers([collector], [collector])\n\n# Run sortition operations\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\n\n# Get messages that were logged during execution\nlogged_messages = collector.get_messages()\nprint(\"Logged:\", logged_messages)\n\n# Get final report (excluding already-logged messages)\nfinal_report = report.as_text(include_logged=False)\nprint(\"Additional report:\", final_report)\n</code></pre>"},{"location":"api-reference/#available-logging-functions","title":"Available Logging Functions","text":"<pre><code>from sortition_algorithms.utils import override_logging_handlers, set_log_level\n\ndef override_logging_handlers(\n    user_logger_handlers: list[logging.Handler],\n    logger_handlers: list[logging.Handler]\n) -&gt; None\n\ndef set_log_level(log_level: int) -&gt; None\n</code></pre>"},{"location":"api-reference/#data-sources","title":"Data Sources","text":"<p>The library uses a data source pattern for loading and saving data. All data sources implement the <code>AbstractDataSource</code> interface and are used via the <code>SelectionData</code> wrapper class.</p>"},{"location":"api-reference/#selectiondata","title":"SelectionData","text":"<p>High-level wrapper class that provides a unified interface for loading data and outputting results, regardless of the underlying data source.</p> <pre><code>class SelectionData:\n    def __init__(\n        self,\n        data_source: AbstractDataSource,\n        gen_rem_tab: bool = True\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>data_source</code>: Any object implementing AbstractDataSource (e.g., CSVFileDataSource, GSheetDataSource)</li> <li><code>gen_rem_tab</code>: If True, generate a \"remaining\" output table; if False, only output selected</li> </ul> <p>Methods:</p> <pre><code>def load_features(self) -&gt; tuple[FeatureCollection, RunReport]:\n    # Load feature definitions from data source\n\ndef load_people(\n    self, settings: Settings, features: FeatureCollection\n) -&gt; tuple[People, RunReport]:\n    # Load people data from data source\n\ndef output_selected_remaining(\n    self,\n    people_selected_rows: list[list[str]],\n    people_remaining_rows: list[list[str]],\n    settings: Settings,\n) -&gt; list[int]:\n    # Write selected and remaining tables, returns list of duplicate indexes\n\ndef output_multi_selections(\n    self, multi_selections: list[list[str]]\n) -&gt; None:\n    # Write multiple selection panels (gen_rem_tab must be False)\n</code></pre> <p>Example - CSV Files:</p> <pre><code>from sortition_algorithms.adapters import CSVFileDataSource, SelectionData\nfrom pathlib import Path\n\n# Create data source for CSV files\ndata_source = CSVFileDataSource(\n    features_file=Path(\"features.csv\"),\n    people_file=Path(\"people.csv\"),\n    selected_file=Path(\"selected.csv\"),\n    remaining_file=Path(\"remaining.csv\")\n)\n\n# Wrap in SelectionData\nselection_data = SelectionData(data_source)\n\n# Load data\nfeatures, report = selection_data.load_features()\npeople, report = selection_data.load_people(settings, features)\n\n# Run stratification (using core.py functions)\nfrom sortition_algorithms.core import run_stratification, selected_remaining_tables\nsuccess, panels, report = run_stratification(features, people, 100, settings)\n\n# Format and output results\nselected_rows, remaining_rows, _ = selected_remaining_tables(\n    people, panels[0], features, settings\n)\ndupes, report = selection_data.output_selected_remaining(\n    selected_rows, remaining_rows, settings\n)\n</code></pre> <p>Example - Google Sheets:</p> <pre><code>from sortition_algorithms.adapters import GSheetDataSource, SelectionData\nfrom pathlib import Path\n\n# Create data source for Google Sheets\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"credentials.json\")\n)\ndata_source.set_g_sheet_name(\"My Sortition Spreadsheet\")\n\n# Wrap in SelectionData\nselection_data = SelectionData(data_source)\n\n# Load and process (same as CSV example above)\nfeatures, report = selection_data.load_features()\npeople, report = selection_data.load_people(settings, features)\n# ... run stratification and output results\n</code></pre>"},{"location":"api-reference/#csvstringdatasource","title":"CSVStringDataSource","text":"<p>Data source for working with CSV data provided as strings (useful for testing or web applications).</p> <pre><code>class CSVStringDataSource(AbstractDataSource):\n    def __init__(self, features_data: str, people_data: str):\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_data</code>: CSV content for features as a string</li> <li><code>people_data</code>: CSV content for people as a string</li> </ul> <p>Attributes:</p> <ul> <li><code>selected_file</code>: StringIO buffer containing selected output</li> <li><code>remaining_file</code>: StringIO buffer containing remaining output</li> <li><code>selected_file_written</code>: Boolean indicating if selected was written</li> <li><code>remaining_file_written</code>: Boolean indicating if remaining was written</li> </ul> <p>Example:</p> <pre><code>features_csv = \"\"\"feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\"\"\"\n\npeople_csv = \"\"\"id,name,Gender\np1,Alice,Female\np2,Bob,Male\"\"\"\n\ndata_source = CSVStringDataSource(features_csv, people_csv)\nselection_data = SelectionData(data_source)\n# ... use as normal, then access results from StringIO:\nselected_output = data_source.selected_file.getvalue()\n</code></pre>"},{"location":"api-reference/#csvfiledatasource","title":"CSVFileDataSource","text":"<p>Data source for reading from and writing to CSV files on disk.</p> <pre><code>class CSVFileDataSource(AbstractDataSource):\n    def __init__(\n        self,\n        features_file: Path,\n        people_file: Path,\n        selected_file: Path,\n        remaining_file: Path\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_file</code>: Path to input CSV file with feature definitions</li> <li><code>people_file</code>: Path to input CSV file with candidate data</li> <li><code>selected_file</code>: Path to output CSV file for selected people</li> <li><code>remaining_file</code>: Path to output CSV file for remaining people</li> </ul>"},{"location":"api-reference/#gsheetdatasource","title":"GSheetDataSource","text":"<p>Data source for reading from and writing to Google Sheets.</p> <pre><code>class GSheetDataSource(AbstractDataSource):\n    def __init__(\n        self,\n        feature_tab_name: str,\n        people_tab_name: str,\n        auth_json_path: Path\n    ):\n\n    def set_g_sheet_name(self, g_sheet_name: str) -&gt; None:\n</code></pre> <p>Parameters:</p> <ul> <li><code>feature_tab_name</code>: Name of the tab containing feature definitions</li> <li><code>people_tab_name</code>: Name of the tab containing candidate data</li> <li><code>auth_json_path</code>: Path to Google API service account credentials JSON</li> </ul> <p>Methods:</p> <ul> <li><code>set_g_sheet_name(g_sheet_name)</code>: Set the spreadsheet to work with (name or URL)</li> </ul> <p>Attributes:</p> <ul> <li><code>selected_tab_name</code>: Name of created tab with selected people (set after output)</li> <li><code>remaining_tab_name</code>: Name of created tab with remaining people (set after output)</li> </ul> <p>Notes:</p> <ul> <li>Automatically creates new output tabs with incrementing numbers to avoid overwriting</li> <li>Highlights duplicate addresses in orange in the remaining tab</li> <li>Requires Google Sheets API credentials (see Google Cloud Console)</li> </ul>"},{"location":"api-reference/#abstractdatasource","title":"AbstractDataSource","text":"<p>Abstract base class defining the interface that all data sources must implement.</p> <pre><code>class AbstractDataSource(abc.ABC):\n    @abc.abstractmethod\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        ...\n\n    @abc.abstractmethod\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        ...\n\n    @abc.abstractmethod\n    def write_selected(self, selected: list[list[str]]) -&gt; None:\n        ...\n\n    @abc.abstractmethod\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None:\n        ...\n\n    @abc.abstractmethod\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        ...\n</code></pre> <p>Implement this interface to create custom data sources (e.g., for databases, APIs, or other formats).</p>"},{"location":"api-reference/#core-data-classes","title":"Core Data Classes","text":""},{"location":"api-reference/#featurecollection","title":"FeatureCollection","text":"<p>Container for demographic features and their quotas. It is a nested dict of <code>FeatureValueMinMax</code> objects. The outer dict keys are the feature names, and the inner dict keys are the value names.</p> <p>Key Helper Functions:</p> <pre><code>def check_desired(fc: FeatureCollection, desired_number: int) -&gt; None:\n    # Validates that quotas are achievable for the desired panel size\n    # Raises exception if infeasible\n\ndef iterate_feature_collection(features: FeatureCollection) -&gt; Generator[tuple[str, str, FeatureValueMinMax]]:\n    # Iterate over all feature values and their count objects\n</code></pre>"},{"location":"api-reference/#people","title":"People","text":"<p>Container for the candidate pool.</p> <p>Key Methods:</p> <pre><code>def __len__(self) -&gt; int:\n    # Number of people in the pool\n\ndef __iter__(self) -&gt; Iterator[str]:\n    # Iterate over person IDs\n\ndef get_person_dict(self, person_id: str) -&gt; dict[str, str]:\n    # Get all data for a specific person\n\ndef matching_address(\n    self, person_id: str, address_columns: list[str]\n) -&gt; list[str]:\n    # Find people with matching address to given person\n\ndef remove(self, person_id: str) -&gt; None:\n    # Remove person from pool\n\ndef remove_many(self, person_ids: list[str]) -&gt; None:\n    # Remove multiple people from pool\n</code></pre>"},{"location":"api-reference/#error-classes","title":"Error Classes","text":""},{"location":"api-reference/#infeasiblequotaserror","title":"InfeasibleQuotasError","text":"<p>Raised when quotas cannot be satisfied with the available candidate pool.</p> <pre><code>class InfeasibleQuotasError(Exception):\n    def __init__(self, output: list[str])\n</code></pre> <p>Attributes:</p> <ul> <li><code>output</code>: List of diagnostic messages explaining the infeasibility</li> </ul>"},{"location":"api-reference/#selectionerror","title":"SelectionError","text":"<p>General error for selection process failures.</p> <pre><code>class SelectionError(Exception):\n    pass\n</code></pre>"},{"location":"api-reference/#utility-functions","title":"Utility Functions","text":""},{"location":"api-reference/#set_random_provider","title":"set_random_provider()","text":"<p>Configure the random number generator for reproducible results.</p> <pre><code>def set_random_provider(seed: int | None) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>seed</code>: Random seed (None for secure random)</li> </ul> <p>Example:</p> <pre><code>set_random_provider(42)  # Reproducible results\nset_random_provider(None)  # Secure random\n</code></pre>"},{"location":"api-reference/#generate_dupes","title":"generate_dupes()","text":"<p>Identify people who share an address in a table of remaining candidates.</p> <pre><code>def generate_dupes(\n    people_remaining_rows: list[list[str]],\n    settings: Settings\n) -&gt; list[int]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>people_remaining_rows</code>: Table of people data where first row is headers</li> <li><code>settings</code>: Settings object (uses <code>check_same_address</code> and <code>check_same_address_columns</code>)</li> </ul> <p>Returns:</p> <ul> <li>List of row indexes (1-indexed, accounting for header) of people who share an address with at least one other person</li> </ul> <p>Example:</p> <pre><code># Table with headers in row 0\npeople_table = [\n    [\"id\", \"name\", \"address_line_1\", \"postcode\"],\n    [\"1\", \"Alice\", \"33 Acacia Avenue\", \"W1A 1AA\"],\n    [\"2\", \"Bob\", \"31 Acacia Avenue\", \"W1A 1AA\"],\n    [\"3\", \"Charlotte\", \"33 Acacia Avenue\", \"W1A 1AA\"],\n    [\"4\", \"David\", \"33 Acacia Avenue\", \"W1B 1BB\"],\n]\n\nsettings = Settings(\n    id_column=\"id\",\n    columns_to_keep=[\"name\"],\n    check_same_address=True,\n    check_same_address_columns=[\"address_line_1\", \"postcode\"]\n)\n\ndupes = generate_dupes(people_table, settings)\n# Returns [1, 3] - Alice and Charlotte share the same address\n</code></pre> <p>Notes:</p> <ul> <li>Returns empty list if <code>check_same_address</code> is False</li> <li>Only considers exact matches on ALL specified address columns</li> <li>Row indexes account for the header being at index 0</li> </ul>"},{"location":"api-reference/#type-hints","title":"Type Hints","text":"<p>Common type aliases used throughout the API:</p> <pre><code># A committee is a set of person IDs\nCommittee = frozenset[str]\n\n# Selection results are lists of committees\nSelectionResult = list[Committee]\n\n# Tables are lists of rows (lists of strings)\nTable = list[list[str]]\n</code></pre>"},{"location":"cli/","title":"Command Line Interface","text":"<p>The CLI provides a convenient way to run sortition algorithms without writing Python code. It's ideal for:</p> <ul> <li>One-off selections: Quick panel selections for events or research</li> <li>Sample code: The code in the command line functions can be the basis for writing your own implementation.</li> <li>Batch processing: Running multiple selections with scripts</li> <li>Non-programmers: Teams who prefer command-line tools</li> <li>Integration: Incorporating sortition into existing workflows</li> </ul>"},{"location":"cli/#installation","title":"Installation","text":"<p>Install the CLI with optional dependencies:</p> <pre><code># Basic installation\npip install 'sortition-algorithms[cli]'\n\n# With Gurobi support for leximin algorithm\npip install 'sortition-algorithms[cli,gurobi]'\n</code></pre>"},{"location":"cli/#quick-start","title":"Quick Start","text":"<pre><code># Check installation\npython -m sortition_algorithms --help\n\n# Basic CSV selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#commands-overview","title":"Commands Overview","text":"<p>The CLI provides three main commands:</p> <pre><code>$ python -m sortition_algorithms --help\nUsage: python -m sortition_algorithms [OPTIONS] COMMAND [ARGS]...\n\n  A command line tool to exercise the sortition algorithms.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  csv         Do sortition with CSV files\n  gen-sample  Generate sample CSV file compatible with features\n  gsheet      Do sortition with Google Spreadsheets\n</code></pre>"},{"location":"cli/#csv-workflow","title":"CSV Workflow","text":"<p>The most common usage pattern for working with local CSV files.</p>"},{"location":"cli/#command-reference","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms csv --help\nUsage: python -m sortition_algorithms csv [OPTIONS]\n\n  Do sortition with CSV files.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  -f, --features-csv FILE         CSV with demographic features [required]\n  -p, --people-csv FILE           CSV with candidate pool [required]\n  -s, --selected-csv FILE         Output: selected people [required]\n  -r, --remaining-csv FILE        Output: remaining people [required]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-files","title":"Example Files","text":"<p>demographics.csv (feature definitions):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,35,45\nAge,51+,25,35\nLocation,Urban,40,60\nLocation,Rural,40,60\n</code></pre> <p>candidates.csv (candidate pool):</p> <pre><code>id,Name,Email,Gender,Age,Location,Address,Postcode\np001,Alice Smith,alice@email.com,Female,18-30,Urban,123 Main St,12345\np002,Bob Jones,bob@email.com,Male,31-50,Rural,456 Oak Ave,67890\np003,Carol Davis,carol@email.com,Female,51+,Urban,789 Pine Rd,12345\n...\n</code></pre> <p>config.toml (settings):</p> <pre><code># Set to zero for secure random results\nrandom_number_seed = 0\n\n# Household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Algorithm choice\nselection_algorithm = \"maximin\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\nid_column = \"id\"\n</code></pre>"},{"location":"cli/#basic-selection","title":"Basic Selection","text":"<pre><code>python -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#using-environment-variables","title":"Using Environment Variables","text":"<p>Set commonly used paths as environment variables:</p> <pre><code>export SORTITION_SETTINGS=\"config.toml\"\n\npython -m sortition_algorithms csv \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  -s selected.csv \\\n  -r remaining.csv \\\n  -n 100\n</code></pre>"},{"location":"cli/#batch-processing","title":"Batch Processing","text":"<p>Create a script for multiple selections:</p> <pre><code>#!/bin/bash\n# batch_selection.sh\n\nSETTINGS=\"config.toml\"\nFEATURES=\"demographics.csv\"\nPEOPLE=\"candidates.csv\"\nAREAS=(north south east west)\nSIZE=50\n\nfor area in \"${AREAS[@]}\"; do\n    echo \"Selecting $size people...\"\n    python -m sortition_algorithms csv \\\n        --settings \"$SETTINGS\" \\\n        --features-csv \"$FEATURES\" \\\n        --people-csv \"candidates_${area}.csv\" \\\n        --selected-csv \"selected_${area}.csv\" \\\n        --remaining-csv \"remaining_${area}.csv\" \\\n        --number-wanted \"$SIZE\"\ndone\n</code></pre>"},{"location":"cli/#google-sheets-workflow","title":"Google Sheets Workflow","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"cli/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials</li> <li>Share Sheet: Share your spreadsheet with the service account email</li> </ol>"},{"location":"cli/#command-reference_1","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gsheet --help\nUsage: python -m sortition_algorithms gsheet [OPTIONS]\n\n  Do sortition with Google Spreadsheets.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  --auth-json-file FILE           Google API credentials JSON [required]\n  --gen-rem-tab / --no-gen-rem-tab Generate 'Remaining' tab [default: true]\n  -g, --gsheet-name TEXT          Spreadsheet name [required]\n  -f, --feature-tab-name TEXT     Features tab name [default: Categories]\n  -p, --people-tab-name TEXT      People tab name [default: Categories]\n  -s, --selected-tab-name TEXT    Selected output tab [default: Selected]\n  -r, --remaining-tab-name TEXT   Remaining output tab [default: Remaining]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#authentication-setup","title":"Authentication Setup","text":"<ol> <li>Download service account credentials JSON file</li> <li>Never commit this file to version control</li> <li>Store securely and reference by path</li> </ol>"},{"location":"cli/#example-usage","title":"Example Usage","text":"<pre><code>python -m sortition_algorithms gsheet \\\n  --settings config.toml \\\n  --auth-json-file /secure/path/credentials.json \\\n  --gsheet-name \"Citizen Panel 2024\" \\\n  --feature-tab-name \"Demographics\" \\\n  --people-tab-name \"Candidates\" \\\n  --selected-tab-name \"Selected Panel\" \\\n  --remaining-tab-name \"Reserve Pool\" \\\n  --number-wanted 120\n</code></pre>"},{"location":"cli/#spreadsheet-structure","title":"Spreadsheet Structure","text":"<p>Your Google Sheet should have tabs structured like this:</p> <p>Demographics tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Candidates tab:</p> id Name Email Gender Age Location p001 Alice alice@email.com Female 18-30 Urban p002 Bob bob@email.com Male 31-50 Rural"},{"location":"cli/#sample-generation","title":"Sample Generation","text":"<p>Generate test data compatible with your feature definitions.</p>"},{"location":"cli/#command-reference_2","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gen-sample --help\nUsage: python -m sortition_algorithms gen-sample [OPTIONS]\n\n  Generate sample CSV file compatible with features and settings.\n\nOptions:\n  -S, --settings FILE             Settings file [required]\n  -f, --features-csv FILE         Features CSV file [required]\n  -p, --people-csv FILE           Output: generated people CSV [required]\n  -n, --number-wanted INTEGER     Number of people to generate [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-usage_1","title":"Example Usage","text":"<pre><code># Generate 500 sample people\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv sample_candidates.csv \\\n  --number-wanted 500\n</code></pre> <p>This creates a CSV with realistic synthetic data that matches your feature definitions - useful for testing quotas and algorithms.</p>"},{"location":"cli/#configuration-files","title":"Configuration Files","text":""},{"location":"cli/#settings-file-format","title":"Settings File Format","text":"<p>All settings are optional and have sensible defaults:</p> <pre><code># config.toml\n\n# Randomization\nrandom_number_seed = 0  # Set non-zero for reproducible results, omit for random\n\n# Address checking for household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\", \"City\"]\n\n# Algorithm selection\nselection_algorithm = \"maximin\"  # \"maximin\", \"nash\", \"leximin\", \"legacy\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\", \"Notes\"]\nid_column = \"id\"  # Column name containing unique IDs\n</code></pre>"},{"location":"cli/#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Pros Cons Use Case <code>maximin</code> Fair to minorities May not optimize overall Default choice <code>nash</code> Balanced overall Complex optimization Large diverse pools <code>leximin</code> Strongest fairness Requires Gurobi license Academic/research <code>legacy</code> Backwards compatible Less sophisticated Historical consistency"},{"location":"cli/#common-workflows","title":"Common Workflows","text":""},{"location":"cli/#standard-selection-process","title":"Standard Selection Process","text":"<pre><code># 1. Prepare your data files\n# 2. Configure settings\n# 3. Run selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n\n# 4. Review results\nhead selected.csv\nwc -l remaining.csv\n</code></pre>"},{"location":"cli/#with-address-checking","title":"With Address Checking","text":"<p>Ensure household diversity by preventing multiple selections from the same address:</p> <pre><code># config.toml\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n</code></pre>"},{"location":"cli/#reproducible-selections","title":"Reproducible Selections","text":"<p>For auditable results, use a fixed random seed:</p> <pre><code># config.toml\nrandom_number_seed = 20241214  # Use today's date or similar\n</code></pre>"},{"location":"cli/#testing-quotas","title":"Testing Quotas","text":"<p>Use sample generation to test if your quotas are achievable:</p> <pre><code># Generate large sample\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --number-wanted 1000\n\n# Test selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --selected-csv test_selected.csv \\\n  --remaining-csv test_remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli/#common-errors","title":"Common Errors","text":"<p>\"Selection failed\"</p> <ul> <li>Check that the sum of quota minimums for any given features don't exceed panel size (or that maximums are smaller than the panel size).</li> <li>Verify feature values match between files.</li> <li>Review constraint feasibility.</li> </ul> <p>\"File not found\"</p> <ul> <li>Use absolute paths or verify working directory.</li> <li>Check file permissions.</li> <li>Ensure files exist before running.</li> </ul> <p>\"Invalid feature values\"</p> <ul> <li>Verify exact string matching between demographics.csv and candidates.csv</li> <li>Check for typos, case sensitivity, extra spaces</li> <li>Review non-ASCII characters</li> </ul> <p>\"Authentication failed\" (Google Sheets)</p> <ul> <li>Verify <code>credentials.json</code> is correct and accessible</li> <li>Check that service account has access to the spreadsheet</li> <li>Ensure APIs are enabled in Google Cloud Console</li> </ul>"},{"location":"cli/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand the theory behind sortition</li> <li>API Reference - For programmatic usage</li> <li>Data Adapters - Custom data sources and formats</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"concepts/","title":"Core Concepts","text":"<p>Understanding these fundamental concepts is essential for effectively using sortition algorithms.</p>"},{"location":"concepts/#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling (which could accidentally select all men or all young people), sortition uses stratified random selection to ensure demographic balance.</p>"},{"location":"concepts/#historical-context","title":"Historical Context","text":"<p>Sortition has ancient roots in Athenian democracy, where citizens were chosen by lot to serve in government. Modern applications include:</p> <ul> <li>Citizens' Assemblies: Groups that deliberate on policy issues</li> <li>Deliberative Polls: Representative samples for public opinion research</li> <li>Jury Selection: Court juries selected from voter rolls</li> <li>Participatory Budgeting: Community members deciding budget priorities</li> </ul>"},{"location":"concepts/#key-components","title":"Key Components","text":""},{"location":"concepts/#features-and-feature-values","title":"Features and Feature Values","text":"<p>Features are demographic characteristics used for stratification:</p> <ul> <li>Gender, Age, Education, Income, Location, etc.</li> </ul> <p>Feature Values are the specific categories within each feature:</p> <ul> <li>Gender: Male, Female, Non-binary</li> <li>Age: 18-30, 31-50, 51-65, 65+</li> <li>Location: Urban, Suburban, Rural</li> </ul> <p>Note that sometimes Features are called \"categories\" and Feature Values are called \"category values\".</p>"},{"location":"concepts/#quotas-and-targets","title":"Quotas and Targets","text":"<p>Each feature value has minimum and maximum quotas that define the acceptable range for selection:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,25,35\n</code></pre> <p>This ensures your panel of 100 people includes 45-55 men, 45-55 women, 20-30 young adults, etc.</p>"},{"location":"concepts/#people-pool","title":"People Pool","text":"<p>The candidate pool contains all eligible individuals with their demographic data:</p> <pre><code>id,Name,Gender,Age,Location,Email\np001,Alice Smith,Female,18-30,Urban,alice@example.com\np002,Bob Jones,Male,31-50,Rural,bob@example.com\n...\n</code></pre>"},{"location":"concepts/#address-checking-and-household-diversity","title":"Address Checking and Household Diversity","text":"<p>A critical feature for ensuring true representativeness is address checking - preventing multiple people from the same household being selected.</p>"},{"location":"concepts/#why-address-checking-matters","title":"Why Address Checking Matters","text":"<p>Without address checking, you might accidentally select:</p> <ul> <li>Multiple family members with similar views</li> <li>Several housemates from a shared address</li> <li>People who influence each other's opinions</li> </ul> <p>This reduces the independence and diversity of your panel.</p>"},{"location":"concepts/#how-it-works","title":"How It Works","text":"<p>Configure address checking in your settings:</p> <pre><code>settings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre> <p>When someone is selected:</p> <ol> <li>The algorithm identifies anyone else with matching values in the specified columns</li> <li>Those people are removed from the remaining pool</li> <li>This ensures geographic and household diversity</li> </ol>"},{"location":"concepts/#address-column-strategies","title":"Address Column Strategies","text":"<p>Single column approach:</p> <pre><code>check_same_address_columns = [\"Full_Address\"]\n</code></pre> <p>Multi-column approach (more flexible):</p> <pre><code>check_same_address_columns = [\"Street\", \"City\", \"Postcode\"]\n</code></pre> <p>Exact vs. fuzzy matching: The current implementation requires exact string matches. For fuzzy address matching, you'd need to clean your data first.</p>"},{"location":"concepts/#selection-algorithms","title":"Selection Algorithms","text":"<p>Different algorithms optimize for different fairness criteria:</p>"},{"location":"concepts/#maximin-default","title":"Maximin (Default)","text":"<p>Objective: Maximize the minimum selection probability across all groups.</p> <p>When to use:</p> <ul> <li>Default choice for most applications</li> <li>Ensures no group is severely underrepresented</li> <li>Good for citizen assemblies and deliberative panels</li> </ul> <p>Trade-offs:</p> <ul> <li>May not optimize overall fairness</li> <li>Can be conservative in selection choices</li> </ul> <p>Example scenario: A panel where ensuring minimum representation for small minorities is crucial.</p>"},{"location":"concepts/#nash","title":"Nash","text":"<p>Objective: Maximize the product of all selection probabilities.</p> <p>When to use:</p> <ul> <li>Large, diverse candidate pools</li> <li>When you want balanced representation across all groups</li> <li>Academic research requiring mathematical optimality</li> </ul> <p>Trade-offs:</p> <ul> <li>More complex optimization</li> <li>May be harder to explain to stakeholders</li> </ul> <p>Example scenario: Research study requiring theoretically optimal fairness across all demographic groups.</p>"},{"location":"concepts/#leximin","title":"Leximin","text":"<p>Objective: Lexicographic maximin optimization (requires Gurobi license).</p> <p>When to use:</p> <ul> <li>Academic research requiring strongest fairness guarantees</li> <li>When you have access to Gurobi (commercial/academic license)</li> <li>High-stakes selections where maximum fairness is essential</li> </ul> <p>Trade-offs:</p> <ul> <li>Requires commercial solver (Gurobi)</li> <li>More computationally intensive</li> <li>May be overkill for routine selections</li> </ul> <p>Example scenario: Government-sponsored citizen assembly where mathematical proof of fairness is required.</p>"},{"location":"concepts/#legacy","title":"Legacy","text":"<p>Objective: Backwards compatibility with earlier implementations.</p> <p>When to use:</p> <ul> <li>Reproducing historical selections</li> <li>Comparison studies</li> <li>Specific compatibility requirements</li> </ul> <p>Trade-offs:</p> <ul> <li>Less sophisticated than modern algorithms</li> <li>May not provide optimal fairness</li> </ul>"},{"location":"concepts/#research-background","title":"Research Background","text":"<p>The algorithms are described in this paper (open access).</p> <p>Other relevant papers:</p> <ul> <li>Procaccia et al. Is Sortition Both Representative and Fair?</li> <li>Tiago c Peixoto</li> <li>Reflections on the representativeness of citizens\u2019 assemblies and similar innovations and</li> <li>How representative is it really? A correspondence on sortition</li> </ul>"},{"location":"concepts/#the-selection-process","title":"The Selection Process","text":""},{"location":"concepts/#1-feasibility-checking","title":"1. Feasibility Checking","text":"<p>Before selection begins, the algorithm verifies that quotas are achievable:</p> <pre><code>features.check_desired(number_people_wanted=100)\n</code></pre>"},{"location":"concepts/#2-algorithm-execution","title":"2. Algorithm Execution","text":"<p>The chosen algorithm finds an optimal probability distribution over possible committees.</p>"},{"location":"concepts/#3-lottery-rounding","title":"3. Lottery Rounding","text":"<p>The probability distribution is converted to concrete selections using randomized rounding.</p>"},{"location":"concepts/#4-validation","title":"4. Validation","text":"<p>Selected committees are checked against quotas to ensure targets were met.</p>"},{"location":"concepts/#randomness-and-reproducibility","title":"Randomness and Reproducibility","text":""},{"location":"concepts/#random-seeds","title":"Random Seeds","text":"<p>For reproducible results (e.g., for auditing), set a random seed:</p> <pre><code>settings = Settings(random_number_seed=42)\n</code></pre>"},{"location":"concepts/#security-considerations","title":"Security Considerations","text":"<p>For production use, avoid fixed seeds. The library uses Python's <code>secrets</code> module when no seed is specified.</p>"},{"location":"concepts/#data-quality-considerations","title":"Data Quality Considerations","text":""},{"location":"concepts/#feature-consistency","title":"Feature Consistency","text":"<p>Ensure feature values are consistent between your quotas file and candidate data:</p> <pre><code># demographics.csv\nGender,Male,45,55\nGender,Female,45,55\n\n# candidates.csv - values must match exactly\nperson1,Male,...    # \u2705 Matches\nperson2,male,...    # \u274c Case mismatch\nperson3,M,...       # \u274c Abbreviation mismatch\n</code></pre>"},{"location":"concepts/#missing-data","title":"Missing Data","text":"<p>The library requires complete demographic data. Handle missing values before import:</p> <ul> <li>Impute missing values</li> <li>Create \"Unknown\" categories</li> <li>Exclude incomplete records</li> </ul>"},{"location":"concepts/#data-validation","title":"Data Validation","text":"<p>The library performs extensive validation:</p> <ul> <li>Checks for unknown feature values</li> <li>Verifies quota feasibility</li> <li>Validates candidate pool size</li> </ul>"},{"location":"concepts/#error-handling","title":"Error Handling","text":""},{"location":"concepts/#common-errors","title":"Common Errors","text":"<p>InfeasibleQuotasError: Your quotas cannot be satisfied</p> <pre><code># Too restrictive - asking for 90+ males in a pool of 100\nGender,Male,90,100\nGender,Female,90,100\n</code></pre> <p>SelectionError: General selection failures</p> <ul> <li>Insufficient candidates in a category</li> <li>Conflicting constraints</li> </ul> <p>ValueError: Invalid parameters</p> <ul> <li>Negative quotas</li> <li>Invalid algorithm names</li> </ul>"},{"location":"concepts/#debugging-tips","title":"Debugging Tips","text":"<ol> <li>Check quota feasibility: Sum of minimums \u2264 panel size \u2264 sum of maximums</li> <li>Verify data consistency: Feature values match between files</li> <li>Review messages: The algorithm provides detailed feedback</li> <li>Test with relaxed quotas: Temporarily widen ranges to isolate issues</li> </ol>"},{"location":"concepts/#best-practices","title":"Best Practices","text":""},{"location":"concepts/#quota-design","title":"Quota Design","text":"<ul> <li>Start conservative: Use wider ranges initially, then narrow if needed</li> <li>Consider interactions: Age and education might be correlated</li> <li>Plan for edge cases: What if you have few candidates in a category?</li> </ul>"},{"location":"concepts/#data-preparation","title":"Data Preparation","text":"<ul> <li>Standardize values: Consistent capitalization and spelling</li> <li>Validate completeness: No missing demographic data</li> <li>Test with samples: Verify your setup with small test runs</li> </ul>"},{"location":"concepts/#address-checking","title":"Address Checking","text":"<ul> <li>Clean addresses first: Standardize formatting before using address checking</li> <li>Consider geography: Urban areas might need tighter address matching</li> <li>Balance household diversity vs. other constraints: Address checking reduces your effective pool size</li> </ul>"},{"location":"concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the core concepts:</p> <ul> <li>Quick Start - Try your first selection</li> <li>API Reference - Detailed function documentation</li> <li>CLI Usage - Command line examples</li> <li>Data Adapters - Working with different data sources</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"modules/","title":"Modules","text":"<p>Adapters for loading and saving data.</p> <p>Initially we have CSV files locally, and Google Docs Spreadsheets.</p> <p>Selection algorithms for stratified sampling.</p>"},{"location":"modules/#sortition_algorithms.adapters.CSVFileDataSource","title":"<code>CSVFileDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class CSVFileDataSource(AbstractDataSource):\n    def __init__(self, features_file: Path, people_file: Path, selected_file: Path, remaining_file: Path) -&gt; None:\n        self.features_file = features_file\n        self.people_file = people_file\n        self.selected_file = selected_file\n        self.remaining_file = remaining_file\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_line(f\"Loading features from file {self.features_file}.\")\n        with open(self.features_file, newline=\"\") as csv_file:\n            feature_reader = csv.DictReader(csv_file, strict=True)\n            assert feature_reader.fieldnames is not None\n            yield list(feature_reader.fieldnames), feature_reader\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_line(f\"Loading people from file {self.people_file}.\")\n        with open(self.people_file, newline=\"\") as csv_file:\n            people_reader = csv.DictReader(csv_file, strict=True)\n            assert people_reader.fieldnames is not None\n            yield list(people_reader.fieldnames), people_reader\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        report.add_line_and_log(f\"Writing selected rows to {self.selected_file}\", logging.INFO)\n        with open(self.selected_file, \"w\", newline=\"\") as csv_file:\n            _write_csv_rows(csv_file, selected)\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        report.add_line_and_log(f\"Writing remaining rows to {self.selected_file}\", logging.INFO)\n        with open(self.remaining_file, \"w\", newline=\"\") as csv_file:\n            _write_csv_rows(csv_file, remaining)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVFileDataSource.highlight_dupes","title":"<code>highlight_dupes(dupes)</code>","text":"<p>Cannot highlight a CSV file</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def highlight_dupes(self, dupes: list[int]) -&gt; None:\n    \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVStringDataSource","title":"<code>CSVStringDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class CSVStringDataSource(AbstractDataSource):\n    def __init__(self, features_data: str, people_data: str) -&gt; None:\n        self.features_data = features_data\n        self.people_data = people_data\n        self.selected_file = StringIO()\n        self.remaining_file = StringIO()\n        self.selected_file_written = False\n        self.remaining_file_written = False\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_line(\"Loading features from string.\")\n        feature_reader = csv.DictReader(StringIO(self.features_data), strict=True)\n        assert feature_reader.fieldnames is not None\n        yield list(feature_reader.fieldnames), feature_reader\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_line(\"Loading people from string.\")\n        people_reader = csv.DictReader(StringIO(self.people_data), strict=True)\n        assert people_reader.fieldnames is not None\n        yield list(people_reader.fieldnames), people_reader\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        _write_csv_rows(self.selected_file, selected)\n        self.selected_file_written = True\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        _write_csv_rows(self.remaining_file, remaining)\n        self.remaining_file_written = True\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVStringDataSource.highlight_dupes","title":"<code>highlight_dupes(dupes)</code>","text":"<p>Cannot highlight a CSV file</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def highlight_dupes(self, dupes: list[int]) -&gt; None:\n    \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource","title":"<code>GSheetDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class GSheetDataSource(AbstractDataSource):\n    scope: ClassVar = [\n        \"https://spreadsheets.google.com/feeds\",\n        \"https://www.googleapis.com/auth/drive\",\n    ]\n    hl_light_blue: ClassVar = {\n        \"backgroundColor\": {\n            \"red\": 153 / 255,\n            \"green\": 204 / 255,\n            \"blue\": 255 / 255,\n        }\n    }\n    hl_orange: ClassVar = {\"backgroundColor\": {\"red\": 5, \"green\": 2.5, \"blue\": 0}}\n\n    def __init__(self, feature_tab_name: str, people_tab_name: str, auth_json_path: Path) -&gt; None:\n        self.feature_tab_name = feature_tab_name\n        self.people_tab_name = people_tab_name\n        self.auth_json_path = auth_json_path\n        self._client: gspread.client.Client | None = None\n        self._spreadsheet: gspread.Spreadsheet | None = None\n        self.new_tab_default_size_rows = 2\n        self.new_tab_default_size_cols = 40\n        self._g_sheet_name = \"\"\n        self._open_g_sheet_name = \"\"\n        self.selected_tab_name = \"\"\n        self.remaining_tab_name = \"\"\n        self.tab_namer = GSheetTabNamer()\n        self._report = RunReport()\n\n    @property\n    def client(self) -&gt; gspread.client.Client:\n        if self._client is None:\n            creds = ServiceAccountCredentials.from_json_keyfile_name(str(self.auth_json_path), self.scope)\n            # if we're getting rate limited, go slower!\n            # by using the BackOffHTTPClient, that will sleep and retry\n            # if it gets an error related to API usage rate limits.\n            self._client = gspread.authorize(creds, http_client=gspread.BackOffHTTPClient)\n        return self._client\n\n    @property\n    def spreadsheet(self) -&gt; gspread.Spreadsheet:\n        if self._open_g_sheet_name != self._g_sheet_name:\n            # reset the spreadsheet if the name changed\n            self._spreadsheet = None\n            self.tab_namer.reset()\n        if self._spreadsheet is None:\n            if self._g_sheet_name.startswith(\"https://\"):\n                self._spreadsheet = self.client.open_by_url(self._g_sheet_name)\n            else:\n                self._spreadsheet = self.client.open(self._g_sheet_name)\n            self._open_g_sheet_name = self._g_sheet_name\n            self._report.add_line_and_log(f\"Opened Google Sheet: '{self._spreadsheet.title}'. \", log_level=logging.INFO)\n        return self._spreadsheet\n\n    def _get_tab(self, tab_name: str) -&gt; gspread.Worksheet | None:\n        if not self._g_sheet_name:\n            return None\n        tab_list = self.spreadsheet.worksheets()\n        try:\n            return next(tab for tab in tab_list if tab.title == tab_name)\n        except StopIteration:\n            return None\n\n    def _tab_exists(self, tab_name: str) -&gt; bool:\n        return bool(self._get_tab(tab_name))\n\n    def _get_tab_titles(self) -&gt; list[str]:\n        if not self._g_sheet_name:\n            return []\n        return [tab.title for tab in self.spreadsheet.worksheets()]\n\n    def _create_tab(self, tab_name: str) -&gt; gspread.Worksheet:\n        return self.spreadsheet.add_worksheet(\n            title=tab_name,\n            rows=self.new_tab_default_size_rows,\n            cols=self.new_tab_default_size_cols,\n        )\n\n    def set_g_sheet_name(self, g_sheet_name: str) -&gt; None:\n        # if we're changing spreadsheet, reset the spreadsheet object\n        if self._g_sheet_name != g_sheet_name:\n            self._spreadsheet = None\n            self._g_sheet_name = g_sheet_name\n            self.tab_namer.reset()\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        self._report = report\n        try:\n            if not self._tab_exists(self.feature_tab_name):\n                msg = f\"Error in Google sheet: no tab called '{self.feature_tab_name}' found.\"\n                self._report.add_line_and_log(msg, log_level=logging.ERROR)\n                raise SelectionError(msg, self._report)\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}.\"\n            self._report.add_line_and_log(msg, log_level=logging.ERROR)\n            raise SelectionError(msg, self._report) from err\n        tab_features = self.spreadsheet.worksheet(self.feature_tab_name)\n        feature_head = tab_features.row_values(1)\n        feature_body = _stringify_records(tab_features.get_all_records(expected_headers=[]))\n        yield feature_head, feature_body\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        self._report = report\n        try:\n            if not self._tab_exists(self.people_tab_name):\n                msg = f\"Error in Google sheet: no tab called '{self.people_tab_name}' found. \"\n                self._report.add_line(msg)\n                raise SelectionError(msg, self._report)\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}. \"\n            self._report.add_line(msg)\n            raise SelectionError(msg, self._report) from err\n\n        tab_people = self.spreadsheet.worksheet(self.people_tab_name)\n        # if we don't read this in here we can't check if there are 2 columns with the same name\n        people_head = tab_people.row_values(1)\n        # the numericise_ignore doesn't convert the phone numbers to ints...\n        # 1 Oct 2024: the final argument with expected_headers is to deal with the fact that\n        # updated versions of gspread can't cope with duplicate headers\n        people_body = _stringify_records(\n            tab_people.get_all_records(\n                numericise_ignore=[\"all\"],\n                expected_headers=[],\n            )\n        )\n        self._report.add_line(f\"Reading in '{self.people_tab_name}' tab in above Google sheet.\")\n        yield people_head, people_body\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        self.tab_namer.find_unused_tab_suffix(self._get_tab_titles())\n        tab_selected = self._create_tab(self.tab_namer.selected_tab_name())\n        report.add_line_and_log(f\"Writing selected people to tab: {tab_selected.title}\", logging.INFO)\n        self.selected_tab_name = tab_selected.title\n        tab_selected.update(selected)\n        tab_selected.format(\"A1:U1\", self.hl_light_blue)\n        user_logger.info(f\"Selected people written to {tab_selected.title} tab\")\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        # the number is selected during write_selected(), so we reuse it here\n        tab_remaining = self._create_tab(self.tab_namer.remaining_tab_name())\n        report.add_line_and_log(f\"Writing remaining people to tab: {tab_remaining.title}\", logging.INFO)\n        self.remaining_tab_name = tab_remaining.title\n        tab_remaining.update(remaining)\n        tab_remaining.format(\"A1:U1\", self.hl_light_blue)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        if not dupes:\n            return\n        tab_remaining = self._get_tab(self.tab_namer.remaining_tab_name())\n        assert tab_remaining is not None, \"highlight_dupes() has been called without first calling write_remaining()\"\n        # note that the indexes we have produced start at 0, but the row indexes start at 1\n        # so we need to add 1 to the indexes.\n        row_strings = [f\"A{index + 1}:U{index + 1}\" for index in dupes]\n        tab_remaining.format(row_strings, self.hl_orange)\n\n    def delete_old_output_tabs(self, dry_run: bool = False) -&gt; list[str]:\n        \"\"\"\n        Find and delete all tabs with names starting with the tab stubs for selected or remaining\n\n        Args:\n            dry_run: If True, report what would be deleted without actually deleting.\n\n        Returns:\n            List of tab names that were deleted (or would be deleted in dry_run mode).\n        \"\"\"\n        if not self._g_sheet_name:\n            return []\n\n        all_tabs = self.spreadsheet.worksheets()\n        tabs_to_delete: list[gspread.Worksheet] = []\n\n        for tab in all_tabs:\n            if self.tab_namer.matches_stubs(tab.title):\n                tabs_to_delete.append(tab)\n\n        deleted_names: list[str] = []\n        for tab in tabs_to_delete:\n            deleted_names.append(tab.title)\n            if not dry_run:\n                self.spreadsheet.del_worksheet(tab)\n\n        return deleted_names\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource.delete_old_output_tabs","title":"<code>delete_old_output_tabs(dry_run=False)</code>","text":"<p>Find and delete all tabs with names starting with the tab stubs for selected or remaining</p> <p>Parameters:</p> Name Type Description Default <code>dry_run</code> <code>bool</code> <p>If True, report what would be deleted without actually deleting.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of tab names that were deleted (or would be deleted in dry_run mode).</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def delete_old_output_tabs(self, dry_run: bool = False) -&gt; list[str]:\n    \"\"\"\n    Find and delete all tabs with names starting with the tab stubs for selected or remaining\n\n    Args:\n        dry_run: If True, report what would be deleted without actually deleting.\n\n    Returns:\n        List of tab names that were deleted (or would be deleted in dry_run mode).\n    \"\"\"\n    if not self._g_sheet_name:\n        return []\n\n    all_tabs = self.spreadsheet.worksheets()\n    tabs_to_delete: list[gspread.Worksheet] = []\n\n    for tab in all_tabs:\n        if self.tab_namer.matches_stubs(tab.title):\n            tabs_to_delete.append(tab)\n\n    deleted_names: list[str] = []\n    for tab in tabs_to_delete:\n        deleted_names.append(tab.title)\n        if not dry_run:\n            self.spreadsheet.del_worksheet(tab)\n\n    return deleted_names\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.generate_dupes","title":"<code>generate_dupes(people_remaining_rows, settings)</code>","text":"<p>Generate a list of indexes of people who share an address with someone else in this set of rows.</p> <p>Note that the first row of people_remaining_rows is the column headers.  The indexes generated are for the rows in this table, so the index takes account of the first row being the header.</p> <p>So if we had people_remaining_rows:</p> <p>id,name,address_line_1,postcode 1,Alice,33 Acacia Avenue,W1A 1AA 1,Bob,31 Acacia Avenue,W1A 1AA 1,Charlotte,33 Acacia Avenue,W1A 1AA 1,David,33 Acacia Avenue,W1B 1BB</p> <p>And settings with <code>check_same_address_columns = [\"address_line_1\", \"postcode\"]</code></p> <p>Then we should return [1, 3]</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def generate_dupes(people_remaining_rows: list[list[str]], settings: Settings) -&gt; list[int]:\n    \"\"\"\n    Generate a list of indexes of people who share an address with someone else in this set of rows.\n\n    Note that the first row of people_remaining_rows is the column headers.  The indexes generated\n    are for the rows in this table, so the index takes account of the first row being the header.\n\n    So if we had people_remaining_rows:\n\n    id,name,address_line_1,postcode\n    1,Alice,33 Acacia Avenue,W1A 1AA\n    1,Bob,31 Acacia Avenue,W1A 1AA\n    1,Charlotte,33 Acacia Avenue,W1A 1AA\n    1,David,33 Acacia Avenue,W1B 1BB\n\n    And settings with `check_same_address_columns = [\"address_line_1\", \"postcode\"]`\n\n    Then we should return [1, 3]\n    \"\"\"\n    if not settings.check_same_address:\n        return []\n\n    table_col_names = people_remaining_rows[0]\n    address_col_indexes: list[int] = [\n        index for index, col in enumerate(table_col_names) if col in settings.check_same_address_columns\n    ]\n    address_remaining_index: dict[tuple[str, ...], list[int]] = defaultdict(list)\n\n    # first, we assemble a dict with the key being the address, the value being the list of\n    # indexes of people at that address\n    for person_index, person in enumerate(people_remaining_rows):\n        if person_index == 0:\n            continue  # skip the header row\n        address_tuple = tuple(col for col_index, col in enumerate(person) if col_index in address_col_indexes)\n        address_remaining_index[address_tuple].append(person_index)\n\n    # now extract all those people where the number of people at their address is more than one\n    dupes: list[int] = []\n    for persons_at_address in address_remaining_index.values():\n        if len(persons_at_address) &gt; 1:\n            dupes += persons_at_address\n\n    return sorted(dupes)\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_any_committee","title":"<code>find_any_committee(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find any single feasible committee that satisfies the quotas.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns to check for same address, or empty list if                         not checking addresses.</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], RunReport]</code> <p>tuple of (list containing one committee as frozenset of person_ids, empty report)</p> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>If quotas are infeasible</p> <code>SelectionError</code> <p>If solver fails for other reasons</p> Source code in <code>src/sortition_algorithms/committee_generation/__init__.py</code> <pre><code>def find_any_committee(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"Find any single feasible committee that satisfies the quotas.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns to check for same address, or empty list if\n                                    not checking addresses.\n\n    Returns:\n        tuple of (list containing one committee as frozenset of person_ids, empty report)\n\n    Raises:\n        InfeasibleQuotasError: If quotas are infeasible\n        SelectionError: If solver fails for other reasons\n    \"\"\"\n    _, agent_vars = setup_committee_generation(features, people, number_people_wanted, check_same_address_columns)\n    committee = ilp_results_to_committee(agent_vars)\n    return [committee], RunReport()\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_leximin","title":"<code>find_distribution_leximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the third-lowest probability and so forth.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Gurobi is not available</p> Source code in <code>src/sortition_algorithms/committee_generation/leximin.py</code> <pre><code>def find_distribution_leximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected\n    (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the\n    third-lowest probability and so forth.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    Raises:\n        RuntimeError: If Gurobi is not available\n    \"\"\"\n    if not GUROBI_AVAILABLE:\n        msg = \"Leximin algorithm requires Gurobi solver which is not available\"\n        raise RuntimeError(msg)\n\n    report = RunReport()\n    report.add_line_and_log(\"Using leximin algorithm.\", log_level=logging.INFO)\n    grb.setParam(\"OutputFlag\", 0)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 3 * people.count\n    )\n    report.add_report(initial_report)\n\n    # Run the main leximin optimization loop to fix agent probabilities\n    fixed_probabilities = _run_leximin_main_loop(new_committee_model, agent_vars, committees, people, report)\n\n    # Convert fixed agent probabilities to committee probabilities\n    probabilities_normalised = _solve_leximin_primal_for_final_probabilities(committees, fixed_probabilities)\n\n    return list(committees), probabilities_normalised, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_maximin","title":"<code>find_distribution_maximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/maximin.py</code> <pre><code>def find_distribution_maximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n    \"\"\"\n    report = RunReport()\n    report.add_line_and_log(\"Using maximin algorithm.\", log_level=logging.INFO)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, init_report = generate_initial_committees(new_committee_model, agent_vars, people.count)\n    report.add_report(init_report)\n\n    # Set up the incremental LP model for column generation\n    incremental_model, incr_agent_vars, upper_bound_var = _setup_maximin_incremental_model(committees, covered_agents)\n\n    # Run the main optimization loop\n    return _run_maximin_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        incremental_model,\n        incr_agent_vars,\n        upper_bound_var,\n        committees,\n        covered_agents,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_nash","title":"<code>find_distribution_nash(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of selection probabilities over all persons.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.</p> Source code in <code>src/sortition_algorithms/committee_generation/nash.py</code> <pre><code>def find_distribution_nash(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of\n    selection probabilities over all persons.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing\n    log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and\n    this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.\n    \"\"\"\n    report = RunReport()\n    report.add_line_and_log(\"Using Nash algorithm.\", log_level=logging.INFO)\n\n    # Set up an ILP used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that include every possible agent\n    committee_set, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 2 * people.count\n    )\n    committees = list(committee_set)\n    report.add_report(initial_report)\n\n    # Map the covered agents to indices in a list for easier matrix representation\n    entitlements, contributes_to_entitlement = _define_entitlements(covered_agents)\n\n    # Run the main Nash welfare optimization loop\n    return _run_nash_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        committees,\n        entitlements,\n        contributes_to_entitlement,\n        covered_agents,\n        number_people_wanted,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_random_sample_legacy","title":"<code>find_random_sample_legacy(people, features, number_people_wanted, check_same_address_columns=None)</code>","text":"<p>Legacy stratified random selection algorithm.</p> <p>Implements the original algorithm that uses greedy selection based on priority ratios. Always selects from the most urgently needed category first (highest ratio of (min-selected)/remaining), then randomly picks within that category.</p> <p>Parameters:</p> Name Type Description Default <code>people</code> <code>People</code> <p>People collection</p> required <code>features</code> <code>FeatureCollection</code> <p>Feature definitions with min/max targets</p> required <code>number_people_wanted</code> <code>int</code> <p>Number of people to select</p> required <code>check_same_address_columns</code> <code>list[str] | None</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>Tuple of (selected_committees, output_messages) where:</p> <code>RunReport</code> <ul> <li>selected_committees: List containing one frozenset of selected person IDs</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report containing log messages about the selection process</li> </ul> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If selection becomes impossible (not enough people, etc.)</p> Source code in <code>src/sortition_algorithms/committee_generation/legacy.py</code> <pre><code>def find_random_sample_legacy(\n    people: People,\n    features: FeatureCollection,\n    number_people_wanted: int,\n    check_same_address_columns: list[str] | None = None,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"\n    Legacy stratified random selection algorithm.\n\n    Implements the original algorithm that uses greedy selection based on priority ratios.\n    Always selects from the most urgently needed category first (highest ratio of\n    (min-selected)/remaining), then randomly picks within that category.\n\n    Args:\n        people: People collection\n        features: Feature definitions with min/max targets\n        number_people_wanted: Number of people to select\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        Tuple of (selected_committees, output_messages) where:\n        - selected_committees: List containing one frozenset of selected person IDs\n        - report: report containing log messages about the selection process\n\n    Raises:\n        SelectionError: If selection becomes impossible (not enough people, etc.)\n    \"\"\"\n    report = RunReport()\n    report.add_line(\"Using legacy algorithm.\")\n    people_selected: set[str] = set()\n\n    # Create PeopleFeatures and initialize\n    people_features = PeopleFeatures(people, features, check_same_address_columns or [])\n    people_features.update_all_features_remaining()\n    people_features.prune_for_feature_max_0()\n\n    # Main selection loop\n    for count in range(number_people_wanted):\n        # Find the category with highest priority ratio\n        try:\n            ratio_result = people_features.find_max_ratio_category()\n        except errors.SelectionError as e:\n            msg = f\"Selection failed on iteration {count + 1}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Find the randomly selected person within that category\n        target_feature = ratio_result.feature_name\n        target_value = ratio_result.feature_value\n        random_position = ratio_result.random_person_index\n\n        selected_person_key = people_features.people.find_person_by_position_in_category(\n            target_feature, target_value, random_position\n        )\n\n        # Should never select the same person twice\n        assert selected_person_key not in people_selected, f\"Person {selected_person_key} was already selected\"\n\n        # Select the person (this also removes household members if configured)\n        people_selected.add(selected_person_key)\n        selected_person_data = people_features.people.get_person_dict(selected_person_key)\n        household_members_removed = people_features.select_person(selected_person_key)\n\n        # Add output messages about household member removal\n        if household_members_removed:\n            report.add_line(\n                f\"Selected {selected_person_key}, also removed household members: \"\n                f\"{', '.join(household_members_removed)}\"\n            )\n\n        # Handle any categories that are now full after this selection\n        try:\n            category_messages = people_features.handle_category_full_deletions(selected_person_data)\n            report.add_lines(category_messages)\n        except errors.SelectionError as e:\n            msg = f\"Selection failed after selecting {selected_person_key}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Check if we're about to run out of people (but not on the last iteration)\n        if count &lt; (number_people_wanted - 1) and people_features.people.count == 0:\n            msg = \"Selection failed: Ran out of people before completing selection\"\n            raise errors.SelectionError(msg)\n\n    # Return in legacy format: list containing single frozenset\n    return [frozenset(people_selected)], report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.standardize_distribution","title":"<code>standardize_distribution(committees, probabilities)</code>","text":"<p>Remove committees with zero probability and renormalize.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], list[float]]</code> <p>tuple of (filtered_committees, normalized_probabilities)</p> Source code in <code>src/sortition_algorithms/committee_generation/__init__.py</code> <pre><code>def standardize_distribution(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n) -&gt; tuple[list[frozenset[str]], list[float]]:\n    \"\"\"Remove committees with zero probability and renormalize.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities\n\n    Returns:\n        tuple of (filtered_committees, normalized_probabilities)\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    new_committees = []\n    new_probabilities = []\n    for committee, prob in zip(committees, probabilities, strict=False):\n        if prob &gt;= EPS2:\n            new_committees.append(committee)\n            new_probabilities.append(prob)\n    prob_sum = sum(new_probabilities)\n    new_probabilities = [prob / prob_sum for prob in new_probabilities]\n    return new_committees, new_probabilities\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.generate_initial_committees","title":"<code>generate_initial_committees(new_committee_model, agent_vars, multiplicative_weights_rounds)</code>","text":"<p>To speed up the main iteration of the maximin and Nash algorithms, start from a diverse set of feasible committees. In particular, each agent that can be included in any committee will be included in at least one of these committees.</p> <p>Parameters:</p> Name Type Description Default <code>new_committee_model</code> <code>Model</code> <p>MIP model for finding committees</p> required <code>agent_vars</code> <code>dict[str, Var]</code> <p>dict mapping agent_id to binary MIP variables</p> required <code>multiplicative_weights_rounds</code> <code>int</code> <p>number of rounds for the multiplicative weights phase</p> required <p>Returns:</p> Type Description <code>set[frozenset[str]]</code> <p>tuple of (committees, covered_agents, output_lines)</p> <code>frozenset[str]</code> <ul> <li>committees: set of feasible committees discovered</li> </ul> <code>RunReport</code> <ul> <li>covered_agents: frozenset of all agents included in some committee</li> </ul> <code>tuple[set[frozenset[str]], frozenset[str], RunReport]</code> <ul> <li>report: run report</li> </ul> <code>tuple[set[frozenset[str]], frozenset[str], RunReport]</code> <ul> <li>output_lines: list of debug messages</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def generate_initial_committees(\n    new_committee_model: mip.model.Model,\n    agent_vars: dict[str, mip.entities.Var],\n    multiplicative_weights_rounds: int,\n) -&gt; tuple[set[frozenset[str]], frozenset[str], RunReport]:\n    \"\"\"To speed up the main iteration of the maximin and Nash algorithms, start from a diverse set of feasible\n    committees. In particular, each agent that can be included in any committee will be included in at least one of\n    these committees.\n\n    Args:\n        new_committee_model: MIP model for finding committees\n        agent_vars: dict mapping agent_id to binary MIP variables\n        multiplicative_weights_rounds: number of rounds for the multiplicative weights phase\n\n    Returns:\n        tuple of (committees, covered_agents, output_lines)\n        - committees: set of feasible committees discovered\n        - covered_agents: frozenset of all agents included in some committee\n        - report: run report\n        - output_lines: list of debug messages\n    \"\"\"\n    report = RunReport()\n\n    # Phase 1: Use multiplicative weights algorithm to find diverse committees\n    committees, covered_agents = _run_multiplicative_weights_phase(\n        new_committee_model, agent_vars, multiplicative_weights_rounds\n    )\n\n    # Phase 2: Find committees for any agents not yet covered\n    additional_committees, covered_agents, coverage_report = _find_committees_for_uncovered_agents(\n        new_committee_model, agent_vars, covered_agents\n    )\n    committees.update(additional_committees)\n    report.add_report(coverage_report)\n\n    # Validation and final output\n    assert len(committees) &gt;= 1  # We assume quotas are feasible at this stage\n\n    if len(covered_agents) == len(agent_vars):\n        report.add_line_and_log(\"All agents are contained in some feasible committee.\", log_level=logging.INFO)\n\n    return committees, frozenset(covered_agents), report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.ilp_results_to_committee","title":"<code>ilp_results_to_committee(variables)</code>","text":"<p>Extract the selected committee from ILP solver variables.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>dict[str, Var]</code> <p>dict mapping person_id to binary MIP variables</p> required <p>Returns:</p> Type Description <code>frozenset[str]</code> <p>frozenset of person_ids who are selected (have variable value &gt; 0.5)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If variables don't have values (solver failed)</p> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def ilp_results_to_committee(variables: dict[str, mip.entities.Var]) -&gt; frozenset[str]:\n    \"\"\"Extract the selected committee from ILP solver variables.\n\n    Args:\n        variables: dict mapping person_id to binary MIP variables\n\n    Returns:\n        frozenset of person_ids who are selected (have variable value &gt; 0.5)\n\n    Raises:\n        ValueError: If variables don't have values (solver failed)\n    \"\"\"\n    try:\n        committee = frozenset(person_id for person_id in variables if variables[person_id].x &gt; 0.5)\n    # unfortunately, MIP sometimes throws generic Exceptions rather than a subclass\n    except Exception as error:\n        msg = f\"It seems like some variables do not have a value. Original exception: {error}.\"\n        raise ValueError(msg) from error\n\n    return committee\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.setup_committee_generation","title":"<code>setup_committee_generation(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Set up the integer linear program for committee generation.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns to check for same address, or empty list if                         not checking addresses.</p> required <p>Returns:</p> Type Description <code>tuple[Model, dict[str, Var]]</code> <p>tuple of (MIP model, dict mapping person_id to binary variables)</p> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>If quotas are infeasible, includes suggested relaxations</p> <code>SelectionError</code> <p>If solver fails for other reasons</p> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def setup_committee_generation(\n    features: FeatureCollection, people: People, number_people_wanted: int, check_same_address_columns: list[str]\n) -&gt; tuple[mip.model.Model, dict[str, mip.entities.Var]]:\n    \"\"\"Set up the integer linear program for committee generation.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns to check for same address, or empty list if\n                                    not checking addresses.\n\n    Returns:\n        tuple of (MIP model, dict mapping person_id to binary variables)\n\n    Raises:\n        InfeasibleQuotasError: If quotas are infeasible, includes suggested relaxations\n        SelectionError: If solver fails for other reasons\n    \"\"\"\n    model = mip.Model(sense=mip.MAXIMIZE)\n    model.verbose = 0  # TODO: get debug level from settings\n\n    # Binary variable for each person (selected/not selected)\n    agent_vars = {person_id: model.add_var(var_type=mip.BINARY) for person_id in people}\n\n    # Must select exactly the desired number of people\n    model.add_constr(mip.xsum(agent_vars.values()) == number_people_wanted)\n\n    # Respect min/max quotas for each feature value\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n        # Count people with this feature-value who are selected\n        number_feature_value_agents = mip.xsum(\n            agent_vars[person_id]\n            for person_id, person_data in people.items()\n            if person_data[feature_name] == fvalue_name\n        )\n\n        # Add min/max constraints\n        model.add_constr(number_feature_value_agents &gt;= fv_minmax.min)\n        model.add_constr(number_feature_value_agents &lt;= fv_minmax.max)\n\n    # Household constraints: at most 1 person per household\n    if check_same_address_columns:\n        for housemates in people.households(check_same_address_columns).values():\n            if len(housemates) &gt; 1:\n                model.add_constr(mip.xsum(agent_vars[member_id] for member_id in housemates) &lt;= 1)\n\n    # Test feasibility by optimizing once\n    status = model.optimize()\n    if status == mip.OptimizationStatus.INFEASIBLE:\n        relaxed_features, output_lines = _relax_infeasible_quotas(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n        raise errors.InfeasibleQuotasError(relaxed_features, output_lines)\n    if status != mip.OptimizationStatus.OPTIMAL:\n        msg = (\n            f\"No feasible committees found, solver returns code {status} (see \"\n            \"https://docs.python-mip.com/en/latest/classes.html#optimizationstatus).\"\n        )\n        raise errors.SelectionError(msg)\n\n    return model, agent_vars\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.legacy.find_random_sample_legacy","title":"<code>find_random_sample_legacy(people, features, number_people_wanted, check_same_address_columns=None)</code>","text":"<p>Legacy stratified random selection algorithm.</p> <p>Implements the original algorithm that uses greedy selection based on priority ratios. Always selects from the most urgently needed category first (highest ratio of (min-selected)/remaining), then randomly picks within that category.</p> <p>Parameters:</p> Name Type Description Default <code>people</code> <code>People</code> <p>People collection</p> required <code>features</code> <code>FeatureCollection</code> <p>Feature definitions with min/max targets</p> required <code>number_people_wanted</code> <code>int</code> <p>Number of people to select</p> required <code>check_same_address_columns</code> <code>list[str] | None</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>Tuple of (selected_committees, output_messages) where:</p> <code>RunReport</code> <ul> <li>selected_committees: List containing one frozenset of selected person IDs</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report containing log messages about the selection process</li> </ul> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If selection becomes impossible (not enough people, etc.)</p> Source code in <code>src/sortition_algorithms/committee_generation/legacy.py</code> <pre><code>def find_random_sample_legacy(\n    people: People,\n    features: FeatureCollection,\n    number_people_wanted: int,\n    check_same_address_columns: list[str] | None = None,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"\n    Legacy stratified random selection algorithm.\n\n    Implements the original algorithm that uses greedy selection based on priority ratios.\n    Always selects from the most urgently needed category first (highest ratio of\n    (min-selected)/remaining), then randomly picks within that category.\n\n    Args:\n        people: People collection\n        features: Feature definitions with min/max targets\n        number_people_wanted: Number of people to select\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        Tuple of (selected_committees, output_messages) where:\n        - selected_committees: List containing one frozenset of selected person IDs\n        - report: report containing log messages about the selection process\n\n    Raises:\n        SelectionError: If selection becomes impossible (not enough people, etc.)\n    \"\"\"\n    report = RunReport()\n    report.add_line(\"Using legacy algorithm.\")\n    people_selected: set[str] = set()\n\n    # Create PeopleFeatures and initialize\n    people_features = PeopleFeatures(people, features, check_same_address_columns or [])\n    people_features.update_all_features_remaining()\n    people_features.prune_for_feature_max_0()\n\n    # Main selection loop\n    for count in range(number_people_wanted):\n        # Find the category with highest priority ratio\n        try:\n            ratio_result = people_features.find_max_ratio_category()\n        except errors.SelectionError as e:\n            msg = f\"Selection failed on iteration {count + 1}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Find the randomly selected person within that category\n        target_feature = ratio_result.feature_name\n        target_value = ratio_result.feature_value\n        random_position = ratio_result.random_person_index\n\n        selected_person_key = people_features.people.find_person_by_position_in_category(\n            target_feature, target_value, random_position\n        )\n\n        # Should never select the same person twice\n        assert selected_person_key not in people_selected, f\"Person {selected_person_key} was already selected\"\n\n        # Select the person (this also removes household members if configured)\n        people_selected.add(selected_person_key)\n        selected_person_data = people_features.people.get_person_dict(selected_person_key)\n        household_members_removed = people_features.select_person(selected_person_key)\n\n        # Add output messages about household member removal\n        if household_members_removed:\n            report.add_line(\n                f\"Selected {selected_person_key}, also removed household members: \"\n                f\"{', '.join(household_members_removed)}\"\n            )\n\n        # Handle any categories that are now full after this selection\n        try:\n            category_messages = people_features.handle_category_full_deletions(selected_person_data)\n            report.add_lines(category_messages)\n        except errors.SelectionError as e:\n            msg = f\"Selection failed after selecting {selected_person_key}: {e}\"\n            raise errors.SelectionError(msg) from e\n\n        # Check if we're about to run out of people (but not on the last iteration)\n        if count &lt; (number_people_wanted - 1) and people_features.people.count == 0:\n            msg = \"Selection failed: Ran out of people before completing selection\"\n            raise errors.SelectionError(msg)\n\n    # Return in legacy format: list containing single frozenset\n    return [frozenset(people_selected)], report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.leximin.find_distribution_leximin","title":"<code>find_distribution_leximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the third-lowest probability and so forth.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Gurobi is not available</p> Source code in <code>src/sortition_algorithms/committee_generation/leximin.py</code> <pre><code>def find_distribution_leximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected\n    (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the\n    third-lowest probability and so forth.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    Raises:\n        RuntimeError: If Gurobi is not available\n    \"\"\"\n    if not GUROBI_AVAILABLE:\n        msg = \"Leximin algorithm requires Gurobi solver which is not available\"\n        raise RuntimeError(msg)\n\n    report = RunReport()\n    report.add_line_and_log(\"Using leximin algorithm.\", log_level=logging.INFO)\n    grb.setParam(\"OutputFlag\", 0)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 3 * people.count\n    )\n    report.add_report(initial_report)\n\n    # Run the main leximin optimization loop to fix agent probabilities\n    fixed_probabilities = _run_leximin_main_loop(new_committee_model, agent_vars, committees, people, report)\n\n    # Convert fixed agent probabilities to committee probabilities\n    probabilities_normalised = _solve_leximin_primal_for_final_probabilities(committees, fixed_probabilities)\n\n    return list(committees), probabilities_normalised, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.maximin.find_distribution_maximin","title":"<code>find_distribution_maximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/maximin.py</code> <pre><code>def find_distribution_maximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n    \"\"\"\n    report = RunReport()\n    report.add_line_and_log(\"Using maximin algorithm.\", log_level=logging.INFO)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, init_report = generate_initial_committees(new_committee_model, agent_vars, people.count)\n    report.add_report(init_report)\n\n    # Set up the incremental LP model for column generation\n    incremental_model, incr_agent_vars, upper_bound_var = _setup_maximin_incremental_model(committees, covered_agents)\n\n    # Run the main optimization loop\n    return _run_maximin_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        incremental_model,\n        incr_agent_vars,\n        upper_bound_var,\n        committees,\n        covered_agents,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.nash.find_distribution_nash","title":"<code>find_distribution_nash(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of selection probabilities over all persons.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.</p> Source code in <code>src/sortition_algorithms/committee_generation/nash.py</code> <pre><code>def find_distribution_nash(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of\n    selection probabilities over all persons.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing\n    log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and\n    this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.\n    \"\"\"\n    report = RunReport()\n    report.add_line_and_log(\"Using Nash algorithm.\", log_level=logging.INFO)\n\n    # Set up an ILP used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that include every possible agent\n    committee_set, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 2 * people.count\n    )\n    committees = list(committee_set)\n    report.add_report(initial_report)\n\n    # Map the covered agents to indices in a list for easier matrix representation\n    entitlements, contributes_to_entitlement = _define_entitlements(covered_agents)\n\n    # Run the main Nash welfare optimization loop\n    return _run_nash_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        committees,\n        entitlements,\n        contributes_to_entitlement,\n        covered_agents,\n        number_people_wanted,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.find_random_sample","title":"<code>find_random_sample(features, people, number_people_wanted, check_same_address_columns, selection_algorithm='maximin', test_selection=False, number_selections=1)</code>","text":"<p>Main algorithm to find one or multiple random committees.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns for the address to check, or empty list if no check required</p> required <code>selection_algorithm</code> <code>str</code> <p>one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"</p> <code>'maximin'</code> <code>test_selection</code> <code>bool</code> <p>if set, do not do a random selection, but just return some valid panel. Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>how many panels to return. Most of the time, this should be set to 1, which means that a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n, containing multiple panels (some panels might be repeated in the list). In this case the eventual panel should be drawn uniformly at random from the returned list.</p> <code>1</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committee_lottery, report)</p> <code>RunReport</code> <ul> <li>committee_lottery: list of committees, where each committee is a frozen set of pool member ids</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report with debug strings</li> </ul> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>if the quotas cannot be satisfied, which includes a suggestion for how to modify them</p> <code>SelectionError</code> <p>in multiple other failure cases</p> <code>ValueError</code> <p>for invalid parameters</p> <code>RuntimeError</code> <p>if required solver is not available</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"Main algorithm to find one or multiple random committees.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns for the address to check, or empty list if no check required\n        selection_algorithm: one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"\n        test_selection: if set, do not do a random selection, but just return some valid panel.\n            Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!\n        number_selections: how many panels to return. Most of the time, this should be set to 1, which means that\n            a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n,\n            containing multiple panels (some panels might be repeated in the list). In this case the eventual panel\n            should be drawn uniformly at random from the returned list.\n\n    Returns:\n        tuple of (committee_lottery, report)\n        - committee_lottery: list of committees, where each committee is a frozen set of pool member ids\n        - report: report with debug strings\n\n    Raises:\n        InfeasibleQuotasError: if the quotas cannot be satisfied, which includes a suggestion for how to modify them\n        SelectionError: in multiple other failure cases\n        ValueError: for invalid parameters\n        RuntimeError: if required solver is not available\n    \"\"\"\n    # Input validation\n    if test_selection and number_selections != 1:\n        msg = (\n            \"Running the test selection does not support generating a transparent lottery, so, if \"\n            \"`test_selection` is true, `number_selections` must be 1.\"\n        )\n        raise ValueError(msg)\n\n    if selection_algorithm == \"legacy\" and number_selections != 1:\n        msg = (\n            \"Currently, the legacy algorithm does not support generating a transparent lottery, \"\n            \"so `number_selections` must be set to 1.\"\n        )\n        raise ValueError(msg)\n\n    # Quick test selection using find_any_committee\n    if test_selection:\n        logger.info(\"Running test selection.\")\n        return find_any_committee(features, people, number_people_wanted, check_same_address_columns)\n\n    report = RunReport()\n\n    # Check if Gurobi is available for leximin\n    if selection_algorithm == \"leximin\" and not GUROBI_AVAILABLE:\n        msg = (\n            \"The leximin algorithm requires the optimization library Gurobi to be installed \"\n            \"(commercial, free academic licenses available). Switching to the simpler \"\n            \"maximin algorithm, which can be run using open source solvers.\"\n        )\n        report.add_line(msg)\n        selection_algorithm = \"maximin\"\n\n    # Route to appropriate algorithm\n    if selection_algorithm == \"legacy\":\n        return find_random_sample_legacy(\n            people,\n            features,\n            number_people_wanted,\n            check_same_address_columns,\n        )\n    elif selection_algorithm == \"leximin\":\n        committees, probabilities, new_report = find_distribution_leximin(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    elif selection_algorithm == \"maximin\":\n        committees, probabilities, new_report = find_distribution_maximin(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    elif selection_algorithm == \"nash\":\n        committees, probabilities, new_report = find_distribution_nash(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    else:\n        msg = (\n            f\"Unknown selection algorithm {selection_algorithm!r}, must be either 'legacy', 'leximin', \"\n            f\"'maximin', or 'nash'.\"\n        )\n        raise ValueError(msg)\n\n    # Post-process the distribution\n    committees, probabilities = standardize_distribution(committees, probabilities)\n    if len(committees) &gt; people.count:\n        logger.warning(\n            \"INFO: The distribution over panels is what is known as a 'basic solution'. There is no reason for concern \"\n            \"about the correctness of your output, but we'd appreciate if you could reach out to panelot\"\n            f\"@paulgoelz.de with the following information: algorithm={selection_algorithm}, \"\n            f\"num_panels={len(committees)}, num_agents={people.count}, min_probs={min(probabilities)}.\"\n        )\n\n    assert len(set(committees)) == len(committees)\n\n    report.add_report(new_report)\n    stats_report = _distribution_stats(people, committees, probabilities)\n    report.add_report(stats_report)\n\n    # Convert to lottery\n    committee_lottery = lottery_rounding(committees, probabilities, number_selections)\n\n    return committee_lottery, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.lottery_rounding","title":"<code>lottery_rounding(committees, probabilities, number_selections)</code>","text":"<p>Convert probability distribution over committees to a discrete lottery.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities (must sum to 1)</p> required <code>number_selections</code> <code>int</code> <p>number of committees to return</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>list of committees (may contain duplicates) of length number_selections</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def lottery_rounding(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n    number_selections: int,\n) -&gt; list[frozenset[str]]:\n    \"\"\"Convert probability distribution over committees to a discrete lottery.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities (must sum to 1)\n        number_selections: number of committees to return\n\n    Returns:\n        list of committees (may contain duplicates) of length number_selections\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    assert number_selections &gt;= 1\n\n    num_copies: list[int] = []\n    residuals: list[float] = []\n    for _, prob in zip(committees, probabilities, strict=False):\n        scaled_prob = prob * number_selections\n        num_copies.append(int(scaled_prob))  # give lower quotas\n        residuals.append(scaled_prob - int(scaled_prob))\n\n    rounded_up_indices = pipage_rounding(list(enumerate(residuals)))\n    for committee_index in rounded_up_indices:\n        num_copies[committee_index] += 1\n\n    committee_lottery: list[frozenset[str]] = []\n    for committee, committee_copies in zip(committees, num_copies, strict=False):\n        committee_lottery += [committee for _ in range(committee_copies)]\n\n    return committee_lottery\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.pipage_rounding","title":"<code>pipage_rounding(marginals)</code>","text":"<p>Pipage rounding algorithm for converting fractional solutions to integer solutions.</p> <p>Takes a list of (object, probability) pairs and randomly rounds them to a set of objects such that the expected number of times each object appears equals its probability.</p> <p>Parameters:</p> Name Type Description Default <code>marginals</code> <code>list[tuple[int, float]]</code> <p>list of (object, probability) pairs where probabilities sum to an integer</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list of objects that were selected</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def pipage_rounding(marginals: list[tuple[int, float]]) -&gt; list[int]:\n    \"\"\"Pipage rounding algorithm for converting fractional solutions to integer solutions.\n\n    Takes a list of (object, probability) pairs and randomly rounds them to a set of objects\n    such that the expected number of times each object appears equals its probability.\n\n    Args:\n        marginals: list of (object, probability) pairs where probabilities sum to an integer\n\n    Returns:\n        list of objects that were selected\n    \"\"\"\n    assert all(0.0 &lt;= p &lt;= 1.0 for _, p in marginals)\n\n    outcomes: list[int] = []\n    while True:\n        if len(marginals) == 0:\n            return outcomes\n        if len(marginals) == 1:\n            obj, prob = marginals[0]\n            if random_provider().uniform(0.0, 1.0) &lt; prob:\n                outcomes.append(obj)\n            marginals = []\n        else:\n            obj0, prob0 = marginals[0]\n            if prob0 &gt; 1.0 - EPS2:\n                outcomes.append(obj0)\n                marginals = marginals[1:]\n                continue\n            if prob0 &lt; EPS2:\n                marginals = marginals[1:]\n                continue\n\n            obj1, prob1 = marginals[1]\n            if prob1 &gt; 1.0 - EPS2:\n                outcomes.append(obj1)\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n            if prob1 &lt; EPS2:\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n\n            inc0_dec1_amount = min(\n                1.0 - prob0, prob1\n            )  # maximal amount that prob0 can be increased and prob1 can be decreased\n            dec0_inc1_amount = min(prob0, 1.0 - prob1)\n            choice_probability = dec0_inc1_amount / (inc0_dec1_amount + dec0_inc1_amount)\n\n            if random_provider().uniform(0.0, 1.0) &lt; choice_probability:  # increase prob0 and decrease prob1\n                prob0 += inc0_dec1_amount\n                prob1 -= inc0_dec1_amount\n            else:\n                prob0 -= dec0_inc1_amount\n                prob1 += dec0_inc1_amount\n            marginals = [(obj0, prob0), (obj1, prob1)] + marginals[2:]\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.run_stratification","title":"<code>run_stratification(features, people, number_people_wanted, settings, test_selection=False, number_selections=1)</code>","text":"<p>Run stratified random selection with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas for each feature value</p> required <code>people</code> <code>People</code> <p>People object containing the pool of candidates</p> required <code>number_people_wanted</code> <code>int</code> <p>Desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <code>test_selection</code> <code>bool</code> <p>If True, don't randomize (for testing only)</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>Number of panels to return</p> <code>1</code> <p>Returns:</p> Type Description <code>bool</code> <p>Tuple of (success, selected_committees, report)</p> <code>list[frozenset[str]]</code> <ul> <li>success: Whether selection succeeded within max attempts</li> </ul> <code>RunReport</code> <ul> <li>selected_committees: List of committees (frozensets of person IDs)</li> </ul> <code>tuple[bool, list[frozenset[str]], RunReport]</code> <ul> <li>report: contains debug and status messages</li> </ul> <p>Raises:</p> Type Description <code>Exception</code> <p>If number_people_wanted is outside valid range for any feature</p> <code>ValueError</code> <p>For invalid parameters</p> <code>RuntimeError</code> <p>If required solver is not available</p> <code>InfeasibleQuotasError</code> <p>If quotas cannot be satisfied</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[bool, list[frozenset[str]], RunReport]:\n    \"\"\"Run stratified random selection with retry logic.\n\n    Args:\n        features: FeatureCollection with min/max quotas for each feature value\n        people: People object containing the pool of candidates\n        number_people_wanted: Desired size of the panel\n        settings: Settings object containing configuration\n        test_selection: If True, don't randomize (for testing only)\n        number_selections: Number of panels to return\n\n    Returns:\n        Tuple of (success, selected_committees, report)\n        - success: Whether selection succeeded within max attempts\n        - selected_committees: List of committees (frozensets of person IDs)\n        - report: contains debug and status messages\n\n    Raises:\n        Exception: If number_people_wanted is outside valid range for any feature\n        ValueError: For invalid parameters\n        RuntimeError: If required solver is not available\n        InfeasibleQuotasError: If quotas cannot be satisfied\n    \"\"\"\n    # Check if desired number is within feature constraints\n    check_desired(features, number_people_wanted)\n\n    # Set random seed if specified\n    # If the seed is zero or None, we use the secrets module, as it is better\n    # from a security point of view\n    set_random_provider(settings.random_number_seed)\n\n    success = False\n    report = RunReport()\n\n    if test_selection:\n        report.add_line(\"WARNING: Panel is not selected at random! Only use for testing!\", ReportLevel.CRITICAL)\n\n    report.add_line(\"Initial: (selected = 0)\", ReportLevel.IMPORTANT)\n    initial_cat_report = _initial_print_category_info(features, people)\n    report.add_report(initial_cat_report)\n    people_selected: list[frozenset[str]] = []\n\n    tries = 0\n    for tries in range(settings.max_attempts):\n        people_selected = []\n\n        report.add_line(f\"Trial number: {tries}\", ReportLevel.IMPORTANT)\n\n        try:\n            people_selected, new_report = find_random_sample(\n                features,\n                people,\n                number_people_wanted,\n                settings.normalised_address_columns,\n                settings.selection_algorithm,\n                test_selection,\n                number_selections,\n            )\n            report.add_report(new_report)\n\n            # Check if targets were met (only works for number_selections = 1)\n            cat_report = _print_category_info(features, people, people_selected, number_people_wanted)\n            success, check_report = _check_category_selected(features, people, people_selected, number_selections)\n\n            if success:\n                report.add_line(\"SUCCESS!! Final:\", ReportLevel.IMPORTANT)\n                report.add_report(cat_report)\n                report.add_report(check_report)\n                break\n\n        except (ValueError, RuntimeError) as err:\n            report.add_line(str(err))\n            break\n        except errors.InfeasibleQuotasError as err:\n            report.add_lines(err.output)\n            break\n        except errors.InfeasibleQuotasCantRelaxError as err:\n            report.add_line(err.message)\n            break\n        except errors.SelectionError as serr:\n            report.add_line(f\"Failed: Selection Error thrown: {serr}\")\n\n    if not success:\n        report.add_line(f\"Failed {tries} times... gave up.\")\n\n    return success, people_selected, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.selected_remaining_tables","title":"<code>selected_remaining_tables(full_people, people_selected, features, settings)</code>","text":"<p>write some text</p> <p>people_selected is a single frozenset[str] - it must be unwrapped before being passed to this function.</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n    \"\"\"\n    write some text\n\n    people_selected is a single frozenset[str] - it must be unwrapped before being passed\n    to this function.\n    \"\"\"\n    people_working = deepcopy(full_people)\n    output_lines: list[str] = []\n\n    people_selected_rows = person_list_to_table(people_selected, people_working, features, settings)\n\n    # now delete the selected people (and maybe also those at the same address)\n    num_same_address_deleted = 0\n    for pkey in people_selected:\n        # if check address then delete all those at this address (will NOT delete the one we want as well)\n        if settings.check_same_address:\n            pkey_to_delete = list(people_working.matching_address(pkey, settings.check_same_address_columns))\n            num_same_address_deleted += len(pkey_to_delete) + 1\n            # then delete this/these people at the same address from the reserve/remaining pool\n            people_working.remove_many([pkey, *pkey_to_delete])\n        else:\n            people_working.remove(pkey)\n\n    # add the columns to keep into remaining people\n    # as above all these values are all in people_working but this is tidier...\n    people_remaining_rows = person_list_to_table(people_working, people_working, features, settings)\n    return people_selected_rows, people_remaining_rows, output_lines\n\n    # TODO: put this code somewhere more suitable\n    # maybe in strat app only?\n    \"\"\"\n    dupes = self._output_selected_remaining(\n        settings,\n        people_selected_rows,\n        people_remaining_rows,\n    )\n    if settings.check_same_address and self.gen_rem_tab:\n        output_lines.append(\n            f\"Deleted {num_same_address_deleted} people from remaining file who had the same \"\n            f\"address as selected people.\",\n        )\n        m = min(30, len(dupes))\n        output_lines.append(\n            f\"In the remaining tab there are {len(dupes)} people who share the same address as \"\n            f\"someone else in the tab. We highlighted the first {m} of these. \"\n            f\"The full list of lines is {dupes}\",\n        )\n    \"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionError","title":"<code>SelectionError</code>","text":"<p>               Bases: <code>Exception</code></p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class SelectionError(Exception):\n    def __init__(self, *args: object) -&gt; None:\n        \"\"\"\n        If one of the args is a RunReport, extract it and save it\n        \"\"\"\n        report_args = [a for a in args if isinstance(a, RunReport)]\n        non_report_args = [a for a in args if not isinstance(a, RunReport)]\n        super().__init__(*non_report_args)\n        self.report = report_args[0] if report_args else RunReport()\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionError.__init__","title":"<code>__init__(*args)</code>","text":"<p>If one of the args is a RunReport, extract it and save it</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __init__(self, *args: object) -&gt; None:\n    \"\"\"\n    If one of the args is a RunReport, extract it and save it\n    \"\"\"\n    report_args = [a for a in args if isinstance(a, RunReport)]\n    non_report_args = [a for a in args if not isinstance(a, RunReport)]\n    super().__init__(*non_report_args)\n    self.report = report_args[0] if report_args else RunReport()\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.check_desired","title":"<code>check_desired(fc, desired_number)</code>","text":"<p>Check if the desired number of people is within the min/max of every feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_desired(fc: FeatureCollection, desired_number: int) -&gt; None:\n    \"\"\"\n    Check if the desired number of people is within the min/max of every feature.\n    \"\"\"\n    for feature_name, fvalues in fc.items():\n        if desired_number &lt; _fv_minimum_selection(fvalues) or desired_number &gt; _fv_maximum_selection(fvalues):\n            msg = (\n                f\"The number of people to select ({desired_number}) is out of the range of \"\n                f\"the numbers of people in the {feature_name} feature. It should be within \"\n                f\"[{_fv_minimum_selection(fvalues)}, {_fv_maximum_selection(fvalues)}].\"\n            )\n            raise Exception(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.check_min_max","title":"<code>check_min_max(fc)</code>","text":"<p>If the min is bigger than the max we're in trouble i.e. there's an input error</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_min_max(fc: FeatureCollection) -&gt; None:\n    \"\"\"\n    If the min is bigger than the max we're in trouble i.e. there's an input error\n    \"\"\"\n    if minimum_selection(fc) &gt; maximum_selection(fc):\n        msg = (\n            \"Inconsistent numbers in min and max in the features input: the sum \"\n            \"of the minimum values of a features is larger than the sum of the \"\n            \"maximum values of a(nother) feature. \"\n        )\n        raise ValueError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.iterate_feature_collection","title":"<code>iterate_feature_collection(features)</code>","text":"<p>Helper function to iterate over feature collection.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def iterate_feature_collection(features: FeatureCollection) -&gt; Generator[tuple[str, str, FeatureValueMinMax]]:\n    \"\"\"Helper function to iterate over feature collection.\"\"\"\n    for feature_name, feature_values in features.items():\n        for value_name, fv_minmax in feature_values.items():\n            yield feature_name, value_name, fv_minmax\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.maximum_selection","title":"<code>maximum_selection(fc)</code>","text":"<p>The maximum selection for this set of features is the smallest maximum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def maximum_selection(fc: FeatureCollection) -&gt; int:\n    \"\"\"\n    The maximum selection for this set of features is the smallest maximum selection\n    of any individual feature.\n    \"\"\"\n    if not fc:\n        return 0\n\n    return min(_fv_maximum_selection(fv) for fv in fc.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.minimum_selection","title":"<code>minimum_selection(fc)</code>","text":"<p>The minimum selection for this set of features is the largest minimum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def minimum_selection(fc: FeatureCollection) -&gt; int:\n    \"\"\"\n    The minimum selection for this set of features is the largest minimum selection\n    of any individual feature.\n    \"\"\"\n    if not fc:\n        return 0\n\n    return max(_fv_minimum_selection(fv) for fv in fc.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.read_in_features","title":"<code>read_in_features(features_head, features_body)</code>","text":"<p>Read in stratified selection features and values</p> <p>Note we do want features_head to ensure we don't have multiple columns with the same name</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def read_in_features(features_head: Iterable[str], features_body: Iterable[dict[str, str]]) -&gt; FeatureCollection:\n    \"\"\"\n    Read in stratified selection features and values\n\n    Note we do want features_head to ensure we don't have multiple columns with the same name\n    \"\"\"\n    features: FeatureCollection = defaultdict(dict)\n    features_flex, filtered_headers = _feature_headers_flex(list(features_head))\n    for row in features_body:\n        # check the set of keys in the row are the same as the headers\n        assert set(filtered_headers) &lt;= set(row.keys())\n        stripped_row = utils.StrippedDict(_normalise_col_names(row))\n        if not stripped_row[\"feature\"]:\n            continue\n        fname, fvalue, fv_minmax = _clean_row(stripped_row, features_flex)\n        features[fname][fvalue] = fv_minmax\n\n    check_min_max(features)\n    # check feature_flex to see if we need to set the max here\n    # this only changes the max_flex value if these (optional) flex values are NOT set already\n    set_default_max_flex(features)\n    return features\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.set_default_max_flex","title":"<code>set_default_max_flex(fc)</code>","text":"<p>Note this only sets it if left at the default value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def set_default_max_flex(fc: FeatureCollection) -&gt; None:\n    \"\"\"Note this only sets it if left at the default value\"\"\"\n    max_flex = _safe_max_flex_val(fc)\n    for feature_values in fc.values():\n        for fv_minmax in feature_values.values():\n            fv_minmax.set_default_max_flex(max_flex)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.MaxRatioResult","title":"<code>MaxRatioResult</code>","text":"<p>Result from finding the category with maximum selection ratio.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>@define(kw_only=True, slots=True)\nclass MaxRatioResult:\n    \"\"\"Result from finding the category with maximum selection ratio.\"\"\"\n\n    feature_name: str\n    feature_value: str\n    random_person_index: int\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures","title":"<code>PeopleFeatures</code>","text":"<p>This class manipulates people and features together, making a deepcopy on init.</p> <p>It is only used by the legacy method.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class PeopleFeatures:\n    \"\"\"\n    This class manipulates people and features together, making a deepcopy on init.\n\n    It is only used by the legacy method.\n    \"\"\"\n\n    # TODO: consider naming: maybe SelectionState\n    # TODO: consider moving into committee_generation/legacy.py\n\n    def __init__(\n        self,\n        people: People,\n        features: FeatureCollection,\n        check_same_address_columns: list[str] | None = None,\n    ) -&gt; None:\n        self.people = deepcopy(people)\n        self.features = features\n        self.select_collection = select_from_feature_collection(self.features)\n        self.check_same_address_columns = check_same_address_columns or []\n\n    def update_features_remaining(self, person_key: str) -&gt; None:\n        # this will blow up if the person does not exist\n        person = self.people.get_person_dict(person_key)\n        for feature_name in self.features:\n            feature_value = person[feature_name]\n            self.select_collection[feature_name][feature_value].add_remaining()\n\n    def update_all_features_remaining(self) -&gt; None:\n        for person_key in self.people:\n            self.update_features_remaining(person_key)\n\n    def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n        \"\"\"\n        When a feature/value is \"full\" we delete everyone else in it.\n        \"Full\" means that the number selected equals the \"max\" amount - that\n        is detected elsewhere and then this method is called.\n        Returns count of those deleted, and count of those left\n        \"\"\"\n        # when a category is full we want to delete everyone in it\n        people_to_delete: list[str] = []\n        for pkey, person in self.people.items():\n            if person[feature_name] == feature_value:\n                people_to_delete.append(pkey)\n                for feature in self.features:\n                    current_feature_value = person[feature]\n                    try:\n                        self.select_collection[feature][current_feature_value].remove_remaining()\n                    except errors.SelectionError as e:\n                        msg = (\n                            f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                            f\"as after previous deletion no one/not enough left in {feature} \"\n                            f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                        )\n                        raise errors.SelectionError(msg) from e\n\n        self.people.remove_many(people_to_delete)\n        # return the number of people deleted and the number of people left\n        return len(people_to_delete), self.people.count\n\n    def prune_for_feature_max_0(self) -&gt; list[str]:\n        \"\"\"\n        Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n        NOT DONE: could then check if anyone is left.\n        \"\"\"\n        msg: list[str] = []\n        msg.append(f\"Number of people: {self.people.count}.\")\n        total_num_deleted = 0\n        for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(self.features):\n            if fv_minmax.max == 0:  # we don't want any of these people\n                # pass the message in as deleting them might throw an exception\n                msg.append(f\"Feature/value {feature_name}/{fvalue_name} full - deleting people...\")\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n                # if no exception was thrown above add this bit to the end of the previous message\n                msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n                total_num_deleted += num_deleted\n        # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n        # the 'remaining' file will be useless - remind the user of this!\n        if total_num_deleted &gt;= self.people.count / 2:\n            msg.append(\n                \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n                \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n            )\n        return msg\n\n    def select_person(self, person_key: str) -&gt; list[str]:\n        \"\"\"\n        Selecting a person means:\n        - remove the person from our copy of People\n        - update the `selected` and `remaining` counts of the FeatureCollection\n        - if check_same_address_columns has columns, also remove household members (without adding to selected)\n\n        Returns:\n            List of additional people removed due to same address (empty if check_same_address_columns is empty)\n        \"\"\"\n        # First, find household members if address checking is enabled (before removing the person)\n        household_members_removed = []\n        if self.check_same_address_columns:\n            household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n        # Handle the main person selection\n        person = self.people.get_person_dict(person_key)\n        for feature_name in self.features:\n            feature_value = person[feature_name]\n            self.select_collection[feature_name][feature_value].remove_remaining()\n            self.select_collection[feature_name][feature_value].add_selected()\n        self.people.remove(person_key)\n\n        # Then remove household members if any were found\n        for household_member_key in household_members_removed:\n            household_member = self.people.get_person_dict(household_member_key)\n            for feature_name in self.features:\n                feature_value = household_member[feature_name]\n                self.select_collection[feature_name][feature_value].remove_remaining()\n                # Note: we don't call add_selected() for household members\n            self.people.remove(household_member_key)\n\n        return household_members_removed\n\n    def find_max_ratio_category(self) -&gt; MaxRatioResult:\n        \"\"\"\n        Find the feature/value combination with the highest selection ratio.\n\n        The ratio is calculated as: (min - selected) / remaining\n        This represents how urgently we need people from this category.\n        Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n        Returns:\n            MaxRatioResult containing the feature name, value, and a random person index\n\n        Raises:\n            SelectionError: If insufficient people remain to meet minimum requirements\n        \"\"\"\n        max_ratio = -100.0\n        result_feature_name = \"\"\n        result_feature_value = \"\"\n        random_person_index = -1\n\n        for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n            # Check if we have insufficient people to meet minimum requirements\n            if not select_counts.sufficient_people():\n                msg = (\n                    f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{fvalue_name}. \"\n                    f\"Need {select_counts.people_still_needed} more, but only {select_counts.remaining} remaining.\"\n                )\n                raise errors.SelectionError(msg)\n\n            # Skip categories with no remaining people or max = 0\n            if select_counts.remaining == 0 or select_counts.min_max.max == 0:\n                continue\n\n            # Calculate the priority ratio\n            ratio = select_counts.people_still_needed / float(select_counts.remaining)\n\n            # Track the highest ratio category\n            if ratio &gt; max_ratio:\n                max_ratio = ratio\n                result_feature_name = feature_name\n                result_feature_value = fvalue_name\n                # from 1 to remaining\n                random_person_index = random_provider().randbelow(select_counts.remaining) + 1\n\n        # If no valid category found, all categories must be at their max or have max=0\n        if not result_feature_name:\n            msg = \"No valid categories found - all may be at maximum or have max=0\"\n            raise errors.SelectionError(msg)\n\n        return MaxRatioResult(\n            feature_name=result_feature_name,\n            feature_value=result_feature_value,\n            random_person_index=random_person_index,\n        )\n\n    def handle_category_full_deletions(self, selected_person_data: dict[str, str]) -&gt; list[str]:\n        \"\"\"\n        Check if any categories are now full after a selection and delete remaining people.\n\n        When a person is selected, some categories may reach their maximum quota.\n        This method identifies such categories and removes all remaining people from them.\n\n        Args:\n            selected_person_data: Dictionary of the selected person's feature values\n\n        Returns:\n            List of output messages about categories that became full and people deleted\n\n        Raises:\n            SelectionError: If deletions would violate minimum constraints\n        \"\"\"\n        output_messages = []\n\n        for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n            if (\n                fvalue_name == selected_person_data[feature_name]\n                and select_counts.selected == select_counts.min_max.max\n            ):\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n                if num_deleted &gt; 0:\n                    output_messages.append(\n                        f\"Category {feature_name}/{fvalue_name} full - deleted {num_deleted} people, {num_left} left.\"\n                    )\n\n        return output_messages\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.delete_all_with_feature_value","title":"<code>delete_all_with_feature_value(feature_name, feature_value)</code>","text":"<p>When a feature/value is \"full\" we delete everyone else in it. \"Full\" means that the number selected equals the \"max\" amount - that is detected elsewhere and then this method is called. Returns count of those deleted, and count of those left</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n    \"\"\"\n    When a feature/value is \"full\" we delete everyone else in it.\n    \"Full\" means that the number selected equals the \"max\" amount - that\n    is detected elsewhere and then this method is called.\n    Returns count of those deleted, and count of those left\n    \"\"\"\n    # when a category is full we want to delete everyone in it\n    people_to_delete: list[str] = []\n    for pkey, person in self.people.items():\n        if person[feature_name] == feature_value:\n            people_to_delete.append(pkey)\n            for feature in self.features:\n                current_feature_value = person[feature]\n                try:\n                    self.select_collection[feature][current_feature_value].remove_remaining()\n                except errors.SelectionError as e:\n                    msg = (\n                        f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                        f\"as after previous deletion no one/not enough left in {feature} \"\n                        f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                    )\n                    raise errors.SelectionError(msg) from e\n\n    self.people.remove_many(people_to_delete)\n    # return the number of people deleted and the number of people left\n    return len(people_to_delete), self.people.count\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.find_max_ratio_category","title":"<code>find_max_ratio_category()</code>","text":"<p>Find the feature/value combination with the highest selection ratio.</p> <p>The ratio is calculated as: (min - selected) / remaining This represents how urgently we need people from this category. Higher ratio = more urgent need (fewer people available relative to what we still need).</p> <p>Returns:</p> Type Description <code>MaxRatioResult</code> <p>MaxRatioResult containing the feature name, value, and a random person index</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If insufficient people remain to meet minimum requirements</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def find_max_ratio_category(self) -&gt; MaxRatioResult:\n    \"\"\"\n    Find the feature/value combination with the highest selection ratio.\n\n    The ratio is calculated as: (min - selected) / remaining\n    This represents how urgently we need people from this category.\n    Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n    Returns:\n        MaxRatioResult containing the feature name, value, and a random person index\n\n    Raises:\n        SelectionError: If insufficient people remain to meet minimum requirements\n    \"\"\"\n    max_ratio = -100.0\n    result_feature_name = \"\"\n    result_feature_value = \"\"\n    random_person_index = -1\n\n    for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n        # Check if we have insufficient people to meet minimum requirements\n        if not select_counts.sufficient_people():\n            msg = (\n                f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{fvalue_name}. \"\n                f\"Need {select_counts.people_still_needed} more, but only {select_counts.remaining} remaining.\"\n            )\n            raise errors.SelectionError(msg)\n\n        # Skip categories with no remaining people or max = 0\n        if select_counts.remaining == 0 or select_counts.min_max.max == 0:\n            continue\n\n        # Calculate the priority ratio\n        ratio = select_counts.people_still_needed / float(select_counts.remaining)\n\n        # Track the highest ratio category\n        if ratio &gt; max_ratio:\n            max_ratio = ratio\n            result_feature_name = feature_name\n            result_feature_value = fvalue_name\n            # from 1 to remaining\n            random_person_index = random_provider().randbelow(select_counts.remaining) + 1\n\n    # If no valid category found, all categories must be at their max or have max=0\n    if not result_feature_name:\n        msg = \"No valid categories found - all may be at maximum or have max=0\"\n        raise errors.SelectionError(msg)\n\n    return MaxRatioResult(\n        feature_name=result_feature_name,\n        feature_value=result_feature_value,\n        random_person_index=random_person_index,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.handle_category_full_deletions","title":"<code>handle_category_full_deletions(selected_person_data)</code>","text":"<p>Check if any categories are now full after a selection and delete remaining people.</p> <p>When a person is selected, some categories may reach their maximum quota. This method identifies such categories and removes all remaining people from them.</p> <p>Parameters:</p> Name Type Description Default <code>selected_person_data</code> <code>dict[str, str]</code> <p>Dictionary of the selected person's feature values</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of output messages about categories that became full and people deleted</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If deletions would violate minimum constraints</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def handle_category_full_deletions(self, selected_person_data: dict[str, str]) -&gt; list[str]:\n    \"\"\"\n    Check if any categories are now full after a selection and delete remaining people.\n\n    When a person is selected, some categories may reach their maximum quota.\n    This method identifies such categories and removes all remaining people from them.\n\n    Args:\n        selected_person_data: Dictionary of the selected person's feature values\n\n    Returns:\n        List of output messages about categories that became full and people deleted\n\n    Raises:\n        SelectionError: If deletions would violate minimum constraints\n    \"\"\"\n    output_messages = []\n\n    for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n        if (\n            fvalue_name == selected_person_data[feature_name]\n            and select_counts.selected == select_counts.min_max.max\n        ):\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n            if num_deleted &gt; 0:\n                output_messages.append(\n                    f\"Category {feature_name}/{fvalue_name} full - deleted {num_deleted} people, {num_left} left.\"\n                )\n\n    return output_messages\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.prune_for_feature_max_0","title":"<code>prune_for_feature_max_0()</code>","text":"<p>Check if any feature_value.max is set to zero. if so delete everyone with that feature value NOT DONE: could then check if anyone is left.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def prune_for_feature_max_0(self) -&gt; list[str]:\n    \"\"\"\n    Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n    NOT DONE: could then check if anyone is left.\n    \"\"\"\n    msg: list[str] = []\n    msg.append(f\"Number of people: {self.people.count}.\")\n    total_num_deleted = 0\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(self.features):\n        if fv_minmax.max == 0:  # we don't want any of these people\n            # pass the message in as deleting them might throw an exception\n            msg.append(f\"Feature/value {feature_name}/{fvalue_name} full - deleting people...\")\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n            # if no exception was thrown above add this bit to the end of the previous message\n            msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n            total_num_deleted += num_deleted\n    # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n    # the 'remaining' file will be useless - remind the user of this!\n    if total_num_deleted &gt;= self.people.count / 2:\n        msg.append(\n            \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n            \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n        )\n    return msg\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.select_person","title":"<code>select_person(person_key)</code>","text":"<p>Selecting a person means: - remove the person from our copy of People - update the <code>selected</code> and <code>remaining</code> counts of the FeatureCollection - if check_same_address_columns has columns, also remove household members (without adding to selected)</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of additional people removed due to same address (empty if check_same_address_columns is empty)</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def select_person(self, person_key: str) -&gt; list[str]:\n    \"\"\"\n    Selecting a person means:\n    - remove the person from our copy of People\n    - update the `selected` and `remaining` counts of the FeatureCollection\n    - if check_same_address_columns has columns, also remove household members (without adding to selected)\n\n    Returns:\n        List of additional people removed due to same address (empty if check_same_address_columns is empty)\n    \"\"\"\n    # First, find household members if address checking is enabled (before removing the person)\n    household_members_removed = []\n    if self.check_same_address_columns:\n        household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n    # Handle the main person selection\n    person = self.people.get_person_dict(person_key)\n    for feature_name in self.features:\n        feature_value = person[feature_name]\n        self.select_collection[feature_name][feature_value].remove_remaining()\n        self.select_collection[feature_name][feature_value].add_selected()\n    self.people.remove(person_key)\n\n    # Then remove household members if any were found\n    for household_member_key in household_members_removed:\n        household_member = self.people.get_person_dict(household_member_key)\n        for feature_name in self.features:\n            feature_value = household_member[feature_name]\n            self.select_collection[feature_name][feature_value].remove_remaining()\n            # Note: we don't call add_selected() for household members\n        self.people.remove(household_member_key)\n\n    return household_members_removed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts","title":"<code>SelectCounts</code>","text":"Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>@define(kw_only=True, slots=True)\nclass SelectCounts:\n    min_max: FeatureValueMinMax\n    selected: int = 0\n    remaining: int = 0\n\n    def add_remaining(self) -&gt; None:\n        self.remaining += 1\n\n    def add_selected(self) -&gt; None:\n        self.selected += 1\n\n    def remove_remaining(self) -&gt; None:\n        self.remaining -= 1\n        if self.remaining == 0 and self.selected &lt; self.min_max.min:\n            msg = \"SELECTION IMPOSSIBLE: FAIL - no one/not enough left after deletion.\"\n            raise errors.SelectionError(msg)\n\n    @property\n    def hit_target(self) -&gt; bool:\n        \"\"\"Return true if selected is between min and max (inclusive)\"\"\"\n        return self.selected &gt;= self.min_max.min and self.selected &lt;= self.min_max.max\n\n    def percent_selected(self, number_people_wanted: int) -&gt; float:\n        return self.selected * 100 / float(number_people_wanted)\n\n    @property\n    def people_still_needed(self) -&gt; int:\n        \"\"\"The number of extra people to select to get to the minimum - it should never be negative\"\"\"\n        return max(self.min_max.min - self.selected, 0)\n\n    def sufficient_people(self) -&gt; bool:\n        \"\"\"\n        Return true if we can still make the minimum. So either:\n        - we have already selected at least the minimum, or\n        - the remaining number is at least as big as the number still required\n        \"\"\"\n        return self.selected &gt;= self.min_max.min or self.remaining &gt;= self.people_still_needed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.hit_target","title":"<code>hit_target</code>  <code>property</code>","text":"<p>Return true if selected is between min and max (inclusive)</p>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.people_still_needed","title":"<code>people_still_needed</code>  <code>property</code>","text":"<p>The number of extra people to select to get to the minimum - it should never be negative</p>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.sufficient_people","title":"<code>sufficient_people()</code>","text":"<p>Return true if we can still make the minimum. So either: - we have already selected at least the minimum, or - the remaining number is at least as big as the number still required</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def sufficient_people(self) -&gt; bool:\n    \"\"\"\n    Return true if we can still make the minimum. So either:\n    - we have already selected at least the minimum, or\n    - the remaining number is at least as big as the number still required\n    \"\"\"\n    return self.selected &gt;= self.min_max.min or self.remaining &gt;= self.people_still_needed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample","title":"<code>WeightedSample</code>","text":"Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class WeightedSample:\n    def __init__(self, features: FeatureCollection) -&gt; None:\n        \"\"\"\n        This produces a set of lists of feature values for each feature.  Each value\n        is in the list `fv_minmax.max` times - so a random choice with represent the max.\n\n        So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n        \"black\" with max 2 we'd get:\n\n        [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n        Then making random choices from that list produces a weighted sample.\n        \"\"\"\n        self.weighted: dict[str, list[str]] = defaultdict(list)\n        for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n            self.weighted[feature_name] += [fvalue_name] * fv_minmax.max\n\n    def value_for(self, feature_name: str) -&gt; str:\n        # S311 is random numbers for crypto - but this is just for a sample file\n        return random_provider().choice(self.weighted[feature_name])\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample.__init__","title":"<code>__init__(features)</code>","text":"<p>This produces a set of lists of feature values for each feature.  Each value is in the list <code>fv_minmax.max</code> times - so a random choice with represent the max.</p> <p>So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and \"black\" with max 2 we'd get:</p> <p>[\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]</p> <p>Then making random choices from that list produces a weighted sample.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def __init__(self, features: FeatureCollection) -&gt; None:\n    \"\"\"\n    This produces a set of lists of feature values for each feature.  Each value\n    is in the list `fv_minmax.max` times - so a random choice with represent the max.\n\n    So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n    \"black\" with max 2 we'd get:\n\n    [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n    Then making random choices from that list produces a weighted sample.\n    \"\"\"\n    self.weighted: dict[str, list[str]] = defaultdict(list)\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n        self.weighted[feature_name] += [fvalue_name] * fv_minmax.max\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.iterate_select_collection","title":"<code>iterate_select_collection(select_collection)</code>","text":"<p>Helper function to iterate over select_collection.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def iterate_select_collection(select_collection: SelectCollection) -&gt; Generator[tuple[str, str, SelectCounts]]:\n    \"\"\"Helper function to iterate over select_collection.\"\"\"\n    for feature_name, feature_values in select_collection.items():\n        for value_name, fv_counts in feature_values.items():\n            yield feature_name, value_name, fv_counts\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.simple_add_selected","title":"<code>simple_add_selected(person_keys, people, features)</code>","text":"<p>Just add the person to the selected counts for the feature values for that person. Don't do the more complex handling of the full PeopleFeatures.add_selected()</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def simple_add_selected(person_keys: Iterable[str], people: People, features: SelectCollection) -&gt; None:\n    \"\"\"\n    Just add the person to the selected counts for the feature values for that person.\n    Don't do the more complex handling of the full PeopleFeatures.add_selected()\n    \"\"\"\n    for person_key in person_keys:\n        person = people.get_person_dict(person_key)\n        for feature_name in features:\n            feature_value = person[feature_name]\n            features[feature_name][feature_value].add_selected()\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People","title":"<code>People</code>","text":"Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>class People:\n    def __init__(self, columns_to_keep: list[str]) -&gt; None:\n        self._columns_to_keep = columns_to_keep\n        self._full_data: dict[str, dict[str, str]] = {}\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if not isinstance(other, self.__class__):\n            return False\n        return self._full_data == other._full_data and self._columns_to_keep == self._columns_to_keep\n\n    @property\n    def count(self) -&gt; int:\n        return len(self._full_data)\n\n    def __iter__(self) -&gt; Iterator[str]:\n        return iter(self._full_data)\n\n    def items(self) -&gt; ItemsView[str, dict[str, str]]:\n        return self._full_data.items()\n\n    def add(self, person_key: str, data: StrippedDict, features: FeatureCollection) -&gt; None:\n        person_full_data: dict[str, str] = {}\n        # get the feature values: these are the most important and we must check them\n        for feature_name, feature_values in features.items():\n            # check for input errors here - if it's not in the list of feature values...\n            # allow for some unclean data - at least strip empty space, but only if a str!\n            # (some values will can be numbers)\n            p_value = data[feature_name]\n            if p_value not in feature_values:\n                exc_msg = (\n                    f\"ERROR reading in people (read_in_people): \"\n                    f\"Person (id = {person_key}) has value '{p_value}' not in feature {feature_name}\"\n                )\n                raise errors.BadDataError(exc_msg)\n            person_full_data[feature_name] = p_value\n        # then get the other column values we need\n        # this is address, name etc that we need to keep for output file\n        # we don't check anything here - it's just for user convenience\n        for col in self._columns_to_keep:\n            person_full_data[col] = data[col]\n\n        # add all the data to our people object\n        self._full_data[person_key] = person_full_data\n\n    def remove(self, person_key: str) -&gt; None:\n        del self._full_data[person_key]\n\n    def remove_many(self, person_keys: Iterable[str]) -&gt; None:\n        for key in person_keys:\n            self.remove(key)\n\n    def get_person_dict(self, person_key: str) -&gt; dict[str, str]:\n        return self._full_data[person_key]\n\n    def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n        \"\"\"\n        Generates a dict with:\n        - keys: a tuple containing the address strings\n        - values: a list of person_key for each person at that address\n        \"\"\"\n        households = defaultdict(list)\n        for person_key, person in self._full_data.items():\n            address = tuple(person[col] for col in address_columns)\n            households[address].append(person_key)\n        return households\n\n    def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n        \"\"\"\n        Returns a list of person keys for all people who have an address matching\n        the address of the person passed in.\n        \"\"\"\n        person = self._full_data[person_key]\n        person_address = tuple(person[col] for col in address_columns)\n        for loop_key, loop_person in self._full_data.items():\n            if loop_key == person_key:\n                continue  # skip the person we've been given\n            if person_address == tuple(loop_person[col] for col in address_columns):\n                yield loop_key\n\n    def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n        \"\"\"\n        Find the nth person (1-indexed) in a specific feature category.\n\n        Args:\n            feature_name: Name of the feature (e.g., \"gender\")\n            feature_value: Value of the feature (e.g., \"male\")\n            position: 1-indexed position within the category\n\n        Returns:\n            Person key of the person at the specified position\n\n        Raises:\n            SelectionError: If no person is found at the specified position\n        \"\"\"\n        current_position = 0\n\n        for person_key, person_dict in self._full_data.items():\n            if person_dict[feature_name] == feature_value:\n                current_position += 1\n                if current_position == position:\n                    return person_key\n\n        # Should always find someone if position is valid\n        msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n        raise errors.SelectionError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.find_person_by_position_in_category","title":"<code>find_person_by_position_in_category(feature_name, feature_value, position)</code>","text":"<p>Find the nth person (1-indexed) in a specific feature category.</p> <p>Parameters:</p> Name Type Description Default <code>feature_name</code> <code>str</code> <p>Name of the feature (e.g., \"gender\")</p> required <code>feature_value</code> <code>str</code> <p>Value of the feature (e.g., \"male\")</p> required <code>position</code> <code>int</code> <p>1-indexed position within the category</p> required <p>Returns:</p> Type Description <code>str</code> <p>Person key of the person at the specified position</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If no person is found at the specified position</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n    \"\"\"\n    Find the nth person (1-indexed) in a specific feature category.\n\n    Args:\n        feature_name: Name of the feature (e.g., \"gender\")\n        feature_value: Value of the feature (e.g., \"male\")\n        position: 1-indexed position within the category\n\n    Returns:\n        Person key of the person at the specified position\n\n    Raises:\n        SelectionError: If no person is found at the specified position\n    \"\"\"\n    current_position = 0\n\n    for person_key, person_dict in self._full_data.items():\n        if person_dict[feature_name] == feature_value:\n            current_position += 1\n            if current_position == position:\n                return person_key\n\n    # Should always find someone if position is valid\n    msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n    raise errors.SelectionError(msg)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.households","title":"<code>households(address_columns)</code>","text":"<p>Generates a dict with: - keys: a tuple containing the address strings - values: a list of person_key for each person at that address</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n    \"\"\"\n    Generates a dict with:\n    - keys: a tuple containing the address strings\n    - values: a list of person_key for each person at that address\n    \"\"\"\n    households = defaultdict(list)\n    for person_key, person in self._full_data.items():\n        address = tuple(person[col] for col in address_columns)\n        households[address].append(person_key)\n    return households\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.matching_address","title":"<code>matching_address(person_key, address_columns)</code>","text":"<p>Returns a list of person keys for all people who have an address matching the address of the person passed in.</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n    \"\"\"\n    Returns a list of person keys for all people who have an address matching\n    the address of the person passed in.\n    \"\"\"\n    person = self._full_data[person_key]\n    person_address = tuple(person[col] for col in address_columns)\n    for loop_key, loop_person in self._full_data.items():\n        if loop_key == person_key:\n            continue  # skip the person we've been given\n        if person_address == tuple(loop_person[col] for col in address_columns):\n            yield loop_key\n</code></pre>"},{"location":"modules/#sortition_algorithms.settings.Settings","title":"<code>Settings</code>","text":"<p>Settings to use when selecting committees. Note that only the first two are required. A minimal example would be:</p> <p>Settings(id_column=\"my_id\", columns_to_keep=[\"name\", \"email\"])</p> Source code in <code>src/sortition_algorithms/settings.py</code> <pre><code>@define\nclass Settings:\n    \"\"\"\n    Settings to use when selecting committees. Note that only the first two are required.\n    A minimal example would be:\n\n    Settings(id_column=\"my_id\", columns_to_keep=[\"name\", \"email\"])\n    \"\"\"\n\n    # required\n    id_column: str = field(validator=validators.instance_of(str))\n    columns_to_keep: list[str] = field()\n\n    # fields with defaults\n    check_same_address: bool = field(validator=validators.instance_of(bool), default=False)\n    check_same_address_columns: list[str] = field(validator=check_columns_for_same_address, factory=list)\n    max_attempts: int = field(validator=validators.instance_of(int), default=100)\n    selection_algorithm: str = field(default=\"maximin\")\n    random_number_seed: int = field(validator=validators.instance_of(int), default=0)\n\n    @columns_to_keep.validator\n    def check_columns_to_keep(self, attribute: Any, value: Any) -&gt; None:\n        if not isinstance(value, list):\n            raise TypeError(\"columns_to_keep must be a LIST of strings\")\n        if not all(isinstance(element, str) for element in value):\n            raise TypeError(\"columns_to_keep must be a list of STRINGS\")\n\n    @selection_algorithm.validator\n    def check_selection_algorithm(self, attribute: Any, value: str) -&gt; None:\n        if value not in SELECTION_ALGORITHMS:\n            raise ValueError(f\"selection_algorithm {value} is not one of: {', '.join(SELECTION_ALGORITHMS)}\")\n\n    @property\n    def normalised_address_columns(self) -&gt; list[str]:\n        \"\"\"\n        Returns an empty list if address columns should not be checked (or if the columns\n        specified was an empty list). Otherwise return the columns. That way other code can\n        just check if the columns are empty rather than checking the bool separately.\n        \"\"\"\n        return self.check_same_address_columns if self.check_same_address else []\n\n    @property\n    def full_columns_to_keep(self) -&gt; list[str]:\n        \"\"\"\n        We always need to keep the address columns, so in case they are not listed in\n        self.columns_to_keep we have this property to have the combined list.\n        \"\"\"\n        extra_address_columns = [col for col in self.check_same_address_columns if col not in self.columns_to_keep]\n        return [*self.columns_to_keep, *extra_address_columns]\n\n    @classmethod\n    def load_from_file(\n        cls,\n        settings_file_path: Path,\n    ) -&gt; tuple[\"Settings\", RunReport]:\n        report = RunReport()\n        if not settings_file_path.is_file():\n            with open(settings_file_path, \"w\", encoding=\"utf-8\") as settings_file:\n                settings_file.write(DEFAULT_SETTINGS)\n            report.add_line(\n                f\"Wrote default settings to '{settings_file_path.absolute()}' \"\n                \"- if editing is required, restart this app.\"\n            )\n        with open(settings_file_path, \"rb\") as settings_file:\n            settings = tomllib.load(settings_file)\n        # you can't check an address if there is no info about which columns to check...\n        if settings[\"check_same_address\"] is False:\n            report.add_line(\n                \"WARNING: Settings file is such that we do NOT check if respondents have same address.\",\n                ReportLevel.IMPORTANT,\n            )\n            settings[\"check_same_address_columns\"] = []\n        return structure(settings, cls), report\n</code></pre>"},{"location":"modules/#sortition_algorithms.settings.Settings.full_columns_to_keep","title":"<code>full_columns_to_keep</code>  <code>property</code>","text":"<p>We always need to keep the address columns, so in case they are not listed in self.columns_to_keep we have this property to have the combined list.</p>"},{"location":"modules/#sortition_algorithms.settings.Settings.normalised_address_columns","title":"<code>normalised_address_columns</code>  <code>property</code>","text":"<p>Returns an empty list if address columns should not be checked (or if the columns specified was an empty list). Otherwise return the columns. That way other code can just check if the columns are empty rather than checking the bool separately.</p>"},{"location":"modules/#sortition_algorithms.utils.RandomProvider","title":"<code>RandomProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>This is something of a hack. Mostly we want to use the <code>secrets</code> module. But for repeatable testing we might want to set the random.seed sometimes.</p> <p>So we have a global <code>_random_provider</code> which can be switched between an instance of this class that uses the <code>secrets</code> module and an instance that uses <code>random</code> with a seed. The switch is done by the <code>set_random_provider()</code> function.</p> <p>Then every time we want some randomness, we call <code>random_provider()</code> to get the current version of the global.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class RandomProvider(ABC):\n    \"\"\"\n    This is something of a hack. Mostly we want to use the `secrets` module.\n    But for repeatable testing we might want to set the random.seed sometimes.\n\n    So we have a global `_random_provider` which can be switched between an\n    instance of this class that uses the `secrets` module and an instance that\n    uses `random` with a seed. The switch is done by the `set_random_provider()`\n    function.\n\n    Then every time we want some randomness, we call `random_provider()` to get\n    the current version of the global.\n    \"\"\"\n\n    @classmethod\n    @abstractmethod\n    def uniform(cls, lower: float, upper: float) -&gt; float: ...\n\n    @classmethod\n    @abstractmethod\n    def randbelow(cls, upper: int) -&gt; int: ...\n\n    @classmethod\n    @abstractmethod\n    def choice(cls, seq: \"SupportsLenAndGetItem[str]\") -&gt; str: ...\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport","title":"<code>RunReport</code>","text":"<p>A class to hold a report to show to the user at the end</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class RunReport:\n    \"\"\"A class to hold a report to show to the user at the end\"\"\"\n\n    def __init__(self) -&gt; None:\n        self._data: list[RunLineLevel | RunTable] = []\n\n    def __bool__(self) -&gt; bool:\n        \"\"\"\n        Basically, False is the report is empty, or True if there is some content. So you can do\n        things like\n\n        ```\n        if run_report:\n            print(f\"Run Report\\n\\n{run_report.as_text()}\")\n        ```\n        \"\"\"\n        return self.has_content()\n\n    def has_content(self) -&gt; bool:\n        \"\"\"\n        False is the report is empty, or True if there is some content. So you can do\n        things like\n\n        ```\n        if run_report.has_content():\n            print(f\"Run Report\\n\\n{run_report.as_text()}\")\n        ```\n        \"\"\"\n        return bool(self._data)\n\n    def add_line(self, line: str, level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n        \"\"\"\n        Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n        \"\"\"\n        self._data.append(RunLineLevel(line, level))\n\n    def add_line_and_log(self, line: str, log_level: int) -&gt; None:\n        \"\"\"\n        Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n        This method will also log the message to the `user_logger`. This message can be shown to the user as\n        the run is happening, so the user has feedback on what is going on while the run is in progress.\n\n        When generating the report we can skip those messages, to avoid duplication. But if the user_logger\n        has not been set up to be shown to the user during the run, we do want those messages to be in the\n        final report.\n        \"\"\"\n        self._data.append(RunLineLevel(line, ReportLevel.NORMAL, log_level))\n        user_logger.log(level=log_level, msg=line)\n\n    def add_lines(self, lines: Iterable[str], level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n        \"\"\"Add a line of text, and a level - we use the logging levels\"\"\"\n        for line in lines:\n            self._data.append(RunLineLevel(line, level))\n\n    def add_table(self, table_headings: list[str], table_data: list[list[str | int | float]]) -&gt; None:\n        self._data.append(RunTable(table_headings, table_data))\n\n    def add_report(self, other: \"RunReport\") -&gt; None:\n        self._data += other._data\n\n    def _element_to_text(self, element: RunLineLevel | RunTable, include_logged: bool) -&gt; str | None:\n        if isinstance(element, RunLineLevel):\n            # we might want to skip lines that were already logged\n            if include_logged or element.log_level == logging.NOTSET:\n                return element.line\n            else:\n                # sometimes we want empty strings for blank lines, so here we return None\n                # instead so the logged lines can be filtered out\n                return None\n        else:\n            table_text = tabulate(element.data, headers=element.headers, tablefmt=\"simple\")\n            # we want a blank line before and after the table.\n            return f\"\\n{table_text}\\n\"\n\n    def as_text(self, include_logged: bool = True) -&gt; str:\n        parts = [self._element_to_text(element, include_logged) for element in self._data]\n        return \"\\n\".join(p for p in parts if p is not None)\n\n    def _line_to_html(self, line_level: RunLineLevel) -&gt; str:\n        tags = {\n            ReportLevel.NORMAL: (\"\", \"\"),\n            ReportLevel.IMPORTANT: (\"&lt;b&gt;\", \"&lt;/b&gt;\"),\n            ReportLevel.CRITICAL: ('&lt;b style=\"color: red\"&gt;', \"&lt;/b&gt;\"),\n        }\n        start_tag, end_tag = tags[line_level.level]\n        escaped_line = html.escape(line_level.line)\n        return f\"{start_tag}{escaped_line}{end_tag}\"\n\n    def _element_to_html(self, element: RunLineLevel | RunTable, include_logged: bool) -&gt; str | None:\n        if isinstance(element, RunLineLevel):\n            if include_logged or element.log_level == logging.NOTSET:\n                return self._line_to_html(element)\n            else:\n                return None\n        else:\n            # TODO: add attributes to the `&lt;table&gt;` tag - the original code had:\n            # &lt;table border='1' cellpadding='5'&gt; - though do we really want that?\n            # Probably better to use CSS so others can style as they see fit.\n            return tabulate(element.data, headers=element.headers, tablefmt=\"html\")\n\n    def as_html(self, include_logged: bool = True) -&gt; str:\n        parts = [self._element_to_html(element, include_logged) for element in self._data]\n        return \"&lt;br /&gt;\\n\".join(p for p in parts if p is not None)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.__bool__","title":"<code>__bool__()</code>","text":"<pre><code>    Basically, False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report:\n        print(f\"Run Report\n</code></pre> <p>{run_report.as_text()}\")         ```</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def __bool__(self) -&gt; bool:\n    \"\"\"\n    Basically, False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report:\n        print(f\"Run Report\\n\\n{run_report.as_text()}\")\n    ```\n    \"\"\"\n    return self.has_content()\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_line","title":"<code>add_line(line, level=ReportLevel.NORMAL)</code>","text":"<p>Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_line(self, line: str, level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n    \"\"\"\n    Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n    \"\"\"\n    self._data.append(RunLineLevel(line, level))\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_line_and_log","title":"<code>add_line_and_log(line, log_level)</code>","text":"<p>Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.</p> <p>This method will also log the message to the <code>user_logger</code>. This message can be shown to the user as the run is happening, so the user has feedback on what is going on while the run is in progress.</p> <p>When generating the report we can skip those messages, to avoid duplication. But if the user_logger has not been set up to be shown to the user during the run, we do want those messages to be in the final report.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_line_and_log(self, line: str, log_level: int) -&gt; None:\n    \"\"\"\n    Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n    This method will also log the message to the `user_logger`. This message can be shown to the user as\n    the run is happening, so the user has feedback on what is going on while the run is in progress.\n\n    When generating the report we can skip those messages, to avoid duplication. But if the user_logger\n    has not been set up to be shown to the user during the run, we do want those messages to be in the\n    final report.\n    \"\"\"\n    self._data.append(RunLineLevel(line, ReportLevel.NORMAL, log_level))\n    user_logger.log(level=log_level, msg=line)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_lines","title":"<code>add_lines(lines, level=ReportLevel.NORMAL)</code>","text":"<p>Add a line of text, and a level - we use the logging levels</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_lines(self, lines: Iterable[str], level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n    \"\"\"Add a line of text, and a level - we use the logging levels\"\"\"\n    for line in lines:\n        self._data.append(RunLineLevel(line, level))\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.has_content","title":"<code>has_content()</code>","text":"<pre><code>    False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report.has_content():\n        print(f\"Run Report\n</code></pre> <p>{run_report.as_text()}\")         ```</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def has_content(self) -&gt; bool:\n    \"\"\"\n    False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report.has_content():\n        print(f\"Run Report\\n\\n{run_report.as_text()}\")\n    ```\n    \"\"\"\n    return bool(self._data)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.StrippedDict","title":"<code>StrippedDict</code>","text":"<p>Wraps a dict, and whenever we get a value from it, we convert to str and strip() whitespace</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class StrippedDict:\n    \"\"\"\n    Wraps a dict, and whenever we get a value from it, we convert to str and\n    strip() whitespace\n    \"\"\"\n\n    def __init__(self, raw_dict: Mapping[str, str] | Mapping[str, str | int]) -&gt; None:\n        self.raw_dict = raw_dict\n\n    def __getitem__(self, key: str) -&gt; str:\n        return strip_str_int(self.raw_dict[key])\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.default_logging_setup","title":"<code>default_logging_setup()</code>","text":"<p>Set both logger and user_logger to send output to stdout</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def default_logging_setup() -&gt; tuple[logging.Logger, logging.Logger]:\n    \"\"\"Set both logger and user_logger to send output to stdout\"\"\"\n    # we have two loggers\n    # - user_logger is used for messages that any user should see\n    # - logger is used for messages that only a developer or admin should need to see\n    user_logger = logging.getLogger(\"sortition_algorithms_user\")\n    user_logger.setLevel(logging.INFO)\n    if not user_logger.handlers:\n        # no set up has been done yet - so we do it here\n        user_logger.addHandler(logging.StreamHandler(sys.stdout))\n    logger = logging.getLogger(\"sortition_algorithms\")\n    logger.setLevel(logging.INFO)\n    if not logger.handlers:\n        # no set up has been done yet - so we do it here\n        # this logger just goes straight to stdout - no timestamps or anything\n        logger.addHandler(logging.StreamHandler(sys.stdout))\n    return user_logger, logger\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.override_logging_handlers","title":"<code>override_logging_handlers(user_logger_handlers, logger_handlers)</code>","text":"<p>Replace the default handlers with other ones</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def override_logging_handlers(\n    user_logger_handlers: list[logging.Handler], logger_handlers: list[logging.Handler]\n) -&gt; None:\n    \"\"\"Replace the default handlers with other ones\"\"\"\n    if user_logger_handlers:\n        _override_handlers_for(logging.getLogger(\"sortition_algorithms_user\"), user_logger_handlers)\n    if logger_handlers:\n        _override_handlers_for(logging.getLogger(\"sortition_algorithms\"), logger_handlers)\n</code></pre>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>This guide will get you up and running with sortition algorithms in just a few minutes.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install sortition-algorithms\n\n# Optional: Install CLI support\npip install 'sortition-algorithms[cli]'\n\n# Optional: Install leximin algorithm support (requires commercial/academic license)\npip install 'sortition-algorithms[gurobi]'\n</code></pre>"},{"location":"quickstart/#basic-concepts","title":"Basic Concepts","text":"<p>Before diving in, understand these key concepts:</p> <ul> <li>Sortition: Random selection that maintains demographic representativeness</li> <li>Features: Demographic characteristics (e.g., Gender, Age, Location)</li> <li>Quotas: Min/max targets for each demographic group</li> <li>Stratified Selection: Random selection that respects quotas</li> </ul>"},{"location":"quickstart/#your-first-selection","title":"Your First Selection","text":""},{"location":"quickstart/#1-prepare-your-data","title":"1. Prepare Your Data","text":"<p>You'll need two CSV files:</p> <p>demographics.csv (features with quotas):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,30,50\n</code></pre> <p>candidates.csv (people to select from):</p> <pre><code>id,Gender,Age,Location\nperson1,Male,18-30,Urban\nperson2,Female,31-50,Rural\nperson3,Male,51+,Urban\n...\n</code></pre>"},{"location":"quickstart/#2-run-your-first-selection","title":"2. Run Your First Selection","text":"<pre><code>from sortition_algorithms import (\n    run_stratification,\n    read_in_features,\n    read_in_people,\n    Settings\n)\n\n# Load your data\nsettings = Settings()\nfeatures = read_in_features(\"demographics.csv\")\npeople = read_in_people(\"candidates.csv\", settings, features)\n\n# Select a panel of 50 people\nsuccess, selected_panels, report = run_stratification(\n    features=features,\n    people=people,\n    number_people_wanted=50,\n    settings=settings\n)\n\nif success:\n    selected_people = selected_panels[0]  # frozenset of person IDs\n    print(f\"\u2705 Successfully selected {len(selected_people)} people\")\n    print(\"Selected IDs:\", list(selected_people)[:5], \"...\")\nelse:\n    print(\"\u274c Selection failed\")\n\n# Display the detailed report\nprint(report.as_text())\n</code></pre>"},{"location":"quickstart/#3-export-results","title":"3. Export Results","text":"<pre><code>from sortition_algorithms import selected_remaining_tables\n\n# Get formatted tables for export\nselected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panels[0], features, settings\n)\n\n# Save to CSV\nimport csv\n\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(selected_table)\n\nwith open(\"remaining.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(remaining_table)\n</code></pre>"},{"location":"quickstart/#using-the-command-line","title":"Using the Command Line","text":"<p>For quick operations, use the CLI:</p> <pre><code># CSV workflow\npython -m sortition_algorithms csv \\\n  --settings settings.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 50\n</code></pre>"},{"location":"quickstart/#configuration-with-settings","title":"Configuration with Settings","text":"<p>Customize behavior with a settings file:</p> <p>settings.toml:</p> <pre><code>id_column = \"my_id\"\n\n# Random seed for reproducible results (optional)\n# Set to zero to be properly random\nrandom_number_seed = 0\n\n# Ensure household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Selection algorithm: \"maximin\", \"leximin\", \"nash\", or \"legacy\"\nselection_algorithm = \"maximin\"\n\n# Maximum selection attempts\nmax_attempts = 10\n\n# Output columns to include\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <pre><code>settings, report = Settings.load_from_file(\"settings.toml\")\n</code></pre>"},{"location":"quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"quickstart/#working-with-google-sheets","title":"Working with Google Sheets","text":"<pre><code>from sortition_algorithms import GSheetDataSource, SelectionData\nfrom pathlib import Path\n\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"credentials.json\"),\n    gen_rem_tab=True,\n)\ndata_source.set_g_sheet_name(\"My Spreadsheet\")\nselect_data = SelectionData(data_source)\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(settings, features)\n</code></pre>"},{"location":"quickstart/#address-checking-for-household-diversity","title":"Address Checking for Household Diversity","text":"<pre><code># Ensure only one person per household is selected\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre>"},{"location":"quickstart/#multiple-selection-algorithms","title":"Multiple Selection Algorithms","text":"<pre><code># Maximin: Maximize the minimum probability\nsettings.selection_algorithm = \"maximin\"\n\n# Nash: Maximize the product of probabilities\nsettings.selection_algorithm = \"nash\"\n\n# Leximin: Lexicographic maximin (requires Gurobi)\nsettings.selection_algorithm = \"leximin\"\n</code></pre> <p>Read more about the algorithms.</p>"},{"location":"quickstart/#working-with-reports-and-logging","title":"Working with Reports and Logging","text":"<p>Most library functions return a <code>RunReport</code> object containing detailed status information:</p> <pre><code># Reports contain formatted messages and tables\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\nprint(\"Loading report:\")\nprint(report.as_text())\n\n# Get HTML for web display\nhtml_report = report.as_html()\n\n# Control whether to show messages that were already logged\nsummary = report.as_text(include_logged=False)\n</code></pre>"},{"location":"quickstart/#custom-logging-integration","title":"Custom Logging Integration","text":"<p>Redirect log messages for integration with your application:</p> <pre><code>from sortition_algorithms.utils import override_logging_handlers\nimport logging\n\n# Send logs to a file\nfile_handler = logging.FileHandler('sortition.log')\nfile_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n\noverride_logging_handlers([file_handler], [file_handler])\n\n# Now all library operations will log to the file\nsuccess, panels, report = run_stratification(features, people, 50, settings)\n</code></pre> <p>See the API Reference for complete logging documentation.</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>Core Concepts - Deep dive into sortition theory</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Advanced command line examples</li> <li>Data Adapters - CSV, Google Sheets, and custom adapters</li> <li>Advanced Usage - Complex scenarios and troubleshooting</li> </ul>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>\"Selection failed\" errors: Check that your quotas are achievable given your candidate pool. The sum of minimum quotas shouldn't exceed your target panel size.</p> <p>Import errors: Ensure you've installed the package correctly. For Gurobi features, you need a valid license.</p> <p>Empty results: Verify your CSV files have the correct format and column names match between demographics and candidates files.</p>"}]}