{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Sortition Algorithms Documentation","text":"<p>Welcome to the documentation for sortition-algorithms - a Python library for democratic lotteries and stratified random selection.</p>"},{"location":"#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling, sortition uses stratified random selection to ensure demographic balance while maintaining the randomness essential for fairness.</p> <p>This library provides algorithms for:</p> <ul> <li>Citizens' Assemblies: Representative groups for policy deliberation</li> <li>Deliberative Polls: Research panels reflecting population diversity</li> <li>Jury Selection: Fair selection respecting demographic quotas</li> <li>Participatory Democracy: Community engagement with guaranteed representation</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install the library\npip install sortition-algorithms\n\n# Basic selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"#documentation-guide","title":"Documentation Guide","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Quick Start Guide - Get up and running in minutes with practical examples</li> <li>Core Concepts - Understand sortition, features, quotas, and address checking</li> <li>Installation &amp; Setup - Install the library and optional dependencies</li> </ul>"},{"location":"#using-the-library","title":"Using the Library","text":"<ul> <li>CLI Usage - Command line interface for common operations</li> <li>Data Adapters - Working with CSV, Google Sheets, and custom data sources</li> <li>API Reference - Extended documentation of key functions and classes</li> <li>Modules - Complete documentation of all functions and classes</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Advanced Usage - Performance optimization, complex scenarios, and troubleshooting</li> <li>Algorithm Deep Dive - Understanding maximin, nash, and leximin algorithms</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#stratified-selection","title":"\ud83c\udfaf Stratified Selection","text":"<p>Ensures demographic representativeness while maintaining randomness - no more accidentally all-male or all-young panels.</p>"},{"location":"#household-diversity","title":"\ud83c\udfe0 Household Diversity","text":"<p>Optional address checking prevents multiple selections from the same household, ensuring geographic and social diversity.</p>"},{"location":"#multiple-algorithms","title":"\u2696\ufe0f Multiple Algorithms","text":"<p>Choose from maximin (default), nash, leximin, or legacy algorithms based on your fairness requirements.</p>"},{"location":"#flexible-data-sources","title":"\ud83d\udcca Flexible Data Sources","text":"<p>Works seamlessly with CSV files, Google Sheets, or custom data adapters for databases and APIs.</p>"},{"location":"#full-transparency","title":"\ud83d\udd0d Full Transparency","text":"<p>Detailed reporting shows exactly how quotas were met and provides audit trails for democratic accountability.</p>"},{"location":"#common-use-cases","title":"Common Use Cases","text":""},{"location":"#academic-research","title":"Academic Research","text":"<pre><code>from sortition_algorithms import run_stratification, Settings\n\n# Reproducible results for research\nsettings = Settings(\n    random_number_seed=42,\n    selection_algorithm=\"leximin\"  # Strongest fairness guarantees\n)\nsuccess, panels, msgs = run_stratification(features, people, 150, settings)\n</code></pre>"},{"location":"#citizen-assemblies","title":"Citizen Assemblies","text":"<pre><code># Ensure household diversity for community representation\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"],\n    selection_algorithm=\"maximin\"\n)\n</code></pre>"},{"location":"#large-scale-surveys","title":"Large-Scale Surveys","text":"<pre><code># Batch processing with CLI\npython -m sortition_algorithms csv \\\n  --features-csv national_demographics.csv \\\n  --people-csv voter_registry.csv \\\n  --number-wanted 2000 \\\n  --settings survey_config.toml\n</code></pre>"},{"location":"#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Best For Strengths Requirements Maximin General use, citizen assemblies Fair to minorities, intuitive None Nash Large diverse pools Balanced overall representation None Leximin Academic research Strongest fairness guarantees Gurobi license Legacy Historical compatibility Backwards compatible None <p>Read more about the algorithms.</p>"},{"location":"#real-world-applications","title":"Real-World Applications","text":""},{"location":"#government-democracy","title":"Government &amp; Democracy","text":"<ul> <li>Ireland's Citizens' Assembly: Used sortition for constitutional reform discussions</li> <li>French Citizens' Convention: 150 citizens selected to address climate change</li> <li>UK Citizens' Assemblies: Local and national policy deliberation</li> </ul>"},{"location":"#research-academia","title":"Research &amp; Academia","text":"<ul> <li>Deliberative Polling: Stanford's Center for Deliberative Democracy</li> <li>Policy Research: Representative samples for social science studies</li> <li>Market Research: Demographically balanced focus groups</li> </ul>"},{"location":"#community-engagement","title":"Community Engagement","text":"<ul> <li>Participatory Budgeting: Community members deciding local spending</li> <li>Planning Consultations: Representative input on development projects</li> <li>Local Government: Advisory panels for municipal decisions</li> </ul>"},{"location":"#support-community","title":"Support &amp; Community","text":""},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Troubleshooting Guide - Solutions to common problems</li> <li>GitHub Issues - Report bugs or request features</li> <li>Discussion Forum - Community support and questions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li>Contributing Guide - How to contribute to the project</li> <li>Development Setup - Set up your development environment</li> </ul>"},{"location":"#research-citations","title":"Research &amp; Citations","text":"<ul> <li>Core Paper - Academic foundation for the algorithms</li> <li>Related Research - Additional academic resources</li> </ul>"},{"location":"#license-usage","title":"License &amp; Usage","text":"<p>This library is open source under the GPL License. You're free to use it for:</p> <ul> <li>\u2705 Academic research and education</li> <li>\u2705 Government and civic applications</li> <li>\u2705 Commercial projects and consulting</li> <li>\u2705 Community organizing and activism</li> </ul> <p>Note: The leximin algorithm requires Gurobi, which has commercial licensing requirements. All other algorithms use open-source solvers.</p>"},{"location":"adapters/","title":"Data Adapters","text":"<p>Data adapters handle loading demographic data and candidate pools from various sources, and exporting selection results back to those sources. The library includes adapters for CSV files and Google Sheets, and you can write custom adapters for other data sources.</p>"},{"location":"adapters/#built-in-data-sources","title":"Built-in Data Sources","text":""},{"location":"adapters/#csvfiledatasource","title":"CSVFileDataSource","text":"<p>The most commonly used adapter for working with local CSV files.</p>"},{"location":"adapters/#basic-usage","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import CSVFileDataSource, SelectionData, Settings\nfrom pathlib import Path\n\ndata_source = CSVFileDataSource(\n    features_file=Path(\"demographics.csv\"),\n    people_file=Path(\"candidates.csv\"),\n    selected_file=Path(\"selected.csv\"),\n    remaining_file=Path(\"remaining.csv\"),\n)\nselect_data = SelectionData(data_source)\nsettings = Settings()\n\n# Load data\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(settings, features)\n\n# Do Selection\n# ...\n\n# Export results (after running selection)\ndata_source.output_selected_remaining(selected_rows, remaining_rows)\n</code></pre>"},{"location":"adapters/#working-with-string-data","title":"Working with String Data","text":"<p>For data already in memory:</p> <pre><code># Load from string content\nfeatures_csv = \"\"\"feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\"\"\"\n\npeople_csv = \"\"\"id,Name,Gender\np001,Alice,Female\np002,Bob,Male\"\"\"\n\ndata_source = CSVStringDataSource(features_csv, people_csv)\nselect_data = SelectionData(data_source)\n\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(Settings(), features)\n</code></pre>"},{"location":"adapters/#full-csv-workflow-example","title":"Full CSV Workflow Example","text":"<p>This time for replacements, so we refer to the already selected people.</p> <pre><code>from sortition_algorithms import (\n    CSVFileDataSource, run_stratification, selected_remaining_tables, SelectionData, Settings\n)\nfrom pathlib import Path\nimport csv\n\ndef csv_selection_workflow():\n    # Initialize\n    data_source = CSVFileDataSource(\n        features_file=Path(\"demographics.csv\"),\n        people_file=Path(\"candidates.csv\"),\n        already_selected_file=Path(\"selected.csv\"),\n        selected_file=Path(\"replacements.csv\"),\n        remaining_file=Path(\"remaining.csv\"),\n    )\n    select_data = SelectionData(data_source)\n    settings = Settings()\n    number_wanted=100\n\n    # Load data\n    features, report = select_data.load_features(number_wanted)\n    print(report.as_text())\n    people, report = select_data.load_people(settings, features)\n    print(report.as_text())\n    already_selected, report = select_data.load_already_selected(settings)\n    print(report.as_text())\n\n    # Run selection\n    success, panels, msgs = run_stratification(\n        features, people, number_wanted, settings, already_selected=already_selected\n    )\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings, already_selected=already_selected\n        )\n\n        # Export results\n        data_source.output_selected_remaining(selected_rows, remaining_rows)\n        print(f\"Selected {len(panels[0])} people successfully\")\n    else:\n        print(\"Selection failed\")\n        print(\"\\n\".join(msgs))\n</code></pre>"},{"location":"adapters/#gsheetdatasource","title":"GSheetDataSource","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"adapters/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials and download JSON key</li> <li>Share Spreadsheet: Share your spreadsheet with the service account email address</li> </ol>"},{"location":"adapters/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from sortition_algorithms import GSheetDataSource, SelectionData, Settings\nfrom pathlib import Path\n\n# Initialize with credentials\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"/secure/path/credentials.json\"),\n    gen_rem_tab=True,  # Generate remaining tab\n)\ndata_source.set_g_sheet_name(\"My Spreadsheet\")\nselect_data = SelectionData(data_source)\n\n# Load data from Google Sheet\nfeatures, report = select_data.load_features()\nprint(report.as_text())\n\npeople, report = select_data.load_people(settings, features)\nprint(report.as_text())\n\n# Here, do selection\n\n# Configure output tabs\ndata_source.selected_tab_name_stub = \"Selected Panel\"\ndata_source.remaining_tab_name_stub = \"Reserve Pool\"\n\n# Export results (after running selection)\nselect_data.output_selected_remaining(selected_rows, remaining_rows, settings)\n</code></pre>"},{"location":"adapters/#full-google-sheets-workflow","title":"Full Google Sheets Workflow","text":"<p>This time for replacements, so we refer to the already selected people.</p> <pre><code>from sortition_algorithms import GSheetDataSource, SelectionData, run_stratification, selected_remaining_tables, Settings\nfrom pathlib import Path\n\ndef gsheet_selection_workflow():\n    # Initialize\n    data_source = GSheetDataSource(\n        feature_tab_name=\"Demographics\",\n        people_tab_name=\"Candidates\",\n        already_selected_tab_name=\"Selected\",\n        auth_json_path=Path(\"/secure/path/credentials.json\"),\n        gen_rem_tab=True,  # Generate remaining tab\n    )\n    data_source.set_g_sheet_name(\"My Spreadsheet\")\n    select_data = SelectionData(data_source)\n    settings = Settings()\n    number_wanted = 120\n\n    # Load data\n    adapter.set_g_sheet_name(\"Citizen Panel 2024\")\n    features, report = adapter.load_features(number_wanted)\n    if features is None:\n        print(\"Failed to load features:\", \"\\n\".join(msgs))\n        return\n\n    people, report = adapter.load_people(settings, features)\n    if people is None:\n        print(\"Failed to load people:\", \"\\n\".join(msgs))\n        return\n\n    already_selected, report = adapter.load_already_selected(settings)\n\n    # Run selection\n    success, panels, report = run_stratification(\n        features, people, number_wanted, settings, already_selected=already_selected\n    )\n\n    if success:\n        # Format results\n        selected_table, remaining_table, _ = selected_remaining_tables(\n            people, panels[0], features, settings, already_selected=already_selected\n        )\n\n        # Configure output\n        adapter.selected_tab_name = \"Selected Panel\"\n        adapter.remaining_tab_name = \"Reserve Pool\"\n\n        # Export to Google Sheets\n        dupes, _ = adapter.output_selected_remaining(selected_table, remaining_table, settings)\n\n        print(f\"Selected {len(panels[0])} people successfully\")\n        if dupes:\n            print(f\"Warning: {len(dupes)} people in remaining pool share addresses\")\n    else:\n        print(\"Selection failed:\", report.as_text())\n</code></pre>"},{"location":"adapters/#google-sheets-data-format","title":"Google Sheets Data Format","text":"<p>Your spreadsheet should be structured as follows:</p> <p>Demographics Tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Note that you can have other columns on the tab - the features import code will ignore them.</p> <p>Candidates Tab:</p> id Name Email Gender Age Location Address Postcode p001 Alice Smith alice@email.com Female 18-30 Urban 123 Main St 12345 p002 Bob Jones bob@email.com Male 31-50 Rural 456 Oak Ave 67890"},{"location":"adapters/#writing-custom-data-source-classes","title":"Writing custom Data Source classes","text":"<p>You can create custom data source classes for other data sources like Excel files, SQL databases, or APIs.</p>"},{"location":"adapters/#abstractdatasource","title":"AbstractDataSource","text":"<p>All data source classes should inherit from <code>AbstractDataSource</code> - and implement the methods it defines:</p> <pre><code>from sortition_algorithms import RunReport\n\nclass AbstractDataSource(abc.ABC):\n    @abc.abstractmethod\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]: ...\n\n    @abc.abstractmethod\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]: ...\n\n    @abc.abstractmethod\n    def write_selected(self, selected: list[list[str]]) -&gt; None: ...\n\n    @abc.abstractmethod\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None: ...\n\n    @abc.abstractmethod\n    def highlight_dupes(self, dupes: list[int]) -&gt; None: ...\n</code></pre>"},{"location":"adapters/#example-excel-data-source","title":"Example: Excel Data Source","text":"<p>Here's a complete example of an Excel adapter using the <code>openpyxl</code> library:</p> <pre><code>from pathlib import Path\nfrom typing import Any\nimport openpyxl\nfrom openpyxl.worksheet.worksheet import Worksheet\n\nfrom sortition_algorithms import AbstractDataSource, FeatureCollection, People, RunReport, SelectionError, Settings\nfrom sortition_algorithms.features import read_in_features\nfrom sortition_algorithms.people import read_in_people\n\nclass ExcelDataSource(AbstractDataSource):\n    \"\"\"DataSource for Excel files using openpyxl.\"\"\"\n\n    def __init__(self, excel_file: Path, feature_tab_name: str, people_tab_name: str) -&gt; None:\n        self.excel_file = excel_file\n        self.feature_tab_name = feature_tab_name\n        self.people_tab_name = people_tab_name\n        self.selected_tab_name = \"selected\"\n        self.remaining_tab_name = \"remaining\"\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        \"\"\"Load features data from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(self.excel_file)\n\n        if self.feature_tab_name not in workbook.sheetnames:\n            msg = f\"Sheet '{self.feature_tab_name}' not found in {excel_file}\"\n            report.add_line(msg)\n            raise SelectionError(msg, report)\n\n        sheet = workbook[self.feature_tab_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n        yield headers, data\n        # close the workbook\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        \"\"\"Load people from Excel file.\"\"\"\n        workbook = openpyxl.load_workbook(excel_file)\n\n        if self.people_tab_name not in workbook.sheetnames:\n            msg = f\"Sheet '{self.people_tab_name}' not found in {excel_file}\"\n            report.add_line(msg)\n            raise SelectionError(msg, report)\n\n        sheet = workbook[self.people_tab_name]\n\n        # Read header row\n        headers = [cell.value for cell in sheet[1]]\n\n        # Read data rows\n        data = []\n        for row in sheet.iter_rows(min_row=2, values_only=True):\n            if any(cell is not None for cell in row):  # Skip empty rows\n                row_dict = {headers[i]: str(row[i]) if row[i] is not None else \"\"\n                           for i in range(len(headers))}\n                data.append(row_dict)\n\n        yield headers, data\n\n    def write_selected(self, selected: list[list[str]]) -&gt; None:\n        selected_ws = workbook.create_sheet(self.selected_tab_name)\n        self._write_data_to_sheet(selected_ws, selected_rows)\n        workbook.save(self.excel_file)\n\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None:\n        remaining_ws = workbook.create_sheet(self.remaining_tab_name)\n        self._write_data_to_sheet(remaining_ws, remaining_rows)\n        workbook.save(self.excel_file)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        # not implemented\n        pass\n\n    def _write_data_to_sheet(self, sheet: Worksheet, data: list[list[str]]) -&gt; None:\n        \"\"\"Write data rows to worksheet.\"\"\"\n        for row_idx, row_data in enumerate(data, 1):\n            for col_idx, cell_value in enumerate(row_data, 1):\n                sheet.cell(row=row_idx, column=col_idx, value=cell_value)\n\n        # Style header row\n        if data:\n            for cell in sheet[1]:\n                cell.font = openpyxl.styles.Font(bold=True)\n                cell.fill = openpyxl.styles.PatternFill(\"solid\", fgColor=\"CCCCCC\")\n\n# Usage example\ndef excel_workflow():\n    data_source = ExcelDataSource(\n        Path(\"selection_data.xlsx\"),\n        \"Demographics\",\n        \"Candidates\",\n    )\n    select_data = SelectionData(data_source)\n    settings = Settings()\n\n    # Load data\n    features, _ = select_data.load_features()\n    people, report = select_data.load_people(settings, features)\n\n    # Run selection (assuming you have the selection logic)\n    success, panels, report = run_stratification(...)\n\n    # Export results\n    select_data.output_selected_remaining(selected_table, remaining_table, settings)\n</code></pre>"},{"location":"adapters/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Command line interface</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"advanced/","title":"Advanced Usage","text":"<p>This guide covers complex scenarios, optimization techniques, troubleshooting strategies, and advanced usage patterns for the sortition algorithms library.</p>"},{"location":"advanced/#algorithm-deep-dive","title":"Algorithm Deep Dive","text":"<p>Read more about the algorithms.</p>"},{"location":"advanced/#complex-scenarios","title":"Complex Scenarios","text":""},{"location":"advanced/#weighted-selection","title":"Weighted Selection","text":"<p>For scenarios where some demographic groups need stronger representation:</p> <pre><code>def create_weighted_features():\n    \"\"\"Create features with weighted quotas for underrepresented groups.\"\"\"\n\n    # Standard proportional representation\n    base_features = [\n        (\"Gender\", \"Male\", 45, 55),\n        (\"Gender\", \"Female\", 45, 55),\n        (\"Age\", \"18-30\", 20, 30),\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 25, 35),\n    ]\n\n    # Weighted to ensure representation of underrepresented groups\n    weighted_features = [\n        (\"Gender\", \"Male\", 40, 50),       # Slightly reduce majority\n        (\"Gender\", \"Female\", 45, 55),     # Maintain strong representation\n        (\"Gender\", \"Non-binary\", 5, 10),  # Ensure inclusion\n        (\"Age\", \"18-30\", 25, 35),         # Boost young representation\n        (\"Age\", \"31-50\", 35, 45),\n        (\"Age\", \"51+\", 20, 30),\n    ]\n\n    return create_features_from_list(weighted_features)\n\ndef create_features_from_list(feature_list):\n    \"\"\"Helper to create FeatureCollection from tuples.\"\"\"\n    import csv\n    from io import StringIO\n\n    # Convert to CSV format\n    csv_content = \"feature,value,min,max\\n\"\n    for feature, value, min_val, max_val in feature_list:\n        csv_content += f\"{feature},{value},{min_val},{max_val}\\n\"\n\n    # Use CSV adapter to create FeatureCollection\n    data_source = CSVStringDataSource(csv_content, \"\")\n    select_data = SelectionData(data_source)\n    features, msgs = data_source.load_features()\n    return features\n</code></pre>"},{"location":"advanced/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"advanced/#common-error-patterns","title":"Common Error Patterns","text":""},{"location":"advanced/#infeasible-quotas","title":"Infeasible Quotas","text":"<p>Symptoms: <code>InfeasibleQuotasError</code> exception</p> <p>Diagnosis:</p> <pre><code>def diagnose_quota_feasibility(features: FeatureCollection, panel_size: int):\n    \"\"\"Analyze why quotas might be infeasible.\"\"\"\n\n    issues = []\n\n    max_value_of_minimums = minimum_selection(features)\n    if max_value_of_minimums &gt; panel_size:\n        issues.append(f\"Max value of minimums ({max_value_of_minimums}) exceeds panel size ({panel_size})\")\n\n    min_value_of_maximums = maximum_selection(features)\n    if min_value_of_maximums &lt; panel_size:\n        issues.append(f\"Min value of maximums ({min_value_of_maximums}) is less than panel size ({panel_size})\")\n\n    # Check for impossible individual quotas\n    for feature_name in features:\n        sum_of_min = sum(c.min for c in features[feature_name].values())\n        sum_of_max = sum(c.max for c in features[feature_name].values())\n\n        if sum_of_min &gt; panel_size:\n            issues.append(f\"{feature_name} sum of minimum ({sum_of_min}) exceeds panel size\")\n\n        if sum_of_max &lt; panel_size:\n            issues.append(f\"{feature_name} sum of maximum ({sum_of_max}) is less than panel size\")\n\n    for feature_name, value_name, fv_minmax in iterate_feature_collection(features):\n        if fv_minmax.max &lt; fv_minmax.min:\n            issues.append(f\"{feature_name}:{value_name} max ({fv_minmax.max}) &lt; min ({fv_minmax.min})\")\n\n    return issues\n\ndef suggest_quota_fixes(features: FeatureCollection, people: People, panel_size: int):\n    \"\"\"Suggest quota adjustments to make selection feasible.\"\"\"\n\n    suggestions = []\n\n    # Count available people per category\n    availability = {}\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n        for feature_name in features:\n            value = person_data.get(feature_name, \"Unknown\")\n            key = (feature_name, value)\n            availability[key] = availability.get(key, 0) + 1\n\n    # Suggest adjustments\n    for feature_name, value_name, fv_minmax in iterate_feature_collection(features):\n        available = availability.get((feature_name, value_name), 0)\n\n        if fv_minmax.min &gt; available:\n            suggestions.append(\n                f\"Reduce {feature_name}:{value_name} minimum from {fv_minmax.min} to {available} \"\n                f\"(only {available} candidates available)\"\n            )\n\n    return suggestions\n</code></pre> <p>Solutions:</p> <ol> <li>Reduce minimum quotas: Lower the minimum requirements</li> <li>Increase maximum quotas: Allow more flexibility</li> <li>Expand candidate pool: Recruit more candidates in underrepresented categories</li> <li>Adjust panel size: Sometimes a smaller or larger panel works better</li> </ol>"},{"location":"advanced/#data-quality-issues","title":"Data Quality Issues","text":"<p>Symptoms: Unexpected selection results, warnings about data inconsistencies</p> <p>Diagnosis:</p> <pre><code>from collection import Counter, defaultdict\n\ndef audit_data_quality(people: People, features: FeatureCollection):\n    \"\"\"Comprehensive data quality audit.\"\"\"\n\n    issues = []\n\n    # Check for missing demographic data\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature in features:\n            if feature not in person_data or not person_data[feature].strip():\n                issues.append(f\"Person {person_id} missing {feature}\")\n\n    # Check for unexpected feature values\n    expected_values = {name: set(features[name].keys()]) for name in features}\n\n    for person_id in people:\n        person_data = people.get_person_dict(person_id)\n\n        for feature_name, values in expected_values.items():\n            actual_val = person_data.get(feature_name, \"\")\n            if actual_val and actual_val not in values:\n                issues.append(\n                    f\"Person {person_id} has unexpected {feature_name} value: '{actual_val}'\"\n                )\n\n    # Check for duplicate IDs\n    count_ids = Counter(people)\n    for person_id, count in count_ids.items():\n        if count &gt; 1:\n            issues.append(f\"Duplicate person ID: {person_id}\")\n\n    return issues\n\ndef clean_data_automatically(people_data: list[dict], features: FeatureCollection):\n    \"\"\"Automatically clean common data issues.\"\"\"\n\n    cleaned_data = []\n\n    for person in people_data:\n        cleaned_person = {}\n\n        for key, value in person.items():\n            # Strip whitespace\n            if isinstance(value, str):\n                value = value.strip()\n\n            # Standardize case for categorical variables\n            if key in features:\n                # Convert to title case for consistency\n                value = value.title() if value else \"\"\n\n            cleaned_person[key] = value\n\n        # Skip records with missing required data\n        required_fields = [\"id\"] + list(features.keys())\n        if all(cleaned_person.get(field) for field in required_fields):\n            cleaned_data.append(cleaned_person)\n\n    return cleaned_data\n</code></pre>"},{"location":"advanced/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"advanced/#development-best-practices","title":"Development Best Practices","text":"<ol> <li>Always validate inputs: Check data quality before running selections</li> <li>Use appropriate random seeds: Fixed seeds for testing, None for production</li> <li>Handle errors gracefully: Provide meaningful error messages and recovery options</li> <li>Test with edge cases: Small pools, extreme quotas, missing data</li> <li>Monitor performance: Track memory usage and runtime for large datasets</li> </ol>"},{"location":"advanced/#production-best-practices","title":"Production Best Practices","text":"<ol> <li>Implement comprehensive logging: Track all selection attempts and results</li> <li>Set up monitoring and alerting: Detect failures and performance issues</li> <li>Use version control for configurations: Track changes to quotas and settings</li> <li>Backup candidate data: Ensure data persistence and recoverability</li> <li>Document selection criteria: Maintain audit trails for transparency</li> </ol>"},{"location":"advanced/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand sortition fundamentals</li> <li>API Reference - Complete function documentation</li> <li>Data Adapters - Working with different data sources</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete documentation for all public functions and classes in the sortition-algorithms library.</p>"},{"location":"api-reference/#core-functions","title":"Core Functions","text":""},{"location":"api-reference/#run_stratification","title":"run_stratification()","text":"<p>Main function for running stratified random selection with retry logic.</p> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    test_selection: bool = False,\n    number_selections: int = 1,\n    already_selected: People | None = None,\n) -&gt; tuple[bool, list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features</code>: FeatureCollection with min/max quotas for each feature value</li> <li><code>people</code>: People object containing the pool of candidates</li> <li><code>number_people_wanted</code>: Desired size of the panel</li> <li><code>settings</code>: Settings object containing configuration</li> <li><code>test_selection</code>: If True, don't randomize (for testing only)</li> <li><code>number_selections</code>: Number of panels to return (usually 1)</li> <li><code>already_selected</code>: People selected in a previous round of selection</li> </ul> <p>Returns:</p> <ul> <li><code>success</code>: Whether selection succeeded within max attempts</li> <li><code>selected_committees</code>: List of committees (frozensets of person IDs)</li> <li><code>output_lines</code>: Debug and status messages</li> </ul> <p>Raises:</p> <ul> <li><code>InfeasibleQuotasError</code>: If quotas cannot be satisfied</li> <li><code>SelectionError</code>: For various failure cases</li> <li><code>ValueError</code>: For invalid parameters</li> <li><code>RuntimeError</code>: If required solver is not available</li> </ul> <p>Example:</p> <pre><code>success, panels, messages = run_stratification(\n    features, people, 100, Settings()\n)\nif success:\n    selected_people = panels[0]  # frozenset of IDs\n</code></pre>"},{"location":"api-reference/#find_random_sample","title":"find_random_sample()","text":"<p>Lower-level algorithm function for finding random committees.</p> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n) -&gt; tuple[list[frozenset[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>selection_algorithm</code>: One of \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li>Other parameters same as <code>run_stratification()</code></li> </ul> <p>Returns:</p> <ul> <li><code>committee_lottery</code>: List of committees (may contain duplicates)</li> <li><code>output_lines</code>: Debug strings</li> </ul> <p>Example:</p> <pre><code>committees, messages = find_random_sample(\n    features, people, 50, settings, \"nash\"\n)\n</code></pre>"},{"location":"api-reference/#selected_remaining_tables","title":"selected_remaining_tables()","text":"<p>Format selection results for export to CSV or other formats.</p> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n    already_selected: People | None = None,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>full_people</code>: Original People object</li> <li><code>people_selected</code>: Single frozenset of selected person IDs</li> <li><code>features</code>: FeatureCollection used for selection</li> <li><code>settings</code>: Settings object</li> <li><code>already_selected</code>: People selected in a previous round of selection</li> </ul> <p>Returns:</p> <ul> <li><code>selected_rows</code>: Table with selected people data</li> <li><code>remaining_rows</code>: Table with remaining people data</li> <li><code>output_lines</code>: Additional information messages</li> </ul> <p>Example:</p> <pre><code>selected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panel, features, settings\n)\n\n# Write to CSV\nimport csv\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    csv.writer(f).writerows(selected_table)\n</code></pre>"},{"location":"api-reference/#data-loading-functions","title":"Data Loading Functions","text":""},{"location":"api-reference/#read_in_features","title":"read_in_features()","text":"<p>Load feature definitions from a CSV file.</p> <pre><code>def read_in_features(features_file: str | Path) -&gt; FeatureCollection:\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_file</code>: Path to CSV file with feature definitions</li> </ul> <p>Expected CSV format:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\n</code></pre> <p>Returns:</p> <ul> <li><code>FeatureCollection</code>: Nested dict containing all features and quotas</li> </ul> <p>Example:</p> <pre><code>features = read_in_features(\"demographics.csv\")\n</code></pre>"},{"location":"api-reference/#read_in_people","title":"read_in_people()","text":"<p>Load candidate pool from a CSV file.</p> <pre><code>def read_in_people(\n    people_file: str | Path,\n    settings: Settings,\n    features: FeatureCollection\n) -&gt; People:\n</code></pre> <p>Parameters:</p> <ul> <li><code>people_file</code>: Path to CSV file with candidate data</li> <li><code>settings</code>: Settings object for configuration</li> <li><code>features</code>: FeatureCollection for validation</li> </ul> <p>Expected CSV format:</p> <pre><code>id,Name,Gender,Age,Email\np001,Alice,Female,18-30,alice@example.com\np002,Bob,Male,31-50,bob@example.com\n</code></pre> <p>Returns:</p> <ul> <li><code>People</code>: Object containing candidate pool</li> </ul> <p>Example:</p> <pre><code>people = read_in_people(\"candidates.csv\", settings, features)\n</code></pre>"},{"location":"api-reference/#settings-class","title":"Settings Class","text":"<p>Configuration object for customizing selection behavior.</p> <pre><code>class Settings:\n    def __init__(\n        self,\n        random_number_seed: int | None = None,\n        check_same_address: bool = False,\n        check_same_address_columns: list[str] | None = None,\n        selection_algorithm: str = \"maximin\",\n        max_attempts: int = 10,\n        columns_to_keep: list[str] | None = None,\n        id_column: str = \"id\",\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>random_number_seed</code>: Fixed seed for reproducible results (None or 0 = random)</li> <li><code>check_same_address</code>: Enable household diversity checking</li> <li><code>check_same_address_columns</code>: Columns that define an address</li> <li><code>selection_algorithm</code>: \"maximin\", \"leximin\", \"nash\", or \"legacy\"</li> <li><code>max_attempts</code>: Maximum selection retry attempts</li> <li><code>columns_to_keep</code>: Additional columns to include in output</li> <li><code>id_column</code>: Name of the ID column in people data</li> </ul> <p>Class Methods:</p>"},{"location":"api-reference/#settingsload_from_file","title":"Settings.load_from_file()","text":"<pre><code>@classmethod\ndef load_from_file(\n    cls,\n    settings_file_path: Path\n) -&gt; tuple[Settings, RunReport]:\n</code></pre> <p>Load settings from a TOML file.</p> <p>Example settings.toml:</p> <pre><code>id_column = \"my_id\"\nrandom_number_seed = 0\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\nselection_algorithm = \"maximin\"\nmax_attempts = 10\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <p>Returns:</p> <ul> <li><code>Settings</code>: Configured settings object</li> <li><code>str</code>: Status message</li> </ul> <p>Example:</p> <pre><code>settings, report = Settings.load_from_file(Path(\"config.toml\"))\nprint(report.as_text())  # \"Settings loaded from config.toml\"\n</code></pre>"},{"location":"api-reference/#runreport-class","title":"RunReport Class","text":"<p>The <code>RunReport</code> class provides structured reporting for sortition operations. Most library functions return a <code>RunReport</code> alongside their main results, containing status messages, warnings, and formatted output.</p> <pre><code>class RunReport:\n    def as_text(self, include_logged: bool = True) -&gt; str\n    def as_html(self, include_logged: bool = True) -&gt; str\n</code></pre>"},{"location":"api-reference/#output-methods","title":"Output Methods","text":""},{"location":"api-reference/#as_text","title":"as_text()","text":"<p>Returns the report as formatted plain text.</p> <p>Parameters:</p> <ul> <li><code>include_logged</code>: If <code>False</code>, excludes messages that were already sent to the logging system (useful when the user has already seen logged messages during execution)</li> </ul>"},{"location":"api-reference/#as_html","title":"as_html()","text":"<p>Returns the report as HTML with styling for different message importance levels (normal, important, critical).</p> <p>Parameters:</p> <ul> <li><code>include_logged</code>: Same as <code>as_text()</code></li> </ul>"},{"location":"api-reference/#extracting-errors","title":"Extracting Errors","text":"<p>You can call <code>last_error()</code> to extract the last error that was added to the report. It will return <code>None</code> if no error was added.</p>"},{"location":"api-reference/#usage-pattern","title":"Usage Pattern","text":"<p>Most library functions return a tuple containing results and a <code>RunReport</code>:</p> <pre><code># Loading data\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\nprint(report.as_text())\n\npeople, report = adapter.load_people_from_file(Path(\"people.csv\"), settings, features)\nprint(report.as_text())\n\n# Running selection\nsuccess, panels, report = run_stratification(features, people, 100, settings)\n\n# Display as text\nprint(report.as_text())\n\n# Or generate HTML for web display\nhtml_content = report.as_html()\n\n# Exclude already-logged messages if user saw them during execution\nsummary = report.as_text(include_logged=False)\n\n# Extract the last error added to the report (or None if there was no error)\nerror = report.last_error()\n</code></pre>"},{"location":"api-reference/#logging-integration","title":"Logging Integration","text":"<p>Some report messages are also sent to the logging system in real-time. If your application displays log messages to users during execution, you can use <code>include_logged=False</code> to avoid showing duplicate messages in the final report.</p>"},{"location":"api-reference/#custom-logging","title":"Custom Logging","text":"<p>The library uses Python's standard logging system with two loggers:</p> <ul> <li><code>sortition_algorithms_user</code> - Messages intended for end users</li> <li><code>sortition_algorithms</code> - Debug messages for developers</li> </ul>"},{"location":"api-reference/#setting-up-custom-log-handlers","title":"Setting Up Custom Log Handlers","text":"<p>You can redirect logging output using <code>override_logging_handlers()</code>:</p> <pre><code>from sortition_algorithms.utils import override_logging_handlers\nimport logging\n\n# Create custom handlers\nuser_handler = logging.StreamHandler()\nuser_handler.setFormatter(logging.Formatter('USER: %(message)s'))\n\ndebug_handler = logging.FileHandler('debug.log')\ndebug_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n\n# Apply custom handlers\noverride_logging_handlers([user_handler], [debug_handler])\n</code></pre>"},{"location":"api-reference/#custom-loghandler-example","title":"Custom LogHandler Example","text":"<p>Here's a custom handler that captures messages for further processing:</p> <pre><code>import logging\nfrom typing import List\n\nclass MessageCollector(logging.Handler):\n    \"\"\"Custom handler that collects log messages in memory.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.messages: List[str] = []\n\n    def emit(self, record: logging.LogRecord) -&gt; None:\n        \"\"\"Called for each log message.\"\"\"\n        msg = self.format(record)\n        self.messages.append(msg)\n\n    def get_messages(self) -&gt; List[str]:\n        \"\"\"Return all collected messages.\"\"\"\n        return self.messages.copy()\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear collected messages.\"\"\"\n        self.messages.clear()\n\n# Usage\ncollector = MessageCollector()\noverride_logging_handlers([collector], [collector])\n\n# Run sortition operations\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\n\n# Get messages that were logged during execution\nlogged_messages = collector.get_messages()\nprint(\"Logged:\", logged_messages)\n\n# Get final report (excluding already-logged messages)\nfinal_report = report.as_text(include_logged=False)\nprint(\"Additional report:\", final_report)\n</code></pre>"},{"location":"api-reference/#available-logging-functions","title":"Available Logging Functions","text":"<pre><code>from sortition_algorithms.utils import override_logging_handlers, set_log_level\n\ndef override_logging_handlers(\n    user_logger_handlers: list[logging.Handler],\n    logger_handlers: list[logging.Handler]\n) -&gt; None\n\ndef set_log_level(log_level: int) -&gt; None\n</code></pre>"},{"location":"api-reference/#data-sources","title":"Data Sources","text":"<p>The library uses a data source pattern for loading and saving data. All data sources implement the <code>AbstractDataSource</code> interface and are used via the <code>SelectionData</code> wrapper class.</p>"},{"location":"api-reference/#selectiondata","title":"SelectionData","text":"<p>High-level wrapper class that provides a unified interface for loading data and outputting results, regardless of the underlying data source.</p> <pre><code>class SelectionData:\n    def __init__(\n        self,\n        data_source: AbstractDataSource,\n        gen_rem_tab: bool = True\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>data_source</code>: Any object implementing AbstractDataSource (e.g., CSVFileDataSource, GSheetDataSource)</li> <li><code>gen_rem_tab</code>: If True, generate a \"remaining\" output table; if False, only output selected</li> </ul> <p>Methods:</p> <pre><code>def load_features(self, number_to_select: int = 0) -&gt; tuple[FeatureCollection, RunReport]:\n    # Load feature definitions from data source\n\ndef load_people(\n    self, settings: Settings, features: FeatureCollection\n) -&gt; tuple[People, RunReport]:\n    # Load people data from data source\n\ndef output_selected_remaining(\n    self,\n    people_selected_rows: list[list[str]],\n    people_remaining_rows: list[list[str]],\n    settings: Settings,\n) -&gt; list[int]:\n    # Write selected and remaining tables, returns list of duplicate indexes\n\ndef output_multi_selections(\n    self, multi_selections: list[list[str]]\n) -&gt; None:\n    # Write multiple selection panels (gen_rem_tab must be False)\n</code></pre> <p>Example - CSV Files:</p> <pre><code>from sortition_algorithms.adapters import CSVFileDataSource, SelectionData\nfrom pathlib import Path\n\n# Create data source for CSV files\ndata_source = CSVFileDataSource(\n    features_file=Path(\"features.csv\"),\n    people_file=Path(\"people.csv\"),\n    selected_file=Path(\"selected.csv\"),\n    remaining_file=Path(\"remaining.csv\")\n)\n\n# Wrap in SelectionData\nselection_data = SelectionData(data_source)\nnumber_to_select = 100\n\n# Load data\nfeatures, report = selection_data.load_features(number_to_select)\npeople, report = selection_data.load_people(settings, features)\n\n# Run stratification (using core.py functions)\nfrom sortition_algorithms.core import run_stratification, selected_remaining_tables\nsuccess, panels, report = run_stratification(features, people, number_to_select, settings)\n\n# Format and output results\nselected_rows, remaining_rows, _ = selected_remaining_tables(\n    people, panels[0], features, settings\n)\ndupes, report = selection_data.output_selected_remaining(\n    selected_rows, remaining_rows, settings\n)\n</code></pre> <p>Example - Google Sheets:</p> <pre><code>from sortition_algorithms.adapters import GSheetDataSource, SelectionData\nfrom pathlib import Path\n\n# Create data source for Google Sheets\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"credentials.json\")\n)\ndata_source.set_g_sheet_name(\"My Sortition Spreadsheet\")\n\n# Wrap in SelectionData\nselection_data = SelectionData(data_source)\n\n# Load and process (same as CSV example above)\nfeatures, report = selection_data.load_features()\npeople, report = selection_data.load_people(settings, features)\n# ... run stratification and output results\n</code></pre>"},{"location":"api-reference/#csvstringdatasource","title":"CSVStringDataSource","text":"<p>Data source for working with CSV data provided as strings (useful for testing or web applications).</p> <pre><code>class CSVStringDataSource(AbstractDataSource):\n    def __init__(self, features_data: str, people_data: str):\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_data</code>: CSV content for features as a string</li> <li><code>people_data</code>: CSV content for people as a string</li> </ul> <p>Attributes:</p> <ul> <li><code>selected_file</code>: StringIO buffer containing selected output</li> <li><code>remaining_file</code>: StringIO buffer containing remaining output</li> <li><code>selected_file_written</code>: Boolean indicating if selected was written</li> <li><code>remaining_file_written</code>: Boolean indicating if remaining was written</li> </ul> <p>Example:</p> <pre><code>features_csv = \"\"\"feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\"\"\"\n\npeople_csv = \"\"\"id,name,Gender\np1,Alice,Female\np2,Bob,Male\"\"\"\n\ndata_source = CSVStringDataSource(features_csv, people_csv)\nselection_data = SelectionData(data_source)\n# ... use as normal, then access results from StringIO:\nselected_output = data_source.selected_file.getvalue()\n</code></pre>"},{"location":"api-reference/#csvfiledatasource","title":"CSVFileDataSource","text":"<p>Data source for reading from and writing to CSV files on disk.</p> <pre><code>class CSVFileDataSource(AbstractDataSource):\n    def __init__(\n        self,\n        features_file: Path,\n        people_file: Path,\n        selected_file: Path,\n        remaining_file: Path\n    ):\n</code></pre> <p>Parameters:</p> <ul> <li><code>features_file</code>: Path to input CSV file with feature definitions</li> <li><code>people_file</code>: Path to input CSV file with candidate data</li> <li><code>selected_file</code>: Path to output CSV file for selected people</li> <li><code>remaining_file</code>: Path to output CSV file for remaining people</li> </ul>"},{"location":"api-reference/#gsheetdatasource","title":"GSheetDataSource","text":"<p>Data source for reading from and writing to Google Sheets.</p> <pre><code>class GSheetDataSource(AbstractDataSource):\n    def __init__(\n        self,\n        feature_tab_name: str,\n        people_tab_name: str,\n        auth_json_path: Path\n    ):\n\n    def set_g_sheet_name(self, g_sheet_name: str) -&gt; None:\n</code></pre> <p>Parameters:</p> <ul> <li><code>feature_tab_name</code>: Name of the tab containing feature definitions</li> <li><code>people_tab_name</code>: Name of the tab containing candidate data</li> <li><code>auth_json_path</code>: Path to Google API service account credentials JSON</li> </ul> <p>Methods:</p> <ul> <li><code>set_g_sheet_name(g_sheet_name)</code>: Set the spreadsheet to work with (name or URL)</li> </ul> <p>Attributes:</p> <ul> <li><code>selected_tab_name</code>: Name of created tab with selected people (set after output)</li> <li><code>remaining_tab_name</code>: Name of created tab with remaining people (set after output)</li> </ul> <p>Notes:</p> <ul> <li>Automatically creates new output tabs with incrementing numbers to avoid overwriting</li> <li>Highlights duplicate addresses in orange in the remaining tab</li> <li>Requires Google Sheets API credentials (see Google Cloud Console)</li> </ul>"},{"location":"api-reference/#abstractdatasource","title":"AbstractDataSource","text":"<p>Abstract base class defining the interface that all data sources must implement.</p> <pre><code>class AbstractDataSource(abc.ABC):\n    @abc.abstractmethod\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        ...\n\n    @abc.abstractmethod\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        ...\n\n    @abc.abstractmethod\n    def write_selected(self, selected: list[list[str]]) -&gt; None:\n        ...\n\n    @abc.abstractmethod\n    def write_remaining(self, remaining: list[list[str]]) -&gt; None:\n        ...\n\n    @abc.abstractmethod\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        ...\n</code></pre> <p>Implement this interface to create custom data sources (e.g., for databases, APIs, or other formats).</p>"},{"location":"api-reference/#core-data-classes","title":"Core Data Classes","text":""},{"location":"api-reference/#featurecollection","title":"FeatureCollection","text":"<p>Container for demographic features and their quotas. It is a nested dict of <code>FeatureValueMinMax</code> objects. The outer dict keys are the feature names, and the inner dict keys are the value names.</p> <p>Key Helper Functions:</p> <pre><code>def check_desired(fc: FeatureCollection, desired_number: int) -&gt; None:\n    # Validates that quotas are achievable for the desired panel size\n    # Raises exception if infeasible\n\ndef iterate_feature_collection(features: FeatureCollection) -&gt; Generator[tuple[str, str, FeatureValueMinMax]]:\n    # Iterate over all feature values and their count objects\n</code></pre>"},{"location":"api-reference/#people","title":"People","text":"<p>Container for the candidate pool.</p> <p>Key Methods:</p> <pre><code>def __len__(self) -&gt; int:\n    # Number of people in the pool\n\ndef __iter__(self) -&gt; Iterator[str]:\n    # Iterate over person IDs\n\ndef get_person_dict(self, person_id: str) -&gt; dict[str, str]:\n    # Get all data for a specific person\n\ndef matching_address(\n    self, person_id: str, address_columns: list[str]\n) -&gt; list[str]:\n    # Find people with matching address to given person\n\ndef remove(self, person_id: str) -&gt; None:\n    # Remove person from pool\n\ndef remove_many(self, person_ids: list[str]) -&gt; None:\n    # Remove multiple people from pool\n</code></pre>"},{"location":"api-reference/#error-classes","title":"Error Classes","text":""},{"location":"api-reference/#infeasiblequotaserror","title":"InfeasibleQuotasError","text":"<p>Raised when quotas cannot be satisfied with the available candidate pool.</p> <pre><code>class InfeasibleQuotasError(Exception):\n    def __init__(self, output: list[str])\n</code></pre> <p>Attributes:</p> <ul> <li><code>output</code>: List of diagnostic messages explaining the infeasibility</li> </ul>"},{"location":"api-reference/#selectionerror","title":"SelectionError","text":"<p>General error for selection process failures.</p> <pre><code>class SelectionError(Exception):\n    pass\n</code></pre>"},{"location":"api-reference/#utility-functions","title":"Utility Functions","text":""},{"location":"api-reference/#set_random_provider","title":"set_random_provider()","text":"<p>Configure the random number generator for reproducible results.</p> <pre><code>def set_random_provider(seed: int | None) -&gt; None\n</code></pre> <p>Parameters:</p> <ul> <li><code>seed</code>: Random seed (None for secure random)</li> </ul> <p>Example:</p> <pre><code>set_random_provider(42)  # Reproducible results\nset_random_provider(None)  # Secure random\n</code></pre>"},{"location":"api-reference/#generate_dupes","title":"generate_dupes()","text":"<p>Identify people who share an address in a table of remaining candidates.</p> <pre><code>def generate_dupes(\n    people_remaining_rows: list[list[str]],\n    settings: Settings\n) -&gt; list[int]:\n</code></pre> <p>Parameters:</p> <ul> <li><code>people_remaining_rows</code>: Table of people data where first row is headers</li> <li><code>settings</code>: Settings object (uses <code>check_same_address</code> and <code>check_same_address_columns</code>)</li> </ul> <p>Returns:</p> <ul> <li>List of row indexes (1-indexed, accounting for header) of people who share an address with at least one other person</li> </ul> <p>Example:</p> <pre><code># Table with headers in row 0\npeople_table = [\n    [\"id\", \"name\", \"address_line_1\", \"postcode\"],\n    [\"1\", \"Alice\", \"33 Acacia Avenue\", \"W1A 1AA\"],\n    [\"2\", \"Bob\", \"31 Acacia Avenue\", \"W1A 1AA\"],\n    [\"3\", \"Charlotte\", \"33 Acacia Avenue\", \"W1A 1AA\"],\n    [\"4\", \"David\", \"33 Acacia Avenue\", \"W1B 1BB\"],\n]\n\nsettings = Settings(\n    id_column=\"id\",\n    columns_to_keep=[\"name\"],\n    check_same_address=True,\n    check_same_address_columns=[\"address_line_1\", \"postcode\"]\n)\n\ndupes = generate_dupes(people_table, settings)\n# Returns [1, 3] - Alice and Charlotte share the same address\n</code></pre> <p>Notes:</p> <ul> <li>Returns empty list if <code>check_same_address</code> is False</li> <li>Only considers exact matches on ALL specified address columns</li> <li>Row indexes account for the header being at index 0</li> </ul>"},{"location":"api-reference/#type-hints","title":"Type Hints","text":"<p>Common type aliases used throughout the API:</p> <pre><code># A committee is a set of person IDs\nCommittee = frozenset[str]\n\n# Selection results are lists of committees\nSelectionResult = list[Committee]\n\n# Tables are lists of rows (lists of strings)\nTable = list[list[str]]\n</code></pre>"},{"location":"cli/","title":"Command Line Interface","text":"<p>The CLI provides a convenient way to run sortition algorithms without writing Python code. It's ideal for:</p> <ul> <li>One-off selections: Quick panel selections for events or research</li> <li>Sample code: The code in the command line functions can be the basis for writing your own implementation.</li> <li>Batch processing: Running multiple selections with scripts</li> <li>Non-programmers: Teams who prefer command-line tools</li> <li>Integration: Incorporating sortition into existing workflows</li> </ul>"},{"location":"cli/#installation","title":"Installation","text":"<p>Install the CLI with optional dependencies:</p> <pre><code># Basic installation\npip install 'sortition-algorithms[cli]'\n\n# With Gurobi support for leximin algorithm\npip install 'sortition-algorithms[cli,gurobi]'\n</code></pre>"},{"location":"cli/#quick-start","title":"Quick Start","text":"<pre><code># Check installation\npython -m sortition_algorithms --help\n\n# Basic CSV selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#commands-overview","title":"Commands Overview","text":"<p>The CLI provides three main commands:</p> <pre><code>$ python -m sortition_algorithms --help\nUsage: python -m sortition_algorithms [OPTIONS] COMMAND [ARGS]...\n\n  A command line tool to exercise the sortition algorithms.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  csv         Do sortition with CSV files\n  gen-sample  Generate sample CSV file compatible with features\n  gsheet      Do sortition with Google Spreadsheets\n</code></pre>"},{"location":"cli/#csv-workflow","title":"CSV Workflow","text":"<p>The most common usage pattern for working with local CSV files.</p>"},{"location":"cli/#command-reference","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms csv --help\nUsage: python -m sortition_algorithms csv [OPTIONS]\n\n  Do sortition with CSV files.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  -f, --features-csv FILE         CSV with demographic features [required]\n  -p, --people-csv FILE           CSV with candidate pool [required]\n  -s, --selected-csv FILE         Output: selected people [required]\n  -r, --remaining-csv FILE        Output: remaining people [required]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-files","title":"Example Files","text":"<p>demographics.csv (feature definitions):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,35,45\nAge,51+,25,35\nLocation,Urban,40,60\nLocation,Rural,40,60\n</code></pre> <p>candidates.csv (candidate pool):</p> <pre><code>id,Name,Email,Gender,Age,Location,Address,Postcode\np001,Alice Smith,alice@email.com,Female,18-30,Urban,123 Main St,12345\np002,Bob Jones,bob@email.com,Male,31-50,Rural,456 Oak Ave,67890\np003,Carol Davis,carol@email.com,Female,51+,Urban,789 Pine Rd,12345\n...\n</code></pre> <p>config.toml (settings):</p> <pre><code># Set to zero for secure random results\nrandom_number_seed = 0\n\n# Household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Algorithm choice\nselection_algorithm = \"maximin\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\nid_column = \"id\"\n</code></pre>"},{"location":"cli/#basic-selection","title":"Basic Selection","text":"<pre><code>python -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#using-environment-variables","title":"Using Environment Variables","text":"<p>Set commonly used paths as environment variables:</p> <pre><code>export SORTITION_SETTINGS=\"config.toml\"\n\npython -m sortition_algorithms csv \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  -s selected.csv \\\n  -r remaining.csv \\\n  -n 100\n</code></pre>"},{"location":"cli/#batch-processing","title":"Batch Processing","text":"<p>Create a script for multiple selections:</p> <pre><code>#!/bin/bash\n# batch_selection.sh\n\nSETTINGS=\"config.toml\"\nFEATURES=\"demographics.csv\"\nPEOPLE=\"candidates.csv\"\nAREAS=(north south east west)\nSIZE=50\n\nfor area in \"${AREAS[@]}\"; do\n    echo \"Selecting $size people...\"\n    python -m sortition_algorithms csv \\\n        --settings \"$SETTINGS\" \\\n        --features-csv \"$FEATURES\" \\\n        --people-csv \"candidates_${area}.csv\" \\\n        --selected-csv \"selected_${area}.csv\" \\\n        --remaining-csv \"remaining_${area}.csv\" \\\n        --number-wanted \"$SIZE\"\ndone\n</code></pre>"},{"location":"cli/#google-sheets-workflow","title":"Google Sheets Workflow","text":"<p>For organizations using Google Sheets for data management.</p>"},{"location":"cli/#setup-requirements","title":"Setup Requirements","text":"<ol> <li>Google Cloud Project: Create a project in Google Cloud Console</li> <li>Enable APIs: Enable Google Sheets API and Google Drive API</li> <li>Service Account: Create service account credentials</li> <li>Share Sheet: Share your spreadsheet with the service account email</li> </ol>"},{"location":"cli/#command-reference_1","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gsheet --help\nUsage: python -m sortition_algorithms gsheet [OPTIONS]\n\n  Do sortition with Google Spreadsheets.\n\nOptions:\n  -S, --settings FILE             Settings file (TOML format) [required]\n  --auth-json-file FILE           Google API credentials JSON [required]\n  --gen-rem-tab / --no-gen-rem-tab Generate 'Remaining' tab [default: true]\n  -g, --gsheet-name TEXT          Spreadsheet name [required]\n  -f, --feature-tab-name TEXT     Features tab name [default: Categories]\n  -p, --people-tab-name TEXT      People tab name [default: Categories]\n  -s, --selected-tab-name TEXT    Selected output tab [default: Selected]\n  -r, --remaining-tab-name TEXT   Remaining output tab [default: Remaining]\n  -n, --number-wanted INTEGER     Number of people to select [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#authentication-setup","title":"Authentication Setup","text":"<ol> <li>Download service account credentials JSON file</li> <li>Never commit this file to version control</li> <li>Store securely and reference by path</li> </ol>"},{"location":"cli/#example-usage","title":"Example Usage","text":"<pre><code>python -m sortition_algorithms gsheet \\\n  --settings config.toml \\\n  --auth-json-file /secure/path/credentials.json \\\n  --gsheet-name \"Citizen Panel 2024\" \\\n  --feature-tab-name \"Demographics\" \\\n  --people-tab-name \"Candidates\" \\\n  --selected-tab-name \"Selected Panel\" \\\n  --remaining-tab-name \"Reserve Pool\" \\\n  --number-wanted 120\n</code></pre>"},{"location":"cli/#spreadsheet-structure","title":"Spreadsheet Structure","text":"<p>Your Google Sheet should have tabs structured like this:</p> <p>Demographics tab:</p> feature value min max Gender Male 45 55 Gender Female 45 55 Age 18-30 20 30 <p>Candidates tab:</p> id Name Email Gender Age Location p001 Alice alice@email.com Female 18-30 Urban p002 Bob bob@email.com Male 31-50 Rural"},{"location":"cli/#sample-generation","title":"Sample Generation","text":"<p>Generate test data compatible with your feature definitions.</p>"},{"location":"cli/#command-reference_2","title":"Command Reference","text":"<pre><code>$ python -m sortition_algorithms gen-sample --help\nUsage: python -m sortition_algorithms gen-sample [OPTIONS]\n\n  Generate sample CSV file compatible with features and settings.\n\nOptions:\n  -S, --settings FILE             Settings file [required]\n  -f, --features-csv FILE         Features CSV file [required]\n  -p, --people-csv FILE           Output: generated people CSV [required]\n  -n, --number-wanted INTEGER     Number of people to generate [required]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli/#example-usage_1","title":"Example Usage","text":"<pre><code># Generate 500 sample people\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv sample_candidates.csv \\\n  --number-wanted 500\n</code></pre> <p>This creates a CSV with realistic synthetic data that matches your feature definitions - useful for testing quotas and algorithms.</p>"},{"location":"cli/#configuration-files","title":"Configuration Files","text":""},{"location":"cli/#settings-file-format","title":"Settings File Format","text":"<p>All settings are optional and have sensible defaults:</p> <pre><code># config.toml\n\n# Randomization\nrandom_number_seed = 0  # Set non-zero for reproducible results, omit for random\n\n# Address checking for household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\", \"City\"]\n\n# Algorithm selection\nselection_algorithm = \"maximin\"  # \"maximin\", \"nash\", \"leximin\", \"legacy\"\nmax_attempts = 10\n\n# Output customization\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\", \"Notes\"]\nid_column = \"id\"  # Column name containing unique IDs\n</code></pre>"},{"location":"cli/#algorithm-comparison","title":"Algorithm Comparison","text":"Algorithm Pros Cons Use Case <code>maximin</code> Fair to minorities May not optimize overall Default choice <code>nash</code> Balanced overall Complex optimization Large diverse pools <code>leximin</code> Strongest fairness Requires Gurobi license Academic/research <code>legacy</code> Backwards compatible Less sophisticated Historical consistency"},{"location":"cli/#common-workflows","title":"Common Workflows","text":""},{"location":"cli/#standard-selection-process","title":"Standard Selection Process","text":"<pre><code># 1. Prepare your data files\n# 2. Configure settings\n# 3. Run selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 100\n\n# 4. Review results\nhead selected.csv\nwc -l remaining.csv\n</code></pre>"},{"location":"cli/#with-address-checking","title":"With Address Checking","text":"<p>Ensure household diversity by preventing multiple selections from the same address:</p> <pre><code># config.toml\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n</code></pre>"},{"location":"cli/#reproducible-selections","title":"Reproducible Selections","text":"<p>For auditable results, use a fixed random seed:</p> <pre><code># config.toml\nrandom_number_seed = 20241214  # Use today's date or similar\n</code></pre>"},{"location":"cli/#testing-quotas","title":"Testing Quotas","text":"<p>Use sample generation to test if your quotas are achievable:</p> <pre><code># Generate large sample\npython -m sortition_algorithms gen-sample \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --number-wanted 1000\n\n# Test selection\npython -m sortition_algorithms csv \\\n  --settings config.toml \\\n  --features-csv demographics.csv \\\n  --people-csv test_pool.csv \\\n  --selected-csv test_selected.csv \\\n  --remaining-csv test_remaining.csv \\\n  --number-wanted 100\n</code></pre>"},{"location":"cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli/#common-errors","title":"Common Errors","text":"<p>\"Selection failed\"</p> <ul> <li>Check that the sum of quota minimums for any given features don't exceed panel size (or that maximums are smaller than the panel size).</li> <li>Verify feature values match between files.</li> <li>Review constraint feasibility.</li> </ul> <p>\"File not found\"</p> <ul> <li>Use absolute paths or verify working directory.</li> <li>Check file permissions.</li> <li>Ensure files exist before running.</li> </ul> <p>\"Invalid feature values\"</p> <ul> <li>Verify exact string matching between demographics.csv and candidates.csv</li> <li>Check for typos, case sensitivity, extra spaces</li> <li>Review non-ASCII characters</li> </ul> <p>\"Authentication failed\" (Google Sheets)</p> <ul> <li>Verify <code>credentials.json</code> is correct and accessible</li> <li>Check that service account has access to the spreadsheet</li> <li>Ensure APIs are enabled in Google Cloud Console</li> </ul>"},{"location":"cli/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Understand the theory behind sortition</li> <li>API Reference - For programmatic usage</li> <li>Data Adapters - Custom data sources and formats</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"concepts/","title":"Core Concepts","text":"<p>Understanding these fundamental concepts is essential for effectively using sortition algorithms.</p>"},{"location":"concepts/#what-is-sortition","title":"What is Sortition?","text":"<p>Sortition is the random selection of representatives from a larger population, designed to create panels that reflect the demographic composition of the whole group. Unlike simple random sampling (which could accidentally select all men or all young people), sortition uses stratified random selection to ensure demographic balance.</p>"},{"location":"concepts/#historical-context","title":"Historical Context","text":"<p>Sortition has ancient roots in Athenian democracy, where citizens were chosen by lot to serve in government. Modern applications include:</p> <ul> <li>Citizens' Assemblies: Groups that deliberate on policy issues</li> <li>Deliberative Polls: Representative samples for public opinion research</li> <li>Jury Selection: Court juries selected from voter rolls</li> <li>Participatory Budgeting: Community members deciding budget priorities</li> </ul>"},{"location":"concepts/#key-components","title":"Key Components","text":""},{"location":"concepts/#features-and-feature-values","title":"Features and Feature Values","text":"<p>Features are demographic characteristics used for stratification:</p> <ul> <li>Gender, Age, Education, Income, Location, etc.</li> </ul> <p>Feature Values are the specific categories within each feature:</p> <ul> <li>Gender: Male, Female, Non-binary</li> <li>Age: 18-30, 31-50, 51-65, 65+</li> <li>Location: Urban, Suburban, Rural</li> </ul> <p>Note that sometimes Features are called \"categories\" and Feature Values are called \"category values\".</p>"},{"location":"concepts/#quotas-and-targets","title":"Quotas and Targets","text":"<p>Each feature value has minimum and maximum quotas that define the acceptable range for selection:</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,25,35\n</code></pre> <p>This ensures your panel of 100 people includes 45-55 men, 45-55 women, 20-30 young adults, etc.</p>"},{"location":"concepts/#people-pool","title":"People Pool","text":"<p>The candidate pool contains all eligible individuals with their demographic data:</p> <pre><code>id,Name,Gender,Age,Location,Email\np001,Alice Smith,Female,18-30,Urban,alice@example.com\np002,Bob Jones,Male,31-50,Rural,bob@example.com\n...\n</code></pre>"},{"location":"concepts/#address-checking-and-household-diversity","title":"Address Checking and Household Diversity","text":"<p>A critical feature for ensuring true representativeness is address checking - preventing multiple people from the same household being selected.</p>"},{"location":"concepts/#why-address-checking-matters","title":"Why Address Checking Matters","text":"<p>Without address checking, you might accidentally select:</p> <ul> <li>Multiple family members with similar views</li> <li>Several housemates from a shared address</li> <li>People who influence each other's opinions</li> </ul> <p>This reduces the independence and diversity of your panel.</p>"},{"location":"concepts/#how-it-works","title":"How It Works","text":"<p>Configure address checking in your settings:</p> <pre><code>settings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre> <p>When someone is selected:</p> <ol> <li>The algorithm identifies anyone else with matching values in the specified columns</li> <li>Those people are removed from the remaining pool</li> <li>This ensures geographic and household diversity</li> </ol>"},{"location":"concepts/#address-column-strategies","title":"Address Column Strategies","text":"<p>Single column approach:</p> <pre><code>check_same_address_columns = [\"Full_Address\"]\n</code></pre> <p>Multi-column approach (more flexible):</p> <pre><code>check_same_address_columns = [\"Street\", \"City\", \"Postcode\"]\n</code></pre> <p>Exact vs. fuzzy matching: The current implementation requires exact string matches. For fuzzy address matching, you'd need to clean your data first.</p>"},{"location":"concepts/#selection-algorithms","title":"Selection Algorithms","text":"<p>Different algorithms optimize for different fairness criteria:</p>"},{"location":"concepts/#maximin-default","title":"Maximin (Default)","text":"<p>Objective: Maximize the minimum selection probability across all groups.</p> <p>When to use:</p> <ul> <li>Default choice for most applications</li> <li>Ensures no group is severely underrepresented</li> <li>Good for citizen assemblies and deliberative panels</li> </ul> <p>Trade-offs:</p> <ul> <li>May not optimize overall fairness</li> <li>Can be conservative in selection choices</li> </ul> <p>Example scenario: A panel where ensuring minimum representation for small minorities is crucial.</p>"},{"location":"concepts/#nash","title":"Nash","text":"<p>Objective: Maximize the product of all selection probabilities.</p> <p>When to use:</p> <ul> <li>Large, diverse candidate pools</li> <li>When you want balanced representation across all groups</li> <li>Academic research requiring mathematical optimality</li> </ul> <p>Trade-offs:</p> <ul> <li>More complex optimization</li> <li>May be harder to explain to stakeholders</li> </ul> <p>Example scenario: Research study requiring theoretically optimal fairness across all demographic groups.</p>"},{"location":"concepts/#leximin","title":"Leximin","text":"<p>Objective: Lexicographic maximin optimization (requires Gurobi license).</p> <p>When to use:</p> <ul> <li>Academic research requiring strongest fairness guarantees</li> <li>When you have access to Gurobi (commercial/academic license)</li> <li>High-stakes selections where maximum fairness is essential</li> </ul> <p>Trade-offs:</p> <ul> <li>Requires commercial solver (Gurobi)</li> <li>More computationally intensive</li> <li>May be overkill for routine selections</li> </ul> <p>Example scenario: Government-sponsored citizen assembly where mathematical proof of fairness is required.</p>"},{"location":"concepts/#diverimax","title":"Diverimax","text":"<p>Objective: Maximize the diversity of the panel, preferring as many unique profiles as possible</p> <p>When to use:</p> <ul> <li>Ensures no group is severely underrepresented</li> <li>Tries to make all groups AND all intersections of groups (e.g Black, Woman, High income) as represented as possible</li> <li>Enhances deliberative quality by maximizing the number of unique perspectives</li> </ul> <p>Trade-offs:</p> <ul> <li>Does not focus on individual fairness, only on panel composition</li> <li>Does not generate multiple committees with different probabilities, only one optimal committee</li> </ul> <p>Example scenario: An assembly focused on social or community issues where diverse perspectives are critical.</p>"},{"location":"concepts/#legacy","title":"Legacy","text":"<p>Objective: Backwards compatibility with earlier implementations.</p> <p>When to use:</p> <ul> <li>Reproducing historical selections</li> <li>Comparison studies</li> <li>Specific compatibility requirements</li> </ul> <p>Trade-offs:</p> <ul> <li>Less sophisticated than modern algorithms</li> <li>May not provide optimal fairness</li> </ul> <p>Details:</p> <ul> <li>it will have multiple attempts at the core algorithm</li> <li>it goes through each target value in turn, in order of the target value that will be hardest to meet first.</li> <li>for each category, it will randomly choose a sample of people to meet the target for that value, which combined with the people already in the selected group, and add that to the selected group</li> <li>at the end it either finds a sample that meets the targets, or it fails, and another attempt is made from the start</li> </ul>"},{"location":"concepts/#algorithms-not-in-this-library","title":"Algorithms not in this library","text":"<p>(Though they may be added at some point in the future.)</p>"},{"location":"concepts/#goldilocks","title":"Goldilocks","text":"<p>From the same family as Maximin and Leximin. It tries to ensure no one in the pool gets a really high or low chance of being selected.</p> <p>The code is not yet open, but you can read a bit more on the lotterylab algorithms page.</p>"},{"location":"concepts/#max-entropy","title":"Max Entropy","text":"<p>This just tries to select from every possible sample of the right size in the data, finding one at random that meets the targets. Because the number of samples is so large, there are some mathematical tricks used to create samples in a way that increases the chance of finding one that will match the targets, while keeping the randomness.</p> <p>The code is not yet open, but you can read a bit more on the lotterylab algorithms page.</p>"},{"location":"concepts/#swedish-selection","title":"Swedish Selection","text":"<p>This take random samples, calculates the \"distance\" from the ideal targets, and saves it if the distance has gone down. After a while, the sample with the lowest distance is used. It is computationally intense - the README says \"after running it for a few hours ...\". For more complex targets it would take a long time. But it does have the advantage of being easy to explain to people, and the code is fairly easy to read.</p> <p>A note on \"distance\" - there is a weight applied to each target category, and the distance for each target category is multiplied by that weight. This means the most important target categories will be more closely matched.</p> <p>The code can be seen on github and it is developed by Digidem Lab.</p>"},{"location":"concepts/#automatic-selection","title":"Automatic Selection","text":"<p>This is inspired by Swedish Selection, using the same distance measure. But instead of finding fresh random samples each time, it swaps excess people out of the sample for people with target values that are below target from the pool. By doing this it can often find a sample that hits the targets exactly.</p> <p>The code can be seen on github and it is developed by Analyse og Tal.</p>"},{"location":"concepts/#research-background","title":"Research Background","text":"<p>The algorithms are described in this paper (open access).</p> <p>DiversiMax is described here.</p> <p>Other relevant papers:</p> <ul> <li>Procaccia et al. Is Sortition Both Representative and Fair?</li> <li>Tiago c Peixoto</li> <li>Reflections on the representativeness of citizens\u2019 assemblies and similar innovations and</li> <li>How representative is it really? A correspondence on sortition</li> </ul>"},{"location":"concepts/#the-selection-process","title":"The Selection Process","text":""},{"location":"concepts/#1-feasibility-checking","title":"1. Feasibility Checking","text":"<p>Before selection begins, the algorithm verifies that quotas are achievable:</p> <pre><code>features.check_desired(number_people_wanted=100)\n</code></pre>"},{"location":"concepts/#2-algorithm-execution","title":"2. Algorithm Execution","text":"<p>The chosen algorithm finds an optimal probability distribution over possible committees.</p>"},{"location":"concepts/#3-lottery-rounding","title":"3. Lottery Rounding","text":"<p>The probability distribution is converted to concrete selections using randomized rounding. (This step is skipped for Diverimax, which produces a single optimal committee directly.)</p>"},{"location":"concepts/#4-validation","title":"4. Validation","text":"<p>Selected committees are checked against quotas to ensure targets were met.</p>"},{"location":"concepts/#randomness-and-reproducibility","title":"Randomness and Reproducibility","text":""},{"location":"concepts/#random-seeds","title":"Random Seeds","text":"<p>For reproducible results (e.g., for auditing), set a random seed:</p> <pre><code>settings = Settings(random_number_seed=42)\n</code></pre>"},{"location":"concepts/#security-considerations","title":"Security Considerations","text":"<p>For production use, avoid fixed seeds. The library uses Python's <code>secrets</code> module when no seed is specified.</p>"},{"location":"concepts/#data-quality-considerations","title":"Data Quality Considerations","text":""},{"location":"concepts/#feature-consistency","title":"Feature Consistency","text":"<p>Ensure feature values are consistent between your quotas file and candidate data:</p> <pre><code># demographics.csv\nGender,Male,45,55\nGender,Female,45,55\n\n# candidates.csv - values must match exactly\nperson1,Male,...    # \u2705 Matches\nperson2,male,...    # \u274c Case mismatch\nperson3,M,...       # \u274c Abbreviation mismatch\n</code></pre>"},{"location":"concepts/#missing-data","title":"Missing Data","text":"<p>The library requires complete demographic data. Handle missing values before import:</p> <ul> <li>Impute missing values</li> <li>Create \"Unknown\" categories</li> <li>Exclude incomplete records</li> </ul>"},{"location":"concepts/#data-validation","title":"Data Validation","text":"<p>The library performs extensive validation:</p> <ul> <li>Checks for unknown feature values</li> <li>Verifies quota feasibility</li> <li>Validates candidate pool size</li> </ul>"},{"location":"concepts/#error-handling","title":"Error Handling","text":""},{"location":"concepts/#common-errors","title":"Common Errors","text":"<p>InfeasibleQuotasError: Your quotas cannot be satisfied</p> <pre><code># Too restrictive - asking for 90+ males in a pool of 100\nGender,Male,90,100\nGender,Female,90,100\n</code></pre> <p>SelectionError: General selection failures</p> <ul> <li>Insufficient candidates in a category</li> <li>Conflicting constraints</li> </ul> <p>ValueError: Invalid parameters</p> <ul> <li>Negative quotas</li> <li>Invalid algorithm names</li> </ul>"},{"location":"concepts/#debugging-tips","title":"Debugging Tips","text":"<ol> <li>Check quota feasibility: Sum of minimums \u2264 panel size \u2264 sum of maximums</li> <li>Verify data consistency: Feature values match between files</li> <li>Review messages: The algorithm provides detailed feedback</li> <li>Test with relaxed quotas: Temporarily widen ranges to isolate issues</li> </ol>"},{"location":"concepts/#best-practices","title":"Best Practices","text":""},{"location":"concepts/#quota-design","title":"Quota Design","text":"<ul> <li>Start conservative: Use wider ranges initially, then narrow if needed</li> <li>Consider interactions: Age and education might be correlated</li> <li>Plan for edge cases: What if you have few candidates in a category?</li> </ul>"},{"location":"concepts/#data-preparation","title":"Data Preparation","text":"<ul> <li>Standardize values: Consistent capitalization and spelling</li> <li>Validate completeness: No missing demographic data</li> <li>Test with samples: Verify your setup with small test runs</li> </ul>"},{"location":"concepts/#address-checking","title":"Address Checking","text":"<ul> <li>Clean addresses first: Standardize formatting before using address checking</li> <li>Consider geography: Urban areas might need tighter address matching</li> <li>Balance household diversity vs. other constraints: Address checking reduces your effective pool size</li> </ul>"},{"location":"concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the core concepts:</p> <ul> <li>Quick Start - Try your first selection</li> <li>API Reference - Detailed function documentation</li> <li>CLI Usage - Command line examples</li> <li>Data Adapters - Working with different data sources</li> <li>Advanced Usage - Complex scenarios and optimization</li> </ul>"},{"location":"i18n/","title":"Internationalization (i18n) Guide","text":"<p>This library provides comprehensive support for translating error messages into different languages for use in multilingual web applications.</p>"},{"location":"i18n/#overview","title":"Overview","text":"<p>All error messages in the sortition algorithms library include:</p> <ol> <li>English message - for standalone use and backward compatibility</li> <li>Error code - a unique identifier for each error type</li> <li>Structured parameters - data needed to reconstruct the message in any language</li> </ol> <p>This design allows web applications to translate all error messages while keeping the library independent of any specific translation framework.</p>"},{"location":"i18n/#for-web-application-developers","title":"For Web Application Developers","text":""},{"location":"i18n/#basic-approach","title":"Basic Approach","text":"<p>This library provides translation support for both error messages and run report messages. You can access translation data in the following ways:</p>"},{"location":"i18n/#simple-errors-baddataerror-selectionerror-valueerror-etc","title":"Simple Errors (BadDataError, SelectionError, ValueError, etc.)","text":"<p>All simple exceptions now include <code>error_code</code> and <code>error_params</code> attributes:</p> <pre><code>from sortition_algorithms.errors import BadDataError, SelectionError\n\ntry:\n    # ... sortition code\nexcept (BadDataError, SelectionError, ValueError, TypeError, RuntimeError) as e:\n    if hasattr(e, 'error_code') and e.error_code:\n        # Translate using the error code and parameters\n        translated_msg = _(f\"errors.{e.error_code}\") % e.error_params\n        print(translated_msg)\n    else:\n        # Fallback to English message\n        print(str(e))\n</code></pre>"},{"location":"i18n/#parsetable-errors-validation-errors","title":"ParseTable Errors (Validation Errors)","text":"<p>For <code>ParseTableMultiError</code> exceptions, iterate through the structured error data:</p> <pre><code>from sortition_algorithms.errors import ParseTableMultiError\n\ntry:\n    # ... sortition code\nexcept ParseTableMultiError as e:\n    for sub_error in e.all_errors:\n        # Access the error code and parameters\n        if sub_error.error_code:\n            # Translate the core message\n            translated_msg = _(f\"errors.{sub_error.error_code}\") % sub_error.error_params\n\n            # Add context (row/column information)\n            if hasattr(sub_error, 'keys'):  # Multi-column error\n                context = _(\"errors.parse_error_multi_column\") % {\n                    'msg': translated_msg,\n                    'row': sub_error.row,\n                    'keys': ', '.join(sub_error.keys)\n                }\n            else:  # Single-column error\n                context = _(\"errors.parse_error_single_column\") % {\n                    'msg': translated_msg,\n                    'row': sub_error.row,\n                    'key': sub_error.key\n                }\n            print(context)\n        else:\n            # Fallback to English message\n            print(str(sub_error))\n</code></pre>"},{"location":"i18n/#run-report-messages","title":"Run Report Messages","text":"<p>The <code>RunReport</code> object returned by sortition operations contains informational messages about the process. Each message includes translation data:</p> <pre><code>from sortition_algorithms.core import run_stratification\n\nsuccess, selected_people, report = run_stratification(\n    features, people, number_people_wanted, settings\n)\n\n# Iterate through report messages and translate them\nfor element in report._data:\n    # Check if this is a message line (not a table or error)\n    if hasattr(element, 'message_code') and element.message_code:\n        # Translate using the message code and parameters\n        translated_msg = _(f\"report.{element.message_code}\") % element.message_params\n        print(translated_msg)\n    elif hasattr(element, 'line'):\n        # Fallback to English message\n        print(element.line)\n</code></pre> <p>Alternatively, you can use the serialization feature to extract all translation data:</p> <pre><code>serialized_report = report.serialize()\n\nfor element in serialized_report['_data']:\n    if 'message_code' in element and element['message_code']:\n        # Web app can translate based on message_code\n        translated_msg = _(f\"report.{element['message_code']}\") % element['message_params']\n    elif 'line' in element:\n        # For messages without translation codes, use the English text\n        fallback_msg = element['line']\n</code></pre>"},{"location":"i18n/#flask-babel-integration","title":"Flask-Babel Integration","text":"<p>For Flask applications using Babel for i18n:</p>"},{"location":"i18n/#1-configure-babel-to-extract-messages","title":"1. Configure Babel to Extract Messages","text":"<p>Create or update <code>babel.cfg</code> in your web application:</p> <pre><code>[python: **.py]\nkeywords = _:1 gettext:1 ngettext:1,2 N_:1\n\n[jinja2: **/templates/**.html]\n</code></pre>"},{"location":"i18n/#2-extract-messages-from-both-app-and-library","title":"2. Extract Messages from Both App and Library","text":"<p>Run the extraction command including the sortition library:</p> <pre><code>pybabel extract -F babel.cfg \\\n    -k N_ \\\n    -o messages.pot \\\n    your_web_app/ \\\n    venv/lib/python3.x/site-packages/sortition_algorithms/\n</code></pre> <p>This will extract all marked strings from both your application and the sortition library into a single <code>.pot</code> file.</p>"},{"location":"i18n/#3-initialize-or-update-translations","title":"3. Initialize or Update Translations","text":"<pre><code># For a new language (e.g., French)\npybabel init -i messages.pot -d translations -l fr\n\n# To update existing translations\npybabel update -i messages.pot -d translations\n</code></pre>"},{"location":"i18n/#4-translate-the-messages","title":"4. Translate the Messages","text":"<p>Edit the <code>.po</code> files in <code>translations/&lt;language&gt;/LC_MESSAGES/messages.po</code>:</p> <pre><code># English\nmsgid \"No '%(column)s' column %(error_label)s found in %(data_container)s!\"\nmsgstr \"\"\n\n# French translation\nmsgid \"No '%(column)s' column %(error_label)s found in %(data_container)s!\"\nmsgstr \"Aucune colonne '%(column)s' %(error_label)s trouv\u00e9e dans %(data_container)s!\"\n</code></pre>"},{"location":"i18n/#5-compile-translations","title":"5. Compile Translations","text":"<pre><code>pybabel compile -d translations\n</code></pre>"},{"location":"i18n/#available-error-codes","title":"Available Error Codes","text":"<p>The library provides error codes for all validation and runtime errors. Here are the main categories:</p>"},{"location":"i18n/#data-validation-errors","title":"Data Validation Errors","text":"Error Code Parameters Description <code>missing_column</code> column, error_label, data_container Required column not found <code>duplicate_column</code> column, error_label, data_container Multiple columns with same name <code>empty_feature_value</code> value_column_name, feature_column_name, feature_name Blank value in feature data <code>value_not_in_feature</code> value, feature_column_name, feature_name Invalid feature value for person <code>empty_value_in_feature</code> feature_column_name, feature_name Missing feature value for person"},{"location":"i18n/#numeric-validation-errors","title":"Numeric Validation Errors","text":"Error Code Parameters Description <code>no_value_set</code> field No value provided for required numeric field <code>not_a_number</code> value Value cannot be parsed as a number <code>min_greater_than_max</code> min, max Minimum exceeds maximum <code>min_flex_greater_than_min</code> min_flex, min Flexible minimum exceeds minimum <code>max_flex_less_than_max</code> max_flex, max Flexible maximum less than maximum"},{"location":"i18n/#system-errors","title":"System Errors","text":"Error Code Parameters Description <code>spreadsheet_not_found</code> spreadsheet_name Google Spreadsheet not accessible <code>tab_not_found</code> tab_name, spreadsheet_title Worksheet tab not found <code>unknown_selection_algorithm</code> algorithm Invalid algorithm specified <code>gurobi_not_available</code> (none) Gurobi solver not installed <p>See <code>sortition_algorithms/error_messages.py</code> for the complete list of error codes and their message templates.</p>"},{"location":"i18n/#report-message-codes","title":"Report Message Codes","text":"<p>The library provides message codes for all run report messages. Here are the main categories:</p> Category Code Parameters Description Data Loading <code>loading_features_from_string</code> (none) Loading features from string data <code>loading_people_from_string</code> (none) Loading people from string data <code>loading_features_from_file</code> file_path Loading features from file <code>loading_people_from_file</code> file_path Loading people from file <code>features_found</code> count Number of features loaded Algorithm <code>using_legacy_algorithm</code> (none) Using legacy selection algorithm <code>gurobi_unavailable_switching</code> (none) Gurobi unavailable, switching to maximin <code>distribution_stats</code> total_committees, non_zero_committees Distribution statistics Selection Process <code>test_selection_warning</code> (none) Warning about non-random test selection <code>initial_state</code> (none) Initial state message <code>trial_number</code> trial Current trial number <code>selection_success</code> (none) Selection succeeded <code>selection_failed</code> attempts Selection failed after N attempts Validation <code>blank_id_skipped</code> row Blank ID cell found and skipped <p>See <code>sortition_algorithms/report_messages.py</code> for the complete list of report message codes and their templates.</p>"},{"location":"i18n/#message-reference","title":"Message Reference","text":"<p>All translatable strings are defined in:</p> <pre><code># Error messages\nfrom sortition_algorithms.error_messages import ERROR_MESSAGES, N_\n\n# Report messages\nfrom sortition_algorithms.report_messages import REPORT_MESSAGES, get_message\n</code></pre> <p>Both <code>ERROR_MESSAGES</code> and <code>REPORT_MESSAGES</code> dictionaries map message codes to their English message templates using Python <code>%</code> string formatting.</p> <p>The <code>N_()</code> function is a no-op marker that identifies strings for extraction by Babel/gettext tools without requiring any translation framework dependency.</p> <p>The <code>get_message()</code> helper function creates formatted messages from message codes and parameters.</p>"},{"location":"i18n/#example-complete-flask-integration","title":"Example: Complete Flask Integration","text":"<pre><code>from flask import Flask\nfrom flask_babel import Babel, gettext as _\nfrom sortition_algorithms.core import run_stratification\nfrom sortition_algorithms.errors import ParseTableMultiError, SelectionError\n\napp = Flask(__name__)\nbabel = Babel(app)\n\ndef translate_sortition_error(error):\n    \"\"\"Translate a sortition error into the current language.\"\"\"\n    if isinstance(error, ParseTableMultiError):\n        translated_lines = []\n        for sub_error in error.all_errors:\n            if sub_error.error_code:\n                # Translate core message\n                msg_key = f\"errors.{sub_error.error_code}\"\n                core_msg = _(msg_key) % sub_error.error_params\n\n                # Add context\n                if hasattr(sub_error, 'keys'):\n                    full_msg = _(\"errors.parse_error_multi_column\") % {\n                        'msg': core_msg,\n                        'row': sub_error.row,\n                        'keys': ', '.join(sub_error.keys)\n                    }\n                else:\n                    full_msg = _(\"errors.parse_error_single_column\") % {\n                        'msg': core_msg,\n                        'row': sub_error.row,\n                        'key': sub_error.key\n                    }\n                translated_lines.append(full_msg)\n            else:\n                # Fallback to English\n                translated_lines.append(str(sub_error))\n        return '\\n'.join(translated_lines)\n    else:\n        # For other errors, use English for now\n        return str(error)\n\ndef translate_run_report(report):\n    \"\"\"Translate run report messages into the current language.\"\"\"\n    translated_lines = []\n    for element in report._data:\n        if hasattr(element, 'message_code') and element.message_code:\n            # Translate the message\n            msg_key = f\"report.{element.message_code}\"\n            translated_msg = _(msg_key) % element.message_params\n            translated_lines.append(translated_msg)\n        elif hasattr(element, 'line'):\n            # Fallback to English for messages without translation codes\n            translated_lines.append(element.line)\n        # Note: tables and errors would need additional handling\n    return '\\n'.join(translated_lines)\n\n@app.route('/select')\ndef select_committee():\n    try:\n        success, selected, report = run_stratification(...)\n        translated_report = translate_run_report(report)\n        return {\n            \"status\": \"success\",\n            \"selected\": list(selected[0]) if selected else [],\n            \"report\": translated_report\n        }\n    except (ParseTableMultiError, SelectionError) as e:\n        translated_error = translate_sortition_error(e)\n        return {\"status\": \"error\", \"message\": translated_error}, 400\n</code></pre>"},{"location":"i18n/#testing-translations","title":"Testing Translations","text":"<p>To test your translations:</p> <ol> <li>Extract messages: <code>pybabel extract -F babel.cfg -k N_ -o messages.pot . path/to/sortition_algorithms/</code></li> <li>Check the <code>.pot</code> file contains sortition error messages and report messages</li> <li>Initialize test language: <code>pybabel init -i messages.pot -d translations -l test</code></li> <li>Add test translations to verify they appear in your app</li> <li>Compile: <code>pybabel compile -d translations</code></li> <li>Trigger errors and run selections in the sortition library and verify translated messages appear</li> </ol>"},{"location":"i18n/#best-practices","title":"Best Practices","text":"<ol> <li>Always provide fallback: If a message code is missing or empty, display the English message from <code>str(error)</code> or <code>element.line</code></li> <li>Preserve context: When translating ParseTable errors, include row/column information from the error object</li> <li>Keep templates synchronized: After upgrading the sortition library, re-extract messages to catch new error codes and report message codes</li> <li>Test all paths: Ensure your translation code handles all error types and report messages the library can generate</li> <li>Handle all report elements: RunReport can contain lines, tables, and errors - ensure your translation code handles each type appropriately</li> </ol>"},{"location":"i18n/#future-enhancements","title":"Future Enhancements","text":"<p>Future versions may add:</p> <ul> <li>Helper functions for common translation patterns</li> <li>Pre-built integration examples for Django, FastAPI, etc.</li> <li>Translation utilities for generating .pot files directly from the library</li> </ul>"},{"location":"i18n/#getting-help","title":"Getting Help","text":"<p>If you encounter issues with i18n:</p> <ol> <li>Check that your <code>babel.cfg</code> includes the <code>N_</code> keyword</li> <li>Verify the extraction command includes the sortition library path</li> <li>Ensure error codes in your translation files match those in <code>error_messages.py</code></li> <li>Report issues at: https://github.com/anthropics/sortition-algorithms/issues</li> </ol>"},{"location":"modules/","title":"Modules","text":"<p>Adapters for loading and saving data.</p> <p>Initially we have CSV files locally, and Google Docs Spreadsheets.</p> <p>Selection algorithms for stratified sampling.</p>"},{"location":"modules/#sortition_algorithms.adapters.CSVFileDataSource","title":"<code>CSVFileDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class CSVFileDataSource(AbstractDataSource):\n    def __init__(\n        self,\n        *,\n        features_file: Path,\n        people_file: Path,\n        already_selected_file: Path | None,\n        selected_file: Path,\n        remaining_file: Path,\n    ) -&gt; None:\n        self.features_file = features_file\n        self.people_file = people_file\n        self.already_selected_file = already_selected_file\n        self.selected_file = selected_file\n        self.remaining_file = remaining_file\n\n    @property\n    def people_data_container(self) -&gt; str:\n        return f\" CSV file '{self.people_file}'\"\n\n    @property\n    def already_selected_data_container(self) -&gt; str:\n        return f\" CSV file '{self.already_selected_file}'\"\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_message(\"loading_features_from_file\", file_path=str(self.features_file))\n        with open(self.features_file, newline=\"\") as csv_file:\n            feature_reader = csv.DictReader(csv_file, strict=True)\n            assert feature_reader.fieldnames is not None\n            yield list(feature_reader.fieldnames), feature_reader\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_message(\"loading_people_from_file\", file_path=str(self.people_file))\n        with open(self.people_file, newline=\"\") as csv_file:\n            people_reader = csv.DictReader(csv_file, strict=True)\n            assert people_reader.fieldnames is not None\n            yield list(people_reader.fieldnames), people_reader\n\n    @contextmanager\n    def read_already_selected_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        if self.already_selected_file is None or not self.already_selected_file.exists():\n            report.add_message(\"no_already_selected_file\")\n            yield [], []\n            return\n        report.add_message(\"loading_already_selected_from_file\", file_path=str(self.already_selected_file))\n        with open(self.already_selected_file, newline=\"\") as csv_file:\n            already_selected_reader = csv.DictReader(csv_file, strict=True)\n            assert already_selected_reader.fieldnames is not None\n            yield list(already_selected_reader.fieldnames), already_selected_reader\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        report.add_message_and_log(\"writing_selected_csv\", logging.INFO, file_path=self.selected_file)\n        with open(self.selected_file, \"w\", newline=\"\") as csv_file:\n            _write_csv_rows(csv_file, selected)\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        report.add_message_and_log(\"writing_remaining_csv\", logging.INFO, file_path=self.remaining_file)\n        with open(self.remaining_file, \"w\", newline=\"\") as csv_file:\n            _write_csv_rows(csv_file, remaining)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        \"\"\"Cannot highlight a CSV file\"\"\"\n\n    def customise_features_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading features from {self.features_file}\",\n            *[str(e) for e in error.all_errors],\n        ])\n\n    def customise_people_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading people from {self.people_file}\",\n            *[str(e) for e in error.all_errors],\n        ])\n\n    def customise_already_selected_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading already selected people from {self.already_selected_file}\",\n            *[str(e) for e in error.all_errors],\n        ])\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVFileDataSource.highlight_dupes","title":"<code>highlight_dupes(dupes)</code>","text":"<p>Cannot highlight a CSV file</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def highlight_dupes(self, dupes: list[int]) -&gt; None:\n    \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVStringDataSource","title":"<code>CSVStringDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class CSVStringDataSource(AbstractDataSource):\n    def __init__(self, features_data: str, people_data: str, already_selected_data: str = \"\") -&gt; None:\n        self.features_data = features_data\n        self.people_data = people_data\n        self.already_selected_data = already_selected_data\n        self.selected_file = StringIO()\n        self.remaining_file = StringIO()\n        self.selected_file_written = False\n        self.remaining_file_written = False\n\n    @property\n    def people_data_container(self) -&gt; str:\n        return \"people CSV data\"\n\n    @property\n    def already_selected_data_container(self) -&gt; str:\n        return \"already selected CSV data\"\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_message(\"loading_features_from_string\")\n        feature_reader = csv.DictReader(StringIO(self.features_data), strict=True)\n        assert feature_reader.fieldnames is not None\n        yield list(feature_reader.fieldnames), feature_reader\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        report.add_message(\"loading_people_from_string\")\n        people_reader = csv.DictReader(StringIO(self.people_data), strict=True)\n        assert people_reader.fieldnames is not None\n        yield list(people_reader.fieldnames), people_reader\n\n    @contextmanager\n    def read_already_selected_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        if not self.already_selected_data or not self.already_selected_data.strip():\n            report.add_message(\"no_already_selected_data\")\n            yield [], []\n            return\n        report.add_message(\"loading_already_selected_from_string\")\n        already_selected_reader = csv.DictReader(StringIO(self.already_selected_data), strict=True)\n        assert already_selected_reader.fieldnames is not None\n        yield list(already_selected_reader.fieldnames), already_selected_reader\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        _write_csv_rows(self.selected_file, selected)\n        self.selected_file_written = True\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        _write_csv_rows(self.remaining_file, remaining)\n        self.remaining_file_written = True\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        \"\"\"Cannot highlight a CSV file\"\"\"\n\n    def customise_features_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        # given the info is in strings, we can't usefully add anything\n        return error\n\n    def customise_people_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        # given the info is in strings, we can't usefully add anything\n        return error\n\n    def customise_already_selected_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        # given the info is in strings, we can't usefully add anything\n        return error\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.CSVStringDataSource.highlight_dupes","title":"<code>highlight_dupes(dupes)</code>","text":"<p>Cannot highlight a CSV file</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def highlight_dupes(self, dupes: list[int]) -&gt; None:\n    \"\"\"Cannot highlight a CSV file\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource","title":"<code>GSheetDataSource</code>","text":"<p>               Bases: <code>AbstractDataSource</code></p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>class GSheetDataSource(AbstractDataSource):\n    scope: ClassVar = [\n        \"https://spreadsheets.google.com/feeds\",\n        \"https://www.googleapis.com/auth/drive\",\n    ]\n    hl_light_blue: ClassVar = {\n        \"backgroundColor\": {\n            \"red\": 153 / 255,\n            \"green\": 204 / 255,\n            \"blue\": 255 / 255,\n        }\n    }\n    hl_orange: ClassVar = {\"backgroundColor\": {\"red\": 5, \"green\": 2.5, \"blue\": 0}}\n\n    def __init__(\n        self,\n        *,\n        feature_tab_name: str,\n        people_tab_name: str,\n        already_selected_tab_name: str = \"\",\n        id_column: str = \"not_set\",\n        auth_json_path: Path,\n    ) -&gt; None:\n        \"\"\"\n        Args:\n        - feature_tab_name - the name of the tab/worksheet containing the features (aka categories)\n        - people_tab_name - the name of the tab/worksheet containing the people to select from\n        - already_selected_tab_name (optional) - the name of the tab/worksheet containing people who have already been selected\n        - id_column (optional) - the name of the column containing the ID. Only required if already_selected_tab_name is set\n        - auth_json_path - path to the file containing the google service account details.\n        \"\"\"\n        self.feature_tab_name = feature_tab_name\n        self.people_tab_name = people_tab_name\n        self.already_selected_tab_name = already_selected_tab_name\n        self.id_column = id_column\n        self.auth_json_path = auth_json_path\n        self._client: gspread.client.Client | None = None\n        self._spreadsheet: gspread.Spreadsheet | None = None\n        self.new_tab_default_size_rows = 2\n        self.new_tab_default_size_cols = 40\n        self._g_sheet_name = \"\"\n        self._open_g_sheet_name = \"\"\n        self.selected_tab_name = \"\"\n        self.remaining_tab_name = \"\"\n        self.tab_namer = GSheetTabNamer()\n        self._report = RunReport()\n\n    @property\n    def people_data_container(self) -&gt; str:\n        return f\"'{self.people_tab_name}' tab\"\n\n    @property\n    def already_selected_data_container(self) -&gt; str:\n        return f\"'{self.already_selected_tab_name}' tab\"\n\n    @property\n    def client(self) -&gt; gspread.client.Client:\n        if self._client is None:\n            creds = ServiceAccountCredentials.from_json_keyfile_name(str(self.auth_json_path), self.scope)\n            # if we're getting rate limited, go slower!\n            # by using the BackOffHTTPClient, that will sleep and retry\n            # if it gets an error related to API usage rate limits.\n            self._client = gspread.authorize(creds, http_client=gspread.BackOffHTTPClient)\n        return self._client\n\n    @property\n    def spreadsheet(self) -&gt; gspread.Spreadsheet:\n        if self._open_g_sheet_name != self._g_sheet_name:\n            # reset the spreadsheet if the name changed\n            self._spreadsheet = None\n            self.tab_namer.reset()\n        if self._spreadsheet is None:\n            if self._g_sheet_name.startswith(\"https://\"):\n                self._spreadsheet = self.client.open_by_url(self._g_sheet_name)\n            else:\n                self._spreadsheet = self.client.open(self._g_sheet_name)\n            self._open_g_sheet_name = self._g_sheet_name\n            self._report.add_message_and_log(\"opened_gsheet\", logging.INFO, title=self._spreadsheet.title)\n        return self._spreadsheet\n\n    def _get_tab(self, tab_name: str) -&gt; gspread.Worksheet | None:\n        if not self._g_sheet_name:\n            return None\n        tab_list = self.spreadsheet.worksheets()\n        try:\n            return next(tab for tab in tab_list if tab.title == tab_name)\n        except StopIteration:\n            return None\n\n    def _tab_exists(self, tab_name: str) -&gt; bool:\n        return bool(self._get_tab(tab_name))\n\n    def _get_tab_titles(self) -&gt; list[str]:\n        if not self._g_sheet_name:\n            return []\n        return [tab.title for tab in self.spreadsheet.worksheets()]\n\n    def _create_tab(self, tab_name: str) -&gt; gspread.Worksheet:\n        return self.spreadsheet.add_worksheet(\n            title=tab_name,\n            rows=self.new_tab_default_size_rows,\n            cols=self.new_tab_default_size_cols,\n        )\n\n    def set_g_sheet_name(self, g_sheet_name: str) -&gt; None:\n        # if we're changing spreadsheet, reset the spreadsheet object\n        if self._g_sheet_name != g_sheet_name:\n            self._spreadsheet = None\n            self._g_sheet_name = g_sheet_name\n            self.tab_namer.reset()\n\n    def get_title(self) -&gt; str:\n        try:\n            return self.spreadsheet.title\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}.\"\n            raise SelectionError(\n                message=msg, error_code=\"spreadsheet_not_found\", error_params={\"spreadsheet_name\": self._g_sheet_name}\n            ) from err\n\n    @contextmanager\n    def read_feature_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        self._report = report\n        try:\n            if not self._tab_exists(self.feature_tab_name):\n                msg = (\n                    f\"Error in Google sheet: no tab called '{self.feature_tab_name}' \"\n                    f\"found in spreadsheet '{self.spreadsheet.title}'.\"\n                )\n                raise SelectionError(\n                    message=msg,\n                    error_code=\"tab_not_found\",\n                    error_params={\"tab_name\": self.feature_tab_name, \"spreadsheet_title\": self.spreadsheet.title},\n                )\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}.\"\n            raise SelectionError(\n                message=msg, error_code=\"spreadsheet_not_found\", error_params={\"spreadsheet_name\": self._g_sheet_name}\n            ) from err\n        tab_features = self.spreadsheet.worksheet(self.feature_tab_name)\n        feature_head = tab_features.row_values(1)\n        feature_body = _stringify_records(tab_features.get_all_records(expected_headers=[]))\n        yield feature_head, feature_body\n\n    @contextmanager\n    def read_people_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        self._report = report\n        try:\n            if not self._tab_exists(self.people_tab_name):\n                msg = (\n                    f\"Error in Google sheet: no tab called '{self.people_tab_name}' \"\n                    f\"found in spreadsheet '{self.spreadsheet.title}'.\"\n                )\n                raise SelectionError(\n                    message=msg,\n                    error_code=\"tab_not_found\",\n                    error_params={\"tab_name\": self.people_tab_name, \"spreadsheet_title\": self.spreadsheet.title},\n                )\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}. \"\n            raise SelectionError(\n                message=msg, error_code=\"spreadsheet_not_found\", error_params={\"spreadsheet_name\": self._g_sheet_name}\n            ) from err\n\n        tab_people = self.spreadsheet.worksheet(self.people_tab_name)\n        # if we don't read this in here we can't check if there are 2 columns with the same name\n        people_head = tab_people.row_values(1)\n        # the numericise_ignore doesn't convert the phone numbers to ints...\n        # 1 Oct 2024: the final argument with expected_headers is to deal with the fact that\n        # updated versions of gspread can't cope with duplicate headers\n        people_body = _stringify_records(\n            tab_people.get_all_records(\n                numericise_ignore=[\"all\"],\n                expected_headers=[],\n            )\n        )\n        self._report.add_message(\"reading_gsheet_tab\", tab_name=self.people_tab_name)\n        yield people_head, people_body\n\n    @staticmethod\n    def find_header_row(\n        all_values: gspread.ValueRange | list[list[Any]], id_column: str, min_headers: int = 5\n    ) -&gt; tuple[int, list[str]]:\n        \"\"\"\n        Find the first row that looks like a header row in the worksheet.\n\n        A row is considered a header row if it has at least min_headers non-empty cells.\n        This helps skip over title rows, empty rows, etc.\n\n        Args:\n            all_values: The values from the worksheet to search\n            id_column: The text for the id_column - from settings\n            min_headers: Minimum number of non-empty cells to consider a row as headers (default: 3)\n\n        Returns:\n            Tuple of (row_number, header_values) where row_number is 1-indexed\n        \"\"\"\n        # TODO: some logging of non-empty rows that we skipped\n        # Find the first row with enough non-empty cells to be a header row\n        for row_idx, row in enumerate(all_values, start=1):\n            # Count non-empty cells in this row\n            non_empty_cells = _non_empty_cells(row)\n            # also check if the id_column is in this row\n            if len(non_empty_cells) &gt;= min_headers and id_column in non_empty_cells:\n                return row_idx, list(row)\n\n        # If no suitable header row found, return empty\n        return 1, []\n\n    @staticmethod\n    def get_valid_people_rows(\n        entire_sheet: list[list[str]], header_row_num: int, min_values: int = 5\n    ) -&gt; Generator[list[str]]:\n        \"\"\"\n        Find all rows under the header row that contain at least 3 values.\n\n        Sometimes in the spreadsheet there will be a comment in a cell underneath all the valid rows.\n        We should ignore such rows rather than attempt to convert them into an element of People.\n        \"\"\"\n        # TODO: some logging of non-empty rows that we skipped\n        all_rows_under_header = entire_sheet[header_row_num:]\n        for row in all_rows_under_header:\n            # Count non-empty cells in this row\n            non_empty_cells = _non_empty_cells(row)\n            if len(non_empty_cells) &gt; min_values:\n                yield row\n\n    @staticmethod\n    def check_header_duplicates(already_selected_head: list[str], already_selected_tab_name: str) -&gt; None:\n        counts = Counter(already_selected_head)\n        # note that we ignore empty strings when checking for duplicates\n        header_dupes = [item for item in counts if item and counts[item] &gt; 1]\n        if header_dupes:\n            msg = f\"the header row in the {already_selected_tab_name} tab contains duplicates: {header_dupes}\"\n            raise SelectionError(\n                message=msg,\n                error_code=\"already_selected_duplicate_headers\",\n                error_params={\"tab_name\": already_selected_tab_name, \"duplicates\": \", \".join(header_dupes)},\n            )\n\n    @contextmanager\n    def read_already_selected_data(\n        self, report: RunReport\n    ) -&gt; Generator[tuple[Iterable[str], Iterable[dict[str, str]]], None, None]:\n        self._report = report\n        if not self.already_selected_tab_name:\n            # If no tab name provided, return empty data\n            self._report.add_message(\"no_already_selected_tab\")\n            yield [], []\n            return\n\n        try:\n            if not self._tab_exists(self.already_selected_tab_name):\n                msg = (\n                    f\"Error in Google sheet: no tab called '{self.already_selected_tab_name}' \"\n                    f\"found in spreadsheet '{self.spreadsheet.title}'.\"\n                )\n                raise SelectionError(\n                    message=msg,\n                    error_code=\"tab_not_found\",\n                    error_params={\n                        \"tab_name\": self.already_selected_tab_name,\n                        \"spreadsheet_title\": self.spreadsheet.title,\n                    },\n                )\n        except gspread.SpreadsheetNotFound as err:\n            msg = f\"Google spreadsheet not found: {self._g_sheet_name}. \"\n            raise SelectionError(\n                message=msg, error_code=\"spreadsheet_not_found\", error_params={\"spreadsheet_name\": self._g_sheet_name}\n            ) from err\n\n        tab_already_selected = self.spreadsheet.worksheet(self.already_selected_tab_name)\n\n        # Get all values from the sheet\n        all_values = tab_already_selected.get(value_render_option=ValueRenderOption.unformatted, pad_values=True)\n\n        # Find which row contains the headers\n        header_row_num, already_selected_head = self.find_header_row(all_values, self.id_column)\n\n        # If no header row found or it's empty, return empty data\n        if not already_selected_head or not any(cell.strip() for cell in already_selected_head):\n            self._report.add_line(\n                f\"Tab '{self.already_selected_tab_name}' is empty or has no valid header row, using empty data.\"\n            )\n            yield [], []\n            return\n\n        self.check_header_duplicates(already_selected_head, self.already_selected_tab_name)\n\n        already_selected_body = _stringify_records([\n            dict(zip(already_selected_head, row, strict=False))\n            for row in self.get_valid_people_rows(all_values, header_row_num)\n        ])\n        self._report.add_message(\n            \"reading_already_selected_tab\", tab_name=self.already_selected_tab_name, header_row=header_row_num\n        )\n        yield already_selected_head, already_selected_body\n\n    def write_selected(self, selected: list[list[str]], report: RunReport) -&gt; None:\n        self.tab_namer.find_unused_tab_suffix(self._get_tab_titles())\n        tab_selected = self._create_tab(self.tab_namer.selected_tab_name())\n        report.add_message_and_log(\"writing_selected_tab\", logging.INFO, tab_name=tab_selected.title)\n        self.selected_tab_name = tab_selected.title\n        tab_selected.update(selected)\n        tab_selected.format(\"A1:U1\", self.hl_light_blue)\n        user_logger.info(f\"Selected people written to {tab_selected.title} tab\")\n\n    def write_remaining(self, remaining: list[list[str]], report: RunReport) -&gt; None:\n        # the number is selected during write_selected(), so we reuse it here\n        tab_remaining = self._create_tab(self.tab_namer.remaining_tab_name())\n        report.add_message_and_log(\"writing_remaining_tab\", logging.INFO, tab_name=tab_remaining.title)\n        self.remaining_tab_name = tab_remaining.title\n        tab_remaining.update(remaining)\n        tab_remaining.format(\"A1:U1\", self.hl_light_blue)\n\n    def highlight_dupes(self, dupes: list[int]) -&gt; None:\n        if not dupes:\n            return\n        tab_remaining = self._get_tab(self.tab_namer.remaining_tab_name())\n        assert tab_remaining is not None, \"highlight_dupes() has been called without first calling write_remaining()\"\n        # note that the indexes we have produced start at 0, but the row indexes start at 1\n        # so we need to add 1 to the indexes.\n        row_strings = [f\"A{index + 1}:U{index + 1}\" for index in dupes]\n        tab_remaining.format(row_strings, self.hl_orange)\n\n    def delete_old_output_tabs(self, dry_run: bool = False) -&gt; list[str]:\n        \"\"\"\n        Find and delete all tabs with names starting with the tab stubs for selected or remaining\n\n        Args:\n            dry_run: If True, report what would be deleted without actually deleting.\n\n        Returns:\n            List of tab names that were deleted (or would be deleted in dry_run mode).\n        \"\"\"\n        if not self._g_sheet_name:\n            return []\n\n        all_tabs = self.spreadsheet.worksheets()\n        tabs_to_delete: list[gspread.Worksheet] = []\n\n        for tab in all_tabs:\n            if self.tab_namer.matches_stubs(tab.title):\n                tabs_to_delete.append(tab)\n\n        deleted_names: list[str] = []\n        for tab in tabs_to_delete:\n            deleted_names.append(tab.title)\n            if not dry_run:\n                self.spreadsheet.del_worksheet(tab)\n\n        return deleted_names\n\n    def _annotate_parse_errors_with_cell_names(self, error: ParseTableMultiError, headers: Sequence[str]) -&gt; list[str]:\n        msgs: list[str] = []\n        for sub_error in error.all_errors:\n            if isinstance(sub_error, ParseTableErrorMsg):\n                cell_name = get_cell_name(sub_error.row, sub_error.key, headers)\n                msgs.append(f\"{sub_error.msg} - see cell {cell_name}\")\n            else:\n                cell_names = [get_cell_name(sub_error.row, key, headers) for key in sub_error.keys]\n                msgs.append(f\"{sub_error.msg} - see cells {' '.join(cell_names)}\")\n        return msgs\n\n    def customise_features_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading features from '{self.feature_tab_name}' worksheet\",\n            *self._annotate_parse_errors_with_cell_names(error, headers),\n        ])\n\n    def customise_people_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading people from '{self.people_tab_name}' worksheet\",\n            *self._annotate_parse_errors_with_cell_names(error, headers),\n        ])\n\n    def customise_already_selected_parse_error(\n        self, error: ParseTableMultiError, headers: Sequence[str]\n    ) -&gt; SelectionMultilineError:\n        return SelectionMultilineError([\n            f\"Parser error(s) while reading people from '{self.already_selected_tab_name}' worksheet\",\n            *self._annotate_parse_errors_with_cell_names(error, headers),\n        ])\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource.__init__","title":"<code>__init__(*, feature_tab_name, people_tab_name, already_selected_tab_name='', id_column='not_set', auth_json_path)</code>","text":"<p>Args: - feature_tab_name - the name of the tab/worksheet containing the features (aka categories) - people_tab_name - the name of the tab/worksheet containing the people to select from - already_selected_tab_name (optional) - the name of the tab/worksheet containing people who have already been selected - id_column (optional) - the name of the column containing the ID. Only required if already_selected_tab_name is set - auth_json_path - path to the file containing the google service account details.</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def __init__(\n    self,\n    *,\n    feature_tab_name: str,\n    people_tab_name: str,\n    already_selected_tab_name: str = \"\",\n    id_column: str = \"not_set\",\n    auth_json_path: Path,\n) -&gt; None:\n    \"\"\"\n    Args:\n    - feature_tab_name - the name of the tab/worksheet containing the features (aka categories)\n    - people_tab_name - the name of the tab/worksheet containing the people to select from\n    - already_selected_tab_name (optional) - the name of the tab/worksheet containing people who have already been selected\n    - id_column (optional) - the name of the column containing the ID. Only required if already_selected_tab_name is set\n    - auth_json_path - path to the file containing the google service account details.\n    \"\"\"\n    self.feature_tab_name = feature_tab_name\n    self.people_tab_name = people_tab_name\n    self.already_selected_tab_name = already_selected_tab_name\n    self.id_column = id_column\n    self.auth_json_path = auth_json_path\n    self._client: gspread.client.Client | None = None\n    self._spreadsheet: gspread.Spreadsheet | None = None\n    self.new_tab_default_size_rows = 2\n    self.new_tab_default_size_cols = 40\n    self._g_sheet_name = \"\"\n    self._open_g_sheet_name = \"\"\n    self.selected_tab_name = \"\"\n    self.remaining_tab_name = \"\"\n    self.tab_namer = GSheetTabNamer()\n    self._report = RunReport()\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource.delete_old_output_tabs","title":"<code>delete_old_output_tabs(dry_run=False)</code>","text":"<p>Find and delete all tabs with names starting with the tab stubs for selected or remaining</p> <p>Parameters:</p> Name Type Description Default <code>dry_run</code> <code>bool</code> <p>If True, report what would be deleted without actually deleting.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of tab names that were deleted (or would be deleted in dry_run mode).</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def delete_old_output_tabs(self, dry_run: bool = False) -&gt; list[str]:\n    \"\"\"\n    Find and delete all tabs with names starting with the tab stubs for selected or remaining\n\n    Args:\n        dry_run: If True, report what would be deleted without actually deleting.\n\n    Returns:\n        List of tab names that were deleted (or would be deleted in dry_run mode).\n    \"\"\"\n    if not self._g_sheet_name:\n        return []\n\n    all_tabs = self.spreadsheet.worksheets()\n    tabs_to_delete: list[gspread.Worksheet] = []\n\n    for tab in all_tabs:\n        if self.tab_namer.matches_stubs(tab.title):\n            tabs_to_delete.append(tab)\n\n    deleted_names: list[str] = []\n    for tab in tabs_to_delete:\n        deleted_names.append(tab.title)\n        if not dry_run:\n            self.spreadsheet.del_worksheet(tab)\n\n    return deleted_names\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource.find_header_row","title":"<code>find_header_row(all_values, id_column, min_headers=5)</code>  <code>staticmethod</code>","text":"<p>Find the first row that looks like a header row in the worksheet.</p> <p>A row is considered a header row if it has at least min_headers non-empty cells. This helps skip over title rows, empty rows, etc.</p> <p>Parameters:</p> Name Type Description Default <code>all_values</code> <code>ValueRange | list[list[Any]]</code> <p>The values from the worksheet to search</p> required <code>id_column</code> <code>str</code> <p>The text for the id_column - from settings</p> required <code>min_headers</code> <code>int</code> <p>Minimum number of non-empty cells to consider a row as headers (default: 3)</p> <code>5</code> <p>Returns:</p> Type Description <code>tuple[int, list[str]]</code> <p>Tuple of (row_number, header_values) where row_number is 1-indexed</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>@staticmethod\ndef find_header_row(\n    all_values: gspread.ValueRange | list[list[Any]], id_column: str, min_headers: int = 5\n) -&gt; tuple[int, list[str]]:\n    \"\"\"\n    Find the first row that looks like a header row in the worksheet.\n\n    A row is considered a header row if it has at least min_headers non-empty cells.\n    This helps skip over title rows, empty rows, etc.\n\n    Args:\n        all_values: The values from the worksheet to search\n        id_column: The text for the id_column - from settings\n        min_headers: Minimum number of non-empty cells to consider a row as headers (default: 3)\n\n    Returns:\n        Tuple of (row_number, header_values) where row_number is 1-indexed\n    \"\"\"\n    # TODO: some logging of non-empty rows that we skipped\n    # Find the first row with enough non-empty cells to be a header row\n    for row_idx, row in enumerate(all_values, start=1):\n        # Count non-empty cells in this row\n        non_empty_cells = _non_empty_cells(row)\n        # also check if the id_column is in this row\n        if len(non_empty_cells) &gt;= min_headers and id_column in non_empty_cells:\n            return row_idx, list(row)\n\n    # If no suitable header row found, return empty\n    return 1, []\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.GSheetDataSource.get_valid_people_rows","title":"<code>get_valid_people_rows(entire_sheet, header_row_num, min_values=5)</code>  <code>staticmethod</code>","text":"<p>Find all rows under the header row that contain at least 3 values.</p> <p>Sometimes in the spreadsheet there will be a comment in a cell underneath all the valid rows. We should ignore such rows rather than attempt to convert them into an element of People.</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>@staticmethod\ndef get_valid_people_rows(\n    entire_sheet: list[list[str]], header_row_num: int, min_values: int = 5\n) -&gt; Generator[list[str]]:\n    \"\"\"\n    Find all rows under the header row that contain at least 3 values.\n\n    Sometimes in the spreadsheet there will be a comment in a cell underneath all the valid rows.\n    We should ignore such rows rather than attempt to convert them into an element of People.\n    \"\"\"\n    # TODO: some logging of non-empty rows that we skipped\n    all_rows_under_header = entire_sheet[header_row_num:]\n    for row in all_rows_under_header:\n        # Count non-empty cells in this row\n        non_empty_cells = _non_empty_cells(row)\n        if len(non_empty_cells) &gt; min_values:\n            yield row\n</code></pre>"},{"location":"modules/#sortition_algorithms.adapters.generate_dupes","title":"<code>generate_dupes(people_remaining_rows, people_selected_rows, settings, already_selected=None)</code>","text":"<p>Generate a list of indexes of people who share an address with someone else in this set of rows.</p> <p>Note that the first row of people_remaining_rows is the column headers.  The indexes generated are for the rows in this table, so the index takes account of the first row being the header.</p> <p>So if we had people_remaining_rows:</p> <p>id,name,address_line_1,postcode 1,Alice,33 Acacia Avenue,W1A 1AA 1,Bob,31 Acacia Avenue,W1A 1AA 1,Charlotte,33 Acacia Avenue,W1A 1AA 1,David,33 Acacia Avenue,W1B 1BB</p> <p>And settings with <code>check_same_address_columns = [\"address_line_1\", \"postcode\"]</code></p> <p>Then we should return [1, 3]</p> Source code in <code>src/sortition_algorithms/adapters.py</code> <pre><code>def generate_dupes(\n    people_remaining_rows: list[list[str]],\n    people_selected_rows: list[list[str]],\n    settings: Settings,\n    already_selected: People | None = None,\n) -&gt; list[int]:\n    \"\"\"\n    Generate a list of indexes of people who share an address with someone else in this set of rows.\n\n    Note that the first row of people_remaining_rows is the column headers.  The indexes generated\n    are for the rows in this table, so the index takes account of the first row being the header.\n\n    So if we had people_remaining_rows:\n\n    id,name,address_line_1,postcode\n    1,Alice,33 Acacia Avenue,W1A 1AA\n    1,Bob,31 Acacia Avenue,W1A 1AA\n    1,Charlotte,33 Acacia Avenue,W1A 1AA\n    1,David,33 Acacia Avenue,W1B 1BB\n\n    And settings with `check_same_address_columns = [\"address_line_1\", \"postcode\"]`\n\n    Then we should return [1, 3]\n    \"\"\"\n    if not settings.check_same_address:\n        return []\n\n    table_col_names = people_remaining_rows[0]\n    address_col_indexes: list[int] = [\n        index for index, col in enumerate(table_col_names) if col in settings.check_same_address_columns\n    ]\n\n    def _address_from_row(person: list[str]) -&gt; tuple[str, ...]:\n        return tuple(col.lower() for col_index, col in enumerate(person) if col_index in address_col_indexes)\n\n    # first, we assemble a dict with the key being the address, the value being the list of\n    # indexes of people at that address\n    address_remaining_index: dict[tuple[str, ...], list[int]] = defaultdict(list)\n    for person_index, person in enumerate(people_remaining_rows[1:], start=1):  # skip the header row\n        address_remaining_index[_address_from_row(person)].append(person_index)\n\n    # now extract all those people where the number of people at their address is more than one\n    dupes: set[int] = set()\n    for persons_at_address in address_remaining_index.values():\n        if len(persons_at_address) &gt; 1:\n            dupes.update(persons_at_address)\n\n    # Now we assemble the list of all selected addresses.\n    already_selected_addresses: set[tuple[str, ...]] = set()\n    # First those selected in this round of selection\n    for person in people_selected_rows[1:]:  # skip the header row\n        already_selected_addresses.add(_address_from_row(person))\n    # Then those previously selected (if supplied)\n    if already_selected:\n        for selected_key in already_selected:\n            already_selected_addresses.add(\n                already_selected.get_address(selected_key, settings.check_same_address_columns)\n            )\n\n    # and check if any of the remaining people has an address matching\n    # those selected in this round or previous rounds\n    for person_index, person in enumerate(people_remaining_rows[1:], start=1):  # skip the header row\n        if _address_from_row(person) in already_selected_addresses:\n            dupes.add(person_index)\n\n    return sorted(dupes)\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_any_committee","title":"<code>find_any_committee(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find any single feasible committee that satisfies the quotas.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns to check for same address, or empty list if                         not checking addresses.</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], RunReport]</code> <p>tuple of (list containing one committee as frozenset of person_ids, empty report)</p> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>If quotas are infeasible</p> <code>SelectionError</code> <p>If solver fails for other reasons</p> Source code in <code>src/sortition_algorithms/committee_generation/__init__.py</code> <pre><code>def find_any_committee(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"Find any single feasible committee that satisfies the quotas.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns to check for same address, or empty list if\n                                    not checking addresses.\n\n    Returns:\n        tuple of (list containing one committee as frozenset of person_ids, empty report)\n\n    Raises:\n        InfeasibleQuotasError: If quotas are infeasible\n        SelectionError: If solver fails for other reasons\n    \"\"\"\n    _, agent_vars = setup_committee_generation(features, people, number_people_wanted, check_same_address_columns)\n    committee = ilp_results_to_committee(agent_vars)\n    return [committee], RunReport()\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_leximin","title":"<code>find_distribution_leximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the third-lowest probability and so forth.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Gurobi is not available</p> Source code in <code>src/sortition_algorithms/committee_generation/leximin.py</code> <pre><code>def find_distribution_leximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected\n    (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the\n    third-lowest probability and so forth.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    Raises:\n        RuntimeError: If Gurobi is not available\n    \"\"\"\n    if not GUROBI_AVAILABLE:\n        msg = \"Leximin algorithm requires Gurobi solver which is not available\"\n        raise RuntimeError(msg, \"gurobi_not_available\", {})\n\n    report = RunReport()\n    report.add_message_and_log(\"using_leximin_algorithm\", logging.INFO)\n    grb.setParam(\"OutputFlag\", 0)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 3 * people.count\n    )\n    report.add_report(initial_report)\n\n    # Run the main leximin optimization loop to fix agent probabilities\n    fixed_probabilities = _run_leximin_main_loop(new_committee_model, agent_vars, committees, people, report)\n\n    # Convert fixed agent probabilities to committee probabilities\n    probabilities_normalised = _solve_leximin_primal_for_final_probabilities(committees, fixed_probabilities)\n\n    return list(committees), probabilities_normalised, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_maximin","title":"<code>find_distribution_maximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/maximin.py</code> <pre><code>def find_distribution_maximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n    \"\"\"\n    report = RunReport()\n    report.add_message_and_log(\"using_maximin_algorithm\", logging.INFO)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, init_report = generate_initial_committees(new_committee_model, agent_vars, people.count)\n    report.add_report(init_report)\n\n    # Set up the incremental LP model for column generation\n    incremental_model, incr_agent_vars, upper_bound_var = _setup_maximin_incremental_model(committees, covered_agents)\n\n    # Run the main optimization loop\n    return _run_maximin_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        incremental_model,\n        incr_agent_vars,\n        upper_bound_var,\n        committees,\n        covered_agents,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_distribution_nash","title":"<code>find_distribution_nash(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of selection probabilities over all persons.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.</p> Source code in <code>src/sortition_algorithms/committee_generation/nash.py</code> <pre><code>def find_distribution_nash(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of\n    selection probabilities over all persons.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing\n    log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and\n    this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.\n    \"\"\"\n    report = RunReport()\n    report.add_message_and_log(\"using_nash_algorithm\", logging.INFO)\n\n    # Set up an ILP used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that include every possible agent\n    committee_set, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 2 * people.count\n    )\n    committees = list(committee_set)\n    report.add_report(initial_report)\n\n    # Map the covered agents to indices in a list for easier matrix representation\n    entitlements, contributes_to_entitlement = _define_entitlements(covered_agents)\n\n    # Run the main Nash welfare optimization loop\n    return _run_nash_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        committees,\n        entitlements,\n        contributes_to_entitlement,\n        covered_agents,\n        number_people_wanted,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.find_random_sample_legacy","title":"<code>find_random_sample_legacy(people, features, number_people_wanted, check_same_address_columns=None)</code>","text":"<p>Legacy stratified random selection algorithm.</p> <p>Implements the original algorithm that uses greedy selection based on priority ratios. Always selects from the most urgently needed category first (highest ratio of (min-selected)/remaining), then randomly picks within that category.</p> <p>Parameters:</p> Name Type Description Default <code>people</code> <code>People</code> <p>People collection</p> required <code>features</code> <code>FeatureCollection</code> <p>Feature definitions with min/max targets</p> required <code>number_people_wanted</code> <code>int</code> <p>Number of people to select</p> required <code>check_same_address_columns</code> <code>list[str] | None</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>Tuple of (selected_committees, output_messages) where:</p> <code>RunReport</code> <ul> <li>selected_committees: List containing one frozenset of selected person IDs</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report containing log messages about the selection process</li> </ul> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If selection becomes impossible (not enough people, etc.)</p> Source code in <code>src/sortition_algorithms/committee_generation/legacy.py</code> <pre><code>def find_random_sample_legacy(\n    people: People,\n    features: FeatureCollection,\n    number_people_wanted: int,\n    check_same_address_columns: list[str] | None = None,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"\n    Legacy stratified random selection algorithm.\n\n    Implements the original algorithm that uses greedy selection based on priority ratios.\n    Always selects from the most urgently needed category first (highest ratio of\n    (min-selected)/remaining), then randomly picks within that category.\n\n    Args:\n        people: People collection\n        features: Feature definitions with min/max targets\n        number_people_wanted: Number of people to select\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        Tuple of (selected_committees, output_messages) where:\n        - selected_committees: List containing one frozenset of selected person IDs\n        - report: report containing log messages about the selection process\n\n    Raises:\n        SelectionError: If selection becomes impossible (not enough people, etc.)\n    \"\"\"\n    report = RunReport()\n    report.add_message(\"using_legacy_algorithm\")\n    people_selected: set[str] = set()\n\n    # Create PeopleFeatures and initialize\n    people_features = PeopleFeatures(people, features, check_same_address_columns or [])\n    people_features.update_all_features_remaining()\n    people_features.prune_for_feature_max_0()\n\n    # Main selection loop\n    for count in range(number_people_wanted):\n        # Find the category with highest priority ratio\n        try:\n            ratio_result = people_features.find_max_ratio_category()\n        except errors.SelectionError as e:\n            msg = f\"Selection failed on iteration {count + 1}: {e}\"\n            raise errors.RetryableSelectionError(msg) from e\n\n        # Find the randomly selected person within that category\n        target_feature = ratio_result.feature_name\n        target_value = ratio_result.feature_value\n        random_position = ratio_result.random_person_index\n\n        selected_person_key = people_features.people.find_person_by_position_in_category(\n            target_feature, target_value, random_position\n        )\n\n        # Should never select the same person twice\n        assert selected_person_key not in people_selected, f\"Person {selected_person_key} was already selected\"\n\n        # Select the person (this also removes household members if configured)\n        people_selected.add(selected_person_key)\n        selected_person_data = people_features.people.get_person_dict(selected_person_key)\n        household_members_removed = people_features.select_person(selected_person_key)\n\n        # Add output messages about household member removal\n        if household_members_removed:\n            report.add_line(\n                f\"Selected {selected_person_key}, also removed household members: \"\n                f\"{', '.join(household_members_removed)}\"\n            )\n\n        # Handle any categories that are now full after this selection\n        try:\n            category_report = people_features.handle_category_full_deletions(selected_person_data)\n            report.add_report(category_report)\n        except errors.SelectionError as e:\n            msg = f\"Selection failed after selecting {selected_person_key}: {e}\"\n            raise errors.RetryableSelectionError(msg) from e\n\n        # Check if we're about to run out of people (but not on the last iteration)\n        if count &lt; (number_people_wanted - 1) and people_features.people.count == 0:\n            msg = \"Selection failed: Ran out of people before completing selection\"\n            raise errors.RetryableSelectionError(msg)\n\n    # Return in legacy format: list containing single frozenset\n    return [frozenset(people_selected)], report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.standardize_distribution","title":"<code>standardize_distribution(committees, probabilities)</code>","text":"<p>Remove committees with zero probability and renormalize.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities</p> required <p>Returns:</p> Type Description <code>tuple[list[frozenset[str]], list[float]]</code> <p>tuple of (filtered_committees, normalized_probabilities)</p> Source code in <code>src/sortition_algorithms/committee_generation/__init__.py</code> <pre><code>def standardize_distribution(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n) -&gt; tuple[list[frozenset[str]], list[float]]:\n    \"\"\"Remove committees with zero probability and renormalize.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities\n\n    Returns:\n        tuple of (filtered_committees, normalized_probabilities)\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    new_committees = []\n    new_probabilities = []\n    for committee, prob in zip(committees, probabilities, strict=False):\n        if prob &gt;= EPS2:\n            new_committees.append(committee)\n            new_probabilities.append(prob)\n    prob_sum = sum(new_probabilities)\n    new_probabilities = [prob / prob_sum for prob in new_probabilities]\n    return new_committees, new_probabilities\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.create_mip_model","title":"<code>create_mip_model(*, sense)</code>","text":"<p>Creates a MIP model with a sense and verbose set to zero. Can also set the seed.</p> <p>Parameters:</p> Name Type Description Default <code>sense</code> <code>str</code> <p>the sense. Key values are mip.MINIMIZE and mip.MAXIMIZE</p> required Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def create_mip_model(*, sense: str) -&gt; mip.Model:\n    \"\"\"\n    Creates a MIP model with a sense and verbose set to zero. Can also set the seed.\n\n    Args:\n        sense: the sense. Key values are mip.MINIMIZE and mip.MAXIMIZE\n    \"\"\"\n    model = mip.Model(sense=sense)\n    model.verbose = 0  # TODO: get debug level from settings\n    model.seed = random_provider().randint()\n    return model\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.generate_initial_committees","title":"<code>generate_initial_committees(new_committee_model, agent_vars, multiplicative_weights_rounds)</code>","text":"<p>To speed up the main iteration of the maximin and Nash algorithms, start from a diverse set of feasible committees. In particular, each agent that can be included in any committee will be included in at least one of these committees.</p> <p>Parameters:</p> Name Type Description Default <code>new_committee_model</code> <code>Model</code> <p>MIP model for finding committees</p> required <code>agent_vars</code> <code>dict[str, Var]</code> <p>dict mapping agent_id to binary MIP variables</p> required <code>multiplicative_weights_rounds</code> <code>int</code> <p>number of rounds for the multiplicative weights phase</p> required <p>Returns:</p> Type Description <code>set[frozenset[str]]</code> <p>tuple of (committees, covered_agents, output_lines)</p> <code>frozenset[str]</code> <ul> <li>committees: set of feasible committees discovered</li> </ul> <code>RunReport</code> <ul> <li>covered_agents: frozenset of all agents included in some committee</li> </ul> <code>tuple[set[frozenset[str]], frozenset[str], RunReport]</code> <ul> <li>report: run report</li> </ul> <code>tuple[set[frozenset[str]], frozenset[str], RunReport]</code> <ul> <li>output_lines: list of debug messages</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def generate_initial_committees(\n    new_committee_model: mip.model.Model,\n    agent_vars: dict[str, mip.entities.Var],\n    multiplicative_weights_rounds: int,\n) -&gt; tuple[set[frozenset[str]], frozenset[str], RunReport]:\n    \"\"\"To speed up the main iteration of the maximin and Nash algorithms, start from a diverse set of feasible\n    committees. In particular, each agent that can be included in any committee will be included in at least one of\n    these committees.\n\n    Args:\n        new_committee_model: MIP model for finding committees\n        agent_vars: dict mapping agent_id to binary MIP variables\n        multiplicative_weights_rounds: number of rounds for the multiplicative weights phase\n\n    Returns:\n        tuple of (committees, covered_agents, output_lines)\n        - committees: set of feasible committees discovered\n        - covered_agents: frozenset of all agents included in some committee\n        - report: run report\n        - output_lines: list of debug messages\n    \"\"\"\n    report = RunReport()\n\n    # Phase 1: Use multiplicative weights algorithm to find diverse committees\n    committees, covered_agents = _run_multiplicative_weights_phase(\n        new_committee_model, agent_vars, multiplicative_weights_rounds\n    )\n\n    # Phase 2: Find committees for any agents not yet covered\n    additional_committees, covered_agents, coverage_report = _find_committees_for_uncovered_agents(\n        new_committee_model, agent_vars, covered_agents\n    )\n    committees.update(additional_committees)\n    report.add_report(coverage_report)\n\n    # Validation and final output\n    assert len(committees) &gt;= 1  # We assume quotas are feasible at this stage\n\n    if len(covered_agents) == len(agent_vars):\n        report.add_message_and_log(\"all_agents_in_feasible_committees\", logging.INFO)\n\n    return committees, frozenset(covered_agents), report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.ilp_results_to_committee","title":"<code>ilp_results_to_committee(variables)</code>","text":"<p>Extract the selected committee from ILP solver variables.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>dict[str, Var]</code> <p>dict mapping person_id to binary MIP variables</p> required <p>Returns:</p> Type Description <code>frozenset[str]</code> <p>frozenset of person_ids who are selected (have variable value &gt; 0.5)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If variables don't have values (solver failed)</p> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def ilp_results_to_committee(variables: dict[str, mip.entities.Var]) -&gt; frozenset[str]:\n    \"\"\"Extract the selected committee from ILP solver variables.\n\n    Args:\n        variables: dict mapping person_id to binary MIP variables\n\n    Returns:\n        frozenset of person_ids who are selected (have variable value &gt; 0.5)\n\n    Raises:\n        ValueError: If variables don't have values (solver failed)\n    \"\"\"\n    try:\n        committee = frozenset(person_id for person_id in variables if variables[person_id].x &gt; 0.5)\n    # unfortunately, MIP sometimes throws generic Exceptions rather than a subclass\n    except Exception as error:\n        msg = f\"It seems like some variables do not have a value. Original exception: {error}.\"\n        raise ValueError(msg, \"variables_without_value\", {\"error\": str(error)}) from error\n\n    return committee\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.common.setup_committee_generation","title":"<code>setup_committee_generation(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Set up the integer linear program for committee generation.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns to check for same address, or empty list if                         not checking addresses.</p> required <p>Returns:</p> Type Description <code>tuple[Model, dict[str, Var]]</code> <p>tuple of (MIP model, dict mapping person_id to binary variables)</p> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>If quotas are infeasible, includes suggested relaxations</p> <code>SelectionError</code> <p>If solver fails for other reasons</p> Source code in <code>src/sortition_algorithms/committee_generation/common.py</code> <pre><code>def setup_committee_generation(\n    features: FeatureCollection, people: People, number_people_wanted: int, check_same_address_columns: list[str]\n) -&gt; tuple[mip.model.Model, dict[str, mip.entities.Var]]:\n    \"\"\"Set up the integer linear program for committee generation.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns to check for same address, or empty list if\n                                    not checking addresses.\n\n    Returns:\n        tuple of (MIP model, dict mapping person_id to binary variables)\n\n    Raises:\n        InfeasibleQuotasError: If quotas are infeasible, includes suggested relaxations\n        SelectionError: If solver fails for other reasons\n    \"\"\"\n    model = create_mip_model(sense=mip.MAXIMIZE)\n\n    # Binary variable for each person (selected/not selected)\n    agent_vars = {person_id: model.add_var(var_type=mip.BINARY) for person_id in people}\n\n    # Must select exactly the desired number of people\n    model.add_constr(mip.xsum(agent_vars.values()) == number_people_wanted)\n\n    # Respect min/max quotas for each feature value\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n        # Count people with this feature-value who are selected\n        number_feature_value_agents = mip.xsum(\n            agent_vars[person_id]\n            for person_id, person_data in people.items()\n            if person_data[feature_name].lower() == fvalue_name.lower()\n        )\n\n        # Add min/max constraints\n        model.add_constr(number_feature_value_agents &gt;= fv_minmax.min)\n        model.add_constr(number_feature_value_agents &lt;= fv_minmax.max)\n\n    # Household constraints: at most 1 person per household\n    if check_same_address_columns:\n        for housemates in people.households(check_same_address_columns).values():\n            if len(housemates) &gt; 1:\n                model.add_constr(mip.xsum(agent_vars[member_id] for member_id in housemates) &lt;= 1)\n\n    # Test feasibility by optimizing once\n    status = model.optimize()\n    if status == mip.OptimizationStatus.INFEASIBLE:\n        relaxed_features, output_lines = _relax_infeasible_quotas(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n        raise errors.InfeasibleQuotasError(relaxed_features, output_lines)\n    if status != mip.OptimizationStatus.OPTIMAL:\n        msg = (\n            f\"No feasible committees found, solver returns code {status} (see \"\n            \"https://docs.python-mip.com/en/latest/classes.html#optimizationstatus).\"\n        )\n        raise errors.SelectionError(msg)\n\n    return model, agent_vars\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.legacy.find_random_sample_legacy","title":"<code>find_random_sample_legacy(people, features, number_people_wanted, check_same_address_columns=None)</code>","text":"<p>Legacy stratified random selection algorithm.</p> <p>Implements the original algorithm that uses greedy selection based on priority ratios. Always selects from the most urgently needed category first (highest ratio of (min-selected)/remaining), then randomly picks within that category.</p> <p>Parameters:</p> Name Type Description Default <code>people</code> <code>People</code> <p>People collection</p> required <code>features</code> <code>FeatureCollection</code> <p>Feature definitions with min/max targets</p> required <code>number_people_wanted</code> <code>int</code> <p>Number of people to select</p> required <code>check_same_address_columns</code> <code>list[str] | None</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>Tuple of (selected_committees, output_messages) where:</p> <code>RunReport</code> <ul> <li>selected_committees: List containing one frozenset of selected person IDs</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report containing log messages about the selection process</li> </ul> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If selection becomes impossible (not enough people, etc.)</p> Source code in <code>src/sortition_algorithms/committee_generation/legacy.py</code> <pre><code>def find_random_sample_legacy(\n    people: People,\n    features: FeatureCollection,\n    number_people_wanted: int,\n    check_same_address_columns: list[str] | None = None,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"\n    Legacy stratified random selection algorithm.\n\n    Implements the original algorithm that uses greedy selection based on priority ratios.\n    Always selects from the most urgently needed category first (highest ratio of\n    (min-selected)/remaining), then randomly picks within that category.\n\n    Args:\n        people: People collection\n        features: Feature definitions with min/max targets\n        number_people_wanted: Number of people to select\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        Tuple of (selected_committees, output_messages) where:\n        - selected_committees: List containing one frozenset of selected person IDs\n        - report: report containing log messages about the selection process\n\n    Raises:\n        SelectionError: If selection becomes impossible (not enough people, etc.)\n    \"\"\"\n    report = RunReport()\n    report.add_message(\"using_legacy_algorithm\")\n    people_selected: set[str] = set()\n\n    # Create PeopleFeatures and initialize\n    people_features = PeopleFeatures(people, features, check_same_address_columns or [])\n    people_features.update_all_features_remaining()\n    people_features.prune_for_feature_max_0()\n\n    # Main selection loop\n    for count in range(number_people_wanted):\n        # Find the category with highest priority ratio\n        try:\n            ratio_result = people_features.find_max_ratio_category()\n        except errors.SelectionError as e:\n            msg = f\"Selection failed on iteration {count + 1}: {e}\"\n            raise errors.RetryableSelectionError(msg) from e\n\n        # Find the randomly selected person within that category\n        target_feature = ratio_result.feature_name\n        target_value = ratio_result.feature_value\n        random_position = ratio_result.random_person_index\n\n        selected_person_key = people_features.people.find_person_by_position_in_category(\n            target_feature, target_value, random_position\n        )\n\n        # Should never select the same person twice\n        assert selected_person_key not in people_selected, f\"Person {selected_person_key} was already selected\"\n\n        # Select the person (this also removes household members if configured)\n        people_selected.add(selected_person_key)\n        selected_person_data = people_features.people.get_person_dict(selected_person_key)\n        household_members_removed = people_features.select_person(selected_person_key)\n\n        # Add output messages about household member removal\n        if household_members_removed:\n            report.add_line(\n                f\"Selected {selected_person_key}, also removed household members: \"\n                f\"{', '.join(household_members_removed)}\"\n            )\n\n        # Handle any categories that are now full after this selection\n        try:\n            category_report = people_features.handle_category_full_deletions(selected_person_data)\n            report.add_report(category_report)\n        except errors.SelectionError as e:\n            msg = f\"Selection failed after selecting {selected_person_key}: {e}\"\n            raise errors.RetryableSelectionError(msg) from e\n\n        # Check if we're about to run out of people (but not on the last iteration)\n        if count &lt; (number_people_wanted - 1) and people_features.people.count == 0:\n            msg = \"Selection failed: Ran out of people before completing selection\"\n            raise errors.RetryableSelectionError(msg)\n\n    # Return in legacy format: list containing single frozenset\n    return [frozenset(people_selected)], report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.leximin.find_distribution_leximin","title":"<code>find_distribution_leximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the third-lowest probability and so forth.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Gurobi is not available</p> Source code in <code>src/sortition_algorithms/committee_generation/leximin.py</code> <pre><code>def find_distribution_leximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected\n    (just like maximin), but breaks ties to maximize the second-lowest probability, breaks further ties to maximize the\n    third-lowest probability and so forth.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    Raises:\n        RuntimeError: If Gurobi is not available\n    \"\"\"\n    if not GUROBI_AVAILABLE:\n        msg = \"Leximin algorithm requires Gurobi solver which is not available\"\n        raise RuntimeError(msg, \"gurobi_not_available\", {})\n\n    report = RunReport()\n    report.add_message_and_log(\"using_leximin_algorithm\", logging.INFO)\n    grb.setParam(\"OutputFlag\", 0)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 3 * people.count\n    )\n    report.add_report(initial_report)\n\n    # Run the main leximin optimization loop to fix agent probabilities\n    fixed_probabilities = _run_leximin_main_loop(new_committee_model, agent_vars, committees, people, report)\n\n    # Convert fixed agent probabilities to committee probabilities\n    probabilities_normalised = _solve_leximin_primal_for_final_probabilities(committees, fixed_probabilities)\n\n    return list(committees), probabilities_normalised, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.maximin.find_distribution_maximin","title":"<code>find_distribution_maximin(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> Source code in <code>src/sortition_algorithms/committee_generation/maximin.py</code> <pre><code>def find_distribution_maximin(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the minimum probability of an agent being selected.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n    \"\"\"\n    report = RunReport()\n    report.add_message_and_log(\"using_maximin_algorithm\", logging.INFO)\n\n    # Set up an ILP that can be used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that cover every possible agent\n    committees, covered_agents, init_report = generate_initial_committees(new_committee_model, agent_vars, people.count)\n    report.add_report(init_report)\n\n    # Set up the incremental LP model for column generation\n    incremental_model, incr_agent_vars, upper_bound_var = _setup_maximin_incremental_model(committees, covered_agents)\n\n    # Run the main optimization loop\n    return _run_maximin_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        incremental_model,\n        incr_agent_vars,\n        upper_bound_var,\n        committees,\n        covered_agents,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.committee_generation.nash.find_distribution_nash","title":"<code>find_distribution_nash(features, people, number_people_wanted, check_same_address_columns)</code>","text":"<p>Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of selection probabilities over all persons.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>Address columns for household identification, or empty                         if no address checking to be done.</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committees, probabilities, output_lines)</p> <code>list[float]</code> <ul> <li>committees: list of feasible committees (frozenset of agent IDs)</li> </ul> <code>RunReport</code> <ul> <li>probabilities: list of probabilities for each committee</li> </ul> <code>tuple[list[frozenset[str]], list[float], RunReport]</code> <ul> <li>output_lines: list of debug strings</li> </ul> <p>The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.</p> Source code in <code>src/sortition_algorithms/committee_generation/nash.py</code> <pre><code>def find_distribution_nash(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n) -&gt; tuple[list[frozenset[str]], list[float], RunReport]:\n    \"\"\"Find a distribution over feasible committees that maximizes the Nash welfare, i.e., the product of\n    selection probabilities over all persons.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: Address columns for household identification, or empty\n                                    if no address checking to be done.\n\n    Returns:\n        tuple of (committees, probabilities, output_lines)\n        - committees: list of feasible committees (frozenset of agent IDs)\n        - probabilities: list of probabilities for each committee\n        - output_lines: list of debug strings\n\n    The algorithm maximizes the product of selection probabilities \u03a0\u1d62 p\u1d62 by equivalently maximizing\n    log(\u03a0\u1d62 p\u1d62) = \u03a3\u1d62 log(p\u1d62). If some person i is not included in any feasible committee, their p\u1d62 is 0, and\n    this sum is -\u221e. We maximize \u03a3\u1d62 log(p\u1d62) where i is restricted to range over persons that can possibly be included.\n    \"\"\"\n    report = RunReport()\n    report.add_message_and_log(\"using_nash_algorithm\", logging.INFO)\n\n    # Set up an ILP used for discovering new feasible committees\n    new_committee_model, agent_vars = setup_committee_generation(\n        features, people, number_people_wanted, check_same_address_columns\n    )\n\n    # Find initial committees that include every possible agent\n    committee_set, covered_agents, initial_report = generate_initial_committees(\n        new_committee_model, agent_vars, 2 * people.count\n    )\n    committees = list(committee_set)\n    report.add_report(initial_report)\n\n    # Map the covered agents to indices in a list for easier matrix representation\n    entitlements, contributes_to_entitlement = _define_entitlements(covered_agents)\n\n    # Run the main Nash welfare optimization loop\n    return _run_nash_optimization_loop(\n        new_committee_model,\n        agent_vars,\n        committees,\n        entitlements,\n        contributes_to_entitlement,\n        covered_agents,\n        number_people_wanted,\n        report,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.find_random_sample","title":"<code>find_random_sample(features, people, number_people_wanted, check_same_address_columns, *, selection_algorithm='maximin', test_selection=False, number_selections=1, max_seconds=30)</code>","text":"<p>Main algorithm to find one or multiple random committees.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas</p> required <code>people</code> <code>People</code> <p>People object with pool members</p> required <code>number_people_wanted</code> <code>int</code> <p>desired size of the panel</p> required <code>check_same_address_columns</code> <code>list[str]</code> <p>columns for the address to check, or empty list if no check required</p> required <code>selection_algorithm</code> <code>str</code> <p>one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"</p> <code>'maximin'</code> <code>test_selection</code> <code>bool</code> <p>if set, do not do a random selection, but just return some valid panel. Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>how many panels to return. Most of the time, this should be set to 1, which means that a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n, containing multiple panels (some panels might be repeated in the list). In this case the eventual panel should be drawn uniformly at random from the returned list.</p> <code>1</code> <code>max_seconds</code> <code>int</code> <p>the maximum number of seconds to spend searching, for those algorithms that support it. Currently only diversimax supports this.</p> <code>30</code> <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>tuple of (committee_lottery, report)</p> <code>RunReport</code> <ul> <li>committee_lottery: list of committees, where each committee is a frozen set of pool member ids</li> </ul> <code>tuple[list[frozenset[str]], RunReport]</code> <ul> <li>report: report with debug strings</li> </ul> <p>Raises:</p> Type Description <code>InfeasibleQuotasError</code> <p>if the quotas cannot be satisfied, which includes a suggestion for how to modify them</p> <code>SelectionError</code> <p>in multiple other failure cases</p> <code>ValueError</code> <p>for invalid parameters</p> <code>RuntimeError</code> <p>if required solver is not available</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def find_random_sample(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    check_same_address_columns: list[str],\n    *,\n    selection_algorithm: str = \"maximin\",\n    test_selection: bool = False,\n    number_selections: int = 1,\n    max_seconds: int = 30,\n) -&gt; tuple[list[frozenset[str]], RunReport]:\n    \"\"\"Main algorithm to find one or multiple random committees.\n\n    Args:\n        features: FeatureCollection with min/max quotas\n        people: People object with pool members\n        number_people_wanted: desired size of the panel\n        check_same_address_columns: columns for the address to check, or empty list if no check required\n        selection_algorithm: one of \"legacy\", \"maximin\", \"leximin\", or \"nash\"\n        test_selection: if set, do not do a random selection, but just return some valid panel.\n            Useful for quickly testing whether quotas are satisfiable, but should always be false for actual selection!\n        number_selections: how many panels to return. Most of the time, this should be set to 1, which means that\n            a single panel is chosen. When specifying a value n \u2265 2, the function will return a list of length n,\n            containing multiple panels (some panels might be repeated in the list). In this case the eventual panel\n            should be drawn uniformly at random from the returned list.\n        max_seconds: the maximum number of seconds to spend searching, for those algorithms that support it.\n            Currently only diversimax supports this.\n\n    Returns:\n        tuple of (committee_lottery, report)\n        - committee_lottery: list of committees, where each committee is a frozen set of pool member ids\n        - report: report with debug strings\n\n    Raises:\n        InfeasibleQuotasError: if the quotas cannot be satisfied, which includes a suggestion for how to modify them\n        SelectionError: in multiple other failure cases\n        ValueError: for invalid parameters\n        RuntimeError: if required solver is not available\n    \"\"\"\n    # Input validation\n    if test_selection and number_selections != 1:\n        msg = (\n            \"Running the test selection does not support generating a transparent lottery, so, if \"\n            \"`test_selection` is true, `number_selections` must be 1.\"\n        )\n        raise ValueError(msg, \"test_selection_multiple_selections\", {})\n\n    if selection_algorithm == \"legacy\" and number_selections != 1:\n        msg = (\n            \"Currently, the legacy algorithm does not support generating a transparent lottery, \"\n            \"so `number_selections` must be set to 1.\"\n        )\n        raise ValueError(msg, \"legacy_multiple_selections\", {})\n    if selection_algorithm == \"diversimax\" and number_selections != 1:\n        msg = (\n            \"The diversimax algorithm does not support generating multiple committees, \"\n            \"so `number_selections` must be set to 1.\"\n        )\n        raise ValueError(msg, \"diversimax_multiple_selections\", {})\n\n    # Quick test selection using find_any_committee\n    if test_selection:\n        logger.info(\"Running test selection.\")\n        return find_any_committee(features, people, number_people_wanted, check_same_address_columns)\n\n    report = RunReport()\n\n    # Check if Gurobi is available for leximin\n    if selection_algorithm == \"leximin\" and not GUROBI_AVAILABLE:\n        report.add_message(\"gurobi_unavailable_switching\")\n        selection_algorithm = \"maximin\"\n\n    # Route to appropriate algorithm\n    if selection_algorithm == \"legacy\":\n        return find_random_sample_legacy(\n            people,\n            features,\n            number_people_wanted,\n            check_same_address_columns,\n        )\n    elif selection_algorithm == \"leximin\":\n        committees, probabilities, new_report = find_distribution_leximin(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    elif selection_algorithm == \"maximin\":\n        committees, probabilities, new_report = find_distribution_maximin(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    elif selection_algorithm == \"nash\":\n        committees, probabilities, new_report = find_distribution_nash(\n            features, people, number_people_wanted, check_same_address_columns\n        )\n    elif selection_algorithm == \"diversimax\":\n        selected_ids, new_report = find_distribution_diversimax(\n            features, people, number_people_wanted, check_same_address_columns, max_seconds=max_seconds\n        )\n        report.add_report(new_report)\n        return [selected_ids], report\n    else:\n        msg = (\n            f\"Unknown selection algorithm {selection_algorithm!r}, must be either 'legacy', 'leximin', \"\n            f\"'maximin', 'diversimax', or 'nash'.\"\n        )\n        raise ValueError(msg, \"unknown_selection_algorithm\", {\"algorithm\": selection_algorithm})\n\n    report.add_report(new_report)\n\n    # Post-process the distribution\n    committees, probabilities = standardize_distribution(committees, probabilities)\n    if len(committees) &gt; people.count:\n        report.add_message_and_log(\n            \"basic_solution_warning\",\n            logging.WARNING,\n            algorithm=selection_algorithm,\n            num_panels=len(committees),\n            num_agents=people.count,\n            min_probs=min(probabilities),\n        )\n\n    assert len(set(committees)) == len(committees)\n\n    stats_report = _distribution_stats(people, committees, probabilities)\n    report.add_report(stats_report)\n\n    # Convert to lottery\n    committee_lottery = lottery_rounding(committees, probabilities, number_selections)\n\n    return committee_lottery, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.lottery_rounding","title":"<code>lottery_rounding(committees, probabilities, number_selections)</code>","text":"<p>Convert probability distribution over committees to a discrete lottery.</p> <p>Parameters:</p> Name Type Description Default <code>committees</code> <code>list[frozenset[str]]</code> <p>list of committees</p> required <code>probabilities</code> <code>list[float]</code> <p>corresponding probabilities (must sum to 1)</p> required <code>number_selections</code> <code>int</code> <p>number of committees to return</p> required <p>Returns:</p> Type Description <code>list[frozenset[str]]</code> <p>list of committees (may contain duplicates) of length number_selections</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def lottery_rounding(\n    committees: list[frozenset[str]],\n    probabilities: list[float],\n    number_selections: int,\n) -&gt; list[frozenset[str]]:\n    \"\"\"Convert probability distribution over committees to a discrete lottery.\n\n    Args:\n        committees: list of committees\n        probabilities: corresponding probabilities (must sum to 1)\n        number_selections: number of committees to return\n\n    Returns:\n        list of committees (may contain duplicates) of length number_selections\n    \"\"\"\n    assert len(committees) == len(probabilities)\n    assert number_selections &gt;= 1\n\n    num_copies: list[int] = []\n    residuals: list[float] = []\n    for _, prob in zip(committees, probabilities, strict=False):\n        scaled_prob = prob * number_selections\n        num_copies.append(int(scaled_prob))  # give lower quotas\n        residuals.append(scaled_prob - int(scaled_prob))\n\n    rounded_up_indices = pipage_rounding(list(enumerate(residuals)))\n    for committee_index in rounded_up_indices:\n        num_copies[committee_index] += 1\n\n    committee_lottery: list[frozenset[str]] = []\n    for committee, committee_copies in zip(committees, num_copies, strict=False):\n        committee_lottery += [committee for _ in range(committee_copies)]\n\n    return committee_lottery\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.pipage_rounding","title":"<code>pipage_rounding(marginals)</code>","text":"<p>Pipage rounding algorithm for converting fractional solutions to integer solutions.</p> <p>Takes a list of (object, probability) pairs and randomly rounds them to a set of objects such that the expected number of times each object appears equals its probability.</p> <p>Parameters:</p> Name Type Description Default <code>marginals</code> <code>list[tuple[int, float]]</code> <p>list of (object, probability) pairs where probabilities sum to an integer</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list of objects that were selected</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def pipage_rounding(marginals: list[tuple[int, float]]) -&gt; list[int]:\n    \"\"\"Pipage rounding algorithm for converting fractional solutions to integer solutions.\n\n    Takes a list of (object, probability) pairs and randomly rounds them to a set of objects\n    such that the expected number of times each object appears equals its probability.\n\n    Args:\n        marginals: list of (object, probability) pairs where probabilities sum to an integer\n\n    Returns:\n        list of objects that were selected\n    \"\"\"\n    assert all(0.0 &lt;= p &lt;= 1.0 for _, p in marginals)\n\n    outcomes: list[int] = []\n    while True:\n        if len(marginals) == 0:\n            return outcomes\n        if len(marginals) == 1:\n            obj, prob = marginals[0]\n            if random_provider().uniform(0.0, 1.0) &lt; prob:\n                outcomes.append(obj)\n            marginals = []\n        else:\n            obj0, prob0 = marginals[0]\n            if prob0 &gt; 1.0 - EPS2:\n                outcomes.append(obj0)\n                marginals = marginals[1:]\n                continue\n            if prob0 &lt; EPS2:\n                marginals = marginals[1:]\n                continue\n\n            obj1, prob1 = marginals[1]\n            if prob1 &gt; 1.0 - EPS2:\n                outcomes.append(obj1)\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n            if prob1 &lt; EPS2:\n                marginals = [marginals[0]] + marginals[2:]\n                continue\n\n            inc0_dec1_amount = min(\n                1.0 - prob0, prob1\n            )  # maximal amount that prob0 can be increased and prob1 can be decreased\n            dec0_inc1_amount = min(prob0, 1.0 - prob1)\n            choice_probability = dec0_inc1_amount / (inc0_dec1_amount + dec0_inc1_amount)\n\n            if random_provider().uniform(0.0, 1.0) &lt; choice_probability:  # increase prob0 and decrease prob1\n                prob0 += inc0_dec1_amount\n                prob1 -= inc0_dec1_amount\n            else:\n                prob0 -= dec0_inc1_amount\n                prob1 += dec0_inc1_amount\n            marginals = [(obj0, prob0), (obj1, prob1)] + marginals[2:]\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.run_stratification","title":"<code>run_stratification(features, people, number_people_wanted, settings, *, test_selection=False, number_selections=1, already_selected=None, max_seconds=30)</code>","text":"<p>Run stratified random selection with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>FeatureCollection</code> <p>FeatureCollection with min/max quotas for each feature value</p> required <code>people</code> <code>People</code> <p>People object containing the pool of candidates</p> required <code>number_people_wanted</code> <code>int</code> <p>Desired size of the panel</p> required <code>settings</code> <code>Settings</code> <p>Settings object containing configuration</p> required <code>test_selection</code> <code>bool</code> <p>If True, don't randomize (for testing only)</p> <code>False</code> <code>number_selections</code> <code>int</code> <p>Number of panels to return (default: 1)</p> <code>1</code> <code>already_selected</code> <code>People | None</code> <p>People who have already been selected (optional)</p> <code>None</code> <code>max_seconds</code> <code>int</code> <p>Maximum seconds to try and find optimal answer (diversimax only)</p> <code>30</code> <p>Returns:</p> Type Description <code>bool</code> <p>Tuple of (success, selected_committees, report)</p> <code>list[frozenset[str]]</code> <ul> <li>success: Whether selection succeeded within max attempts</li> </ul> <code>RunReport</code> <ul> <li>selected_committees: List of committees (frozensets of person IDs)</li> </ul> <code>tuple[bool, list[frozenset[str]], RunReport]</code> <ul> <li>report: contains debug and status messages</li> </ul> <p>Raises:</p> Type Description <code>Exception</code> <p>If number_people_wanted is outside valid range for any feature</p> <code>ValueError</code> <p>For invalid parameters</p> <code>RuntimeError</code> <p>If required solver is not available</p> <code>InfeasibleQuotasError</code> <p>If quotas cannot be satisfied</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def run_stratification(\n    features: FeatureCollection,\n    people: People,\n    number_people_wanted: int,\n    settings: Settings,\n    *,\n    test_selection: bool = False,\n    number_selections: int = 1,\n    already_selected: People | None = None,\n    max_seconds: int = 30,\n) -&gt; tuple[bool, list[frozenset[str]], RunReport]:\n    \"\"\"Run stratified random selection with retry logic.\n\n    Args:\n        features: FeatureCollection with min/max quotas for each feature value\n        people: People object containing the pool of candidates\n        number_people_wanted: Desired size of the panel\n        settings: Settings object containing configuration\n        test_selection: If True, don't randomize (for testing only)\n        number_selections: Number of panels to return (default: 1)\n        already_selected: People who have already been selected (optional)\n        max_seconds: Maximum seconds to try and find optimal answer (diversimax only)\n\n    Returns:\n        Tuple of (success, selected_committees, report)\n        - success: Whether selection succeeded within max attempts\n        - selected_committees: List of committees (frozensets of person IDs)\n        - report: contains debug and status messages\n\n    Raises:\n        Exception: If number_people_wanted is outside valid range for any feature\n        ValueError: For invalid parameters\n        RuntimeError: If required solver is not available\n        InfeasibleQuotasError: If quotas cannot be satisfied\n    \"\"\"\n    success = False\n    report = RunReport()\n    people_selected: list[frozenset[str]] = []\n\n    try:\n        working_people = exclude_matching_selected_addresses(people, already_selected, settings)\n        dropped_count = people.count - working_people.count\n        if dropped_count:\n            report.add_line_and_log(\n                f\"Dropped {dropped_count} people who have an address matching a selected person.\", logging.INFO\n            )\n        # Check if desired number is within feature constraints\n        check_desired(features, number_people_wanted)\n        check_enough_people_for_every_feature_value(features, working_people)\n    except errors.SelectionError as error:\n        report.add_error(error)\n        return False, people_selected, report\n\n    # Set random seed if specified\n    # If the seed is zero or None, we use the secrets module, as it is better\n    # from a security point of view\n    set_random_provider(settings.random_number_seed)\n\n    if test_selection:\n        report.add_message(\"test_selection_warning\", ReportLevel.CRITICAL)\n\n    report.add_message(\"initial_state\", ReportLevel.IMPORTANT)\n    report.add_report(_initial_category_info_table(features, working_people))\n\n    tries = 0\n    for tries in range(settings.max_attempts):\n        people_selected = []\n\n        report.add_message_and_log(\"trial_number\", logging.WARNING, trial=tries + 1)\n\n        try:\n            people_selected, new_report = find_random_sample(\n                features,\n                working_people,\n                number_people_wanted,\n                settings.normalised_address_columns,\n                selection_algorithm=settings.selection_algorithm,\n                test_selection=test_selection,\n                number_selections=number_selections,\n                max_seconds=max_seconds,\n            )\n            report.add_report(new_report)\n\n            # Check if targets were met (only works for number_selections = 1)\n            # This raises an error if we did not select properly\n            _check_category_selected(features, working_people, people_selected, number_selections)\n\n            report.add_message(\"selection_success\", ReportLevel.IMPORTANT)\n            report.add_report(_category_info_table(features, working_people, people_selected, number_people_wanted))\n            success = True\n            break\n\n        except errors.SelectionError as serr:\n            if serr.is_retryable:\n                report.add_error(serr, is_fatal=False)\n                report.add_message(\"retry_after_error\", error=str(serr))\n                # we do not break here, we try again.\n            else:\n                report.add_error(serr)\n                break\n        # these are all fatal errors\n        except (ValueError, RuntimeError, errors.InfeasibleQuotasCantRelaxError) as err:\n            report.add_error(err)\n            break\n\n    if not success:\n        report.add_message(\"selection_failed\", ReportLevel.IMPORTANT, attempts=tries + 1)\n\n    return success, people_selected, report\n</code></pre>"},{"location":"modules/#sortition_algorithms.core.selected_remaining_tables","title":"<code>selected_remaining_tables(full_people, people_selected, features, settings, already_selected=None, exclude_matching_addresses=True)</code>","text":"<p>write some text</p> <p>people_selected is a single frozenset[str] - it must be unwrapped before being passed to this function.</p> Source code in <code>src/sortition_algorithms/core.py</code> <pre><code>def selected_remaining_tables(\n    full_people: People,\n    people_selected: frozenset[str],\n    features: FeatureCollection,\n    settings: Settings,\n    already_selected: People | None = None,\n    exclude_matching_addresses: bool = True,\n) -&gt; tuple[list[list[str]], list[list[str]], list[str]]:\n    \"\"\"\n    write some text\n\n    people_selected is a single frozenset[str] - it must be unwrapped before being passed\n    to this function.\n    \"\"\"\n    people_working = deepcopy(full_people)\n    output_lines: list[str] = []\n\n    # this function only reads from people, so pass in full_people\n    people_selected_rows = person_list_to_table(people_selected, full_people, features, settings)\n\n    # now delete the selected people\n    for pkey in people_selected:\n        people_working.remove(pkey)\n\n    # now delete the people at the same address as a selected person\n    # TODO: consider retiring this code once we use already_selected everywhere\n    # and then also drop exclude_matching_addresses variable\n    num_same_address_deleted = 0\n    if (\n        exclude_matching_addresses\n        and settings.check_same_address\n        and (already_selected is None or not already_selected.count)\n    ):\n        for pkey in people_selected:\n            pkey_to_delete = list(full_people.matching_address(pkey, settings.check_same_address_columns))\n            num_same_address_deleted += len(pkey_to_delete)\n            # then delete this/these people at the same address from the reserve/remaining pool\n            people_working.remove_many(pkey_to_delete)\n\n    # add the columns to keep into remaining people\n    # as above all these values are all in people_working but this is tidier...\n    # this function only reads from people, so pass in full_people\n    people_remaining_rows = person_list_to_table(people_working, full_people, features, settings)\n    return people_selected_rows, people_remaining_rows, output_lines\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.BadDataError","title":"<code>BadDataError</code>","text":"<p>               Bases: <code>SortitionBaseError</code></p> <p>Error for when bad data is found while reading things in</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class BadDataError(SortitionBaseError):\n    \"\"\"Error for when bad data is found while reading things in\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.InfeasibleQuotasCantRelaxError","title":"<code>InfeasibleQuotasCantRelaxError</code>","text":"<p>               Bases: <code>SortitionBaseError</code></p> <p>The quotas can't be met, and no feasible relaxation was found</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class InfeasibleQuotasCantRelaxError(SortitionBaseError):\n    \"\"\"The quotas can't be met, and no feasible relaxation was found\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.InfeasibleQuotasError","title":"<code>InfeasibleQuotasError</code>","text":"<p>               Bases: <code>SelectionMultilineError</code></p> <p>The quotas can't be met, and a feasible relaxation was found.</p> <p>The details of what relaxations are recommended are included in the error.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class InfeasibleQuotasError(SelectionMultilineError):\n    \"\"\"\n    The quotas can't be met, and a feasible relaxation was found.\n\n    The details of what relaxations are recommended are included in the error.\n    \"\"\"\n\n    def __init__(self, features: \"FeatureCollection\", output: list[str]) -&gt; None:\n        self.features = features\n        super().__init__(lines=[\"The quotas are infeasible:\", *output])\n\n    def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n        \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n        # Extract output from all_lines (skip first line \"The quotas are infeasible:\")\n        output = self.all_lines[1:] if len(self.all_lines) &gt; 1 else []\n        return (self.__class__, (self.features, output))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.InfeasibleQuotasError.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support pickling by returning constructor and arguments.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n    \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n    # Extract output from all_lines (skip first line \"The quotas are infeasible:\")\n    output = self.all_lines[1:] if len(self.all_lines) &gt; 1 else []\n    return (self.__class__, (self.features, output))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseErrorsCollector","title":"<code>ParseErrorsCollector</code>","text":"<p>Class that we can add errors to, but errors with empty messages will be dropped</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class ParseErrorsCollector:\n    \"\"\"Class that we can add errors to, but errors with empty messages will be dropped\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.errors: list[ParseTableErrorMsg | ParseTableMultiValueErrorMsg] = []\n\n    def __len__(self) -&gt; int:\n        \"\"\"This means that we will be falsy if len is 0, so is effectively a __bool__ as well\"\"\"\n        return len(self.errors)\n\n    def add(\n        self,\n        msg: str,\n        key: str,\n        value: str,\n        row: int,\n        row_name: str,\n        error_code: str = \"\",\n        error_params: dict[str, str] | dict[str, str | int] | None = None,\n    ) -&gt; None:\n        if msg:\n            self.errors.append(\n                ParseTableErrorMsg(\n                    row=row,\n                    row_name=row_name,\n                    key=key,\n                    value=value,\n                    msg=msg,\n                    error_code=error_code,\n                    error_params=error_params or {},\n                )\n            )\n\n    def add_multi_value(\n        self,\n        msg: str,\n        keys: list[str],\n        values: list[str],\n        row: int,\n        row_name: str,\n        error_code: str = \"\",\n        error_params: dict[str, str | int] | None = None,\n    ) -&gt; None:\n        if msg:\n            self.errors.append(\n                ParseTableMultiValueErrorMsg(\n                    row=row,\n                    row_name=row_name,\n                    keys=keys,\n                    values=values,\n                    msg=msg,\n                    error_code=error_code,\n                    error_params=error_params or {},\n                )\n            )\n\n    def to_error(self) -&gt; ParseTableMultiError:\n        return ParseTableMultiError(self.errors)\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseErrorsCollector.__len__","title":"<code>__len__()</code>","text":"<p>This means that we will be falsy if len is 0, so is effectively a bool as well</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"This means that we will be falsy if len is 0, so is effectively a __bool__ as well\"\"\"\n    return len(self.errors)\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseTableMultiError","title":"<code>ParseTableMultiError</code>","text":"<p>               Bases: <code>SelectionMultilineError</code></p> <p>Specifically for collecting errors from parsing a table</p> <p>This has information that can be collected at a low level. Then higher level code can read the errors and make a SelectionMultilineError instance with strings with more context, relating to a CSV file, Spreadsheet etc.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class ParseTableMultiError(SelectionMultilineError):\n    \"\"\"\n    Specifically for collecting errors from parsing a table\n\n    This has information that can be collected at a low level. Then higher level code can read\n    the errors and make a SelectionMultilineError instance with strings with more context,\n    relating to a CSV file, Spreadsheet etc.\n    \"\"\"\n\n    def __init__(self, errors: list[ParseTableErrorMsg | ParseTableMultiValueErrorMsg] | None = None) -&gt; None:\n        self.all_errors: list[ParseTableErrorMsg | ParseTableMultiValueErrorMsg] = errors or []\n        # Fix: Call parent __init__ to set Exception.args properly\n        super().__init__(lines=self.lines())\n\n    def __len__(self) -&gt; int:\n        \"\"\"This means that we will be falsy if len is 0, so is effectively a __bool__ as well\"\"\"\n        return len(self.all_errors)\n\n    def lines(self) -&gt; list[str]:\n        return [str(e) for e in self.all_errors]\n\n    def combine(self, other: SelectionMultilineError) -&gt; None:\n        \"\"\"Add all the lines from the other error to this one.\"\"\"\n        assert isinstance(other, ParseTableMultiError)\n        self.all_errors += other.all_errors\n\n    def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n        \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n        return (self.__class__, (self.all_errors,))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseTableMultiError.__len__","title":"<code>__len__()</code>","text":"<p>This means that we will be falsy if len is 0, so is effectively a bool as well</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"This means that we will be falsy if len is 0, so is effectively a __bool__ as well\"\"\"\n    return len(self.all_errors)\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseTableMultiError.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support pickling by returning constructor and arguments.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n    \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n    return (self.__class__, (self.all_errors,))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.ParseTableMultiError.combine","title":"<code>combine(other)</code>","text":"<p>Add all the lines from the other error to this one.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def combine(self, other: SelectionMultilineError) -&gt; None:\n    \"\"\"Add all the lines from the other error to this one.\"\"\"\n    assert isinstance(other, ParseTableMultiError)\n    self.all_errors += other.all_errors\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.RetryableSelectionError","title":"<code>RetryableSelectionError</code>","text":"<p>               Bases: <code>SelectionError</code></p> <p>For errors where the selection should be retried.</p> <p>The main case is when the legacy selection algorithm fails, it can be worth retrying as it might find something the next time around.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class RetryableSelectionError(SelectionError):\n    \"\"\"\n    For errors where the selection should be retried.\n\n    The main case is when the legacy selection algorithm fails, it can be worth\n    retrying as it might find something the next time around.\n    \"\"\"\n\n    is_retryable: bool = True\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionError","title":"<code>SelectionError</code>","text":"<p>               Bases: <code>SortitionBaseError</code></p> <p>Generic error for things that happen in selection</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class SelectionError(SortitionBaseError):\n    \"\"\"Generic error for things that happen in selection\"\"\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionMultilineError","title":"<code>SelectionMultilineError</code>","text":"<p>               Bases: <code>SelectionError</code></p> <p>Generic error for things that happen in selection - multiline</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class SelectionMultilineError(SelectionError):\n    \"\"\"Generic error for things that happen in selection - multiline\"\"\"\n\n    def __init__(\n        self,\n        lines: list[str],\n        is_retryable: bool = False,\n        error_code: str = \"\",\n        error_params: dict[str, str | int] | None = None,\n    ) -&gt; None:\n        message = \"\\n\".join(lines)\n        super().__init__(message=message, error_code=error_code, error_params=error_params)\n        self.all_lines = lines\n        self.is_retryable = is_retryable\n\n    def __str__(self) -&gt; str:\n        return \"\\n\".join(self.lines())\n\n    def to_html(self) -&gt; str:\n        return \"&lt;br /&gt;\".join(html.escape(line) for line in self.lines())\n\n    def lines(self) -&gt; list[str]:\n        return self.all_lines\n\n    def combine(self, other: \"SelectionMultilineError\") -&gt; None:\n        \"\"\"Add all the lines from the other error to this one.\"\"\"\n        self.all_lines += other.lines()\n\n    def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n        \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n        return (self.__class__, (self.all_lines, self.is_retryable, self.error_code, self.error_params))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionMultilineError.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support pickling by returning constructor and arguments.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n    \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n    return (self.__class__, (self.all_lines, self.is_retryable, self.error_code, self.error_params))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SelectionMultilineError.combine","title":"<code>combine(other)</code>","text":"<p>Add all the lines from the other error to this one.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def combine(self, other: \"SelectionMultilineError\") -&gt; None:\n    \"\"\"Add all the lines from the other error to this one.\"\"\"\n    self.all_lines += other.lines()\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SortitionBaseError","title":"<code>SortitionBaseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>A base class that allows all errors to be caught easily.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>class SortitionBaseError(Exception):\n    \"\"\"A base class that allows all errors to be caught easily.\"\"\"\n\n    is_retryable: bool = False\n\n    def __init__(\n        self, message: str = \"\", error_code: str = \"\", error_params: dict[str, str | int] | None = None\n    ) -&gt; None:\n        super().__init__(message)\n        self.error_code = error_code\n        self.error_params = error_params or {}\n        self.message = message\n\n    def to_html(self) -&gt; str:\n        return html.escape(str(self))\n\n    def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n        \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n        return (self.__class__, (self.message, self.error_code, self.error_params))\n</code></pre>"},{"location":"modules/#sortition_algorithms.errors.SortitionBaseError.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support pickling by returning constructor and arguments.</p> Source code in <code>src/sortition_algorithms/errors.py</code> <pre><code>def __reduce__(self) -&gt; tuple[type[Any], tuple[Any, ...]]:\n    \"\"\"Support pickling by returning constructor and arguments.\"\"\"\n    return (self.__class__, (self.message, self.error_code, self.error_params))\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.check_desired","title":"<code>check_desired(fc, desired_number)</code>","text":"<p>Check if the desired number of people is within the min/max of every feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_desired(fc: FeatureCollection, desired_number: int) -&gt; None:\n    \"\"\"\n    Check if the desired number of people is within the min/max of every feature.\n    \"\"\"\n    errors: list[str] = []\n    for feature_name, fvalues in fc.items():\n        if desired_number &lt; _fv_minimum_selection(fvalues) or desired_number &gt; _fv_maximum_selection(fvalues):\n            errors.append(\n                f\"The number of people to select ({desired_number}) is out of the range of \"\n                f\"the numbers of people in the {feature_name} feature. It should be within \"\n                f\"[{_fv_minimum_selection(fvalues)}, {_fv_maximum_selection(fvalues)}].\"\n            )\n    if errors:\n        raise SelectionMultilineError(errors)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.check_min_max","title":"<code>check_min_max(fc, number_to_select=0, feature_column_name='feature')</code>","text":"<p>If the min is bigger than the max we're in trouble i.e. there's an input error</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def check_min_max(fc: FeatureCollection, number_to_select: int = 0, feature_column_name: str = \"feature\") -&gt; None:\n    \"\"\"\n    If the min is bigger than the max we're in trouble i.e. there's an input error\n    \"\"\"\n    errors: list[str] = []\n    if minimum_selection(fc) &gt; maximum_selection(fc):\n        errors += report_min_max_error_details(fc, feature_column_name)\n    if number_to_select:\n        errors += report_min_max_against_number_to_select(fc, number_to_select, feature_column_name)\n    if errors:\n        raise SelectionMultilineError(errors)\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.iterate_feature_collection","title":"<code>iterate_feature_collection(features)</code>","text":"<p>Helper function to iterate over feature collection.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def iterate_feature_collection(features: FeatureCollection) -&gt; Generator[tuple[str, str, FeatureValueMinMax]]:\n    \"\"\"Helper function to iterate over feature collection.\"\"\"\n    for feature_name, feature_values in features.items():\n        for value_name, fv_minmax in feature_values.items():\n            yield feature_name, value_name, fv_minmax\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.maximum_selection","title":"<code>maximum_selection(fc)</code>","text":"<p>The maximum selection for this set of features is the smallest maximum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def maximum_selection(fc: FeatureCollection) -&gt; int:\n    \"\"\"\n    The maximum selection for this set of features is the smallest maximum selection\n    of any individual feature.\n    \"\"\"\n    if not fc:\n        return 0\n\n    return min(_fv_maximum_selection(fv) for fv in fc.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.minimum_selection","title":"<code>minimum_selection(fc)</code>","text":"<p>The minimum selection for this set of features is the largest minimum selection of any individual feature.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def minimum_selection(fc: FeatureCollection) -&gt; int:\n    \"\"\"\n    The minimum selection for this set of features is the largest minimum selection\n    of any individual feature.\n    \"\"\"\n    if not fc:\n        return 0\n\n    return max(_fv_minimum_selection(fv) for fv in fc.values())\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.read_in_features","title":"<code>read_in_features(features_head, features_body, number_to_select=0)</code>","text":"<p>Read in stratified selection features and values</p> <p>Note we do want features_head to ensure we don't have multiple columns with the same name</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def read_in_features(\n    features_head: Iterable[str], features_body: Iterable[dict[str, str]], number_to_select: int = 0\n) -&gt; tuple[FeatureCollection, str, str]:\n    \"\"\"\n    Read in stratified selection features and values\n\n    Note we do want features_head to ensure we don't have multiple columns with the same name\n    \"\"\"\n    features: FeatureCollection = CaseInsensitiveDict()\n    features_flex, filtered_headers = _feature_headers_flex(list(features_head))\n    combined_error = ParseTableMultiError()\n    feature_column_name = \"feature\"\n    feature_value_column_name = \"value\"\n    # row 1 is the header, so the body starts on row 2\n    for row_number, row in enumerate(features_body, start=2):\n        if row_number == 2:\n            _, feature_column_name = _get_feature_from_row(row)\n            _, feature_value_column_name = _get_feature_value_from_row(row)\n        # check the set of keys in the row are the same as the headers\n        assert set(filtered_headers) &lt;= set(row.keys())\n        stripped_row = utils.normalise_dict(row)\n        fname, _ = _get_feature_from_row(row)\n        if not fname:\n            continue\n        try:\n            fname, fvalue, fv_minmax = _clean_row(stripped_row, features_flex, row_number)\n        except ParseTableMultiError as error:\n            # add all the lines into one large error, so we report all the errors in one go\n            combined_error.combine(error)\n        else:\n            if fname not in features:\n                features[fname] = CaseInsensitiveDict()\n            features[fname][fvalue] = fv_minmax\n\n    # if we got any errors in the above loop, raise the combined error.\n    if combined_error:\n        raise combined_error\n\n    check_min_max(features, number_to_select=number_to_select, feature_column_name=feature_column_name)\n    # check feature_flex to see if we need to set the max here\n    # this only changes the max_flex value if these (optional) flex values are NOT set already\n    set_default_max_flex(features)\n    return CaseInsensitiveDict(features), feature_column_name, feature_value_column_name\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.report_min_max_against_number_to_select","title":"<code>report_min_max_against_number_to_select(fc, number_to_select, feature_column_name)</code>","text":"<p>If any combined minimum is &gt; number_to_select we have a problem. If any combined maximum is &lt; number_to_select we have a problem.</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def report_min_max_against_number_to_select(\n    fc: FeatureCollection, number_to_select: int, feature_column_name: str\n) -&gt; list[str]:\n    \"\"\"\n    If any combined minimum is &gt; number_to_select we have a problem.\n    If any combined maximum is &lt; number_to_select we have a problem.\n    \"\"\"\n    if not fc:\n        return []\n    errors: list[str] = []\n    for key, fv in fc.items():\n        feature_minimum = _fv_minimum_selection(fv)\n        feature_maximum = _fv_maximum_selection(fv)\n        if feature_minimum &gt; number_to_select:\n            errors.append(\n                f\"Minimum for {feature_column_name} {key} ({feature_minimum}) \"\n                f\"is more than number to select ({number_to_select})\"\n            )\n        if feature_maximum &lt; number_to_select:\n            errors.append(\n                f\"Maximum for {feature_column_name} {key} ({feature_maximum}) \"\n                f\"is less than number to select ({number_to_select})\"\n            )\n    return errors\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.report_min_max_error_details","title":"<code>report_min_max_error_details(fc, feature_column_name='feature')</code>","text":"<p>Return a list of problems in detail, so that the user can debug the errors in detail</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def report_min_max_error_details(fc: FeatureCollection, feature_column_name: str = \"feature\") -&gt; list[str]:\n    \"\"\"\n    Return a list of problems in detail, so that the user can debug the errors in detail\n    \"\"\"\n    if not fc:\n        return []\n\n    max_feature, max_val = min(((key, _fv_maximum_selection(fv)) for key, fv in fc.items()), key=lambda x: x[1])\n    min_feature, min_val = max(((key, _fv_minimum_selection(fv)) for key, fv in fc.items()), key=lambda x: x[1])\n    return [\n        f\"Inconsistent numbers in min and max in the {feature_column_name} input:\",\n        f\"The smallest maximum is {max_val} for {feature_column_name} '{max_feature}'\",\n        f\"The largest minimum is {min_val} for {feature_column_name} '{min_feature}'\",\n        f\"You need to reduce the minimums for {min_feature} or increase the maximums for {max_feature}.\",\n    ]\n</code></pre>"},{"location":"modules/#sortition_algorithms.features.set_default_max_flex","title":"<code>set_default_max_flex(fc)</code>","text":"<p>Note this only sets it if left at the default value</p> Source code in <code>src/sortition_algorithms/features.py</code> <pre><code>def set_default_max_flex(fc: FeatureCollection) -&gt; None:\n    \"\"\"Note this only sets it if left at the default value\"\"\"\n    max_flex = _safe_max_flex_val(fc)\n    for feature_values in fc.values():\n        for fv_minmax in feature_values.values():\n            fv_minmax.set_default_max_flex(max_flex)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.MaxRatioResult","title":"<code>MaxRatioResult</code>","text":"<p>Result from finding the category with maximum selection ratio.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>@define(kw_only=True, slots=True)\nclass MaxRatioResult:\n    \"\"\"Result from finding the category with maximum selection ratio.\"\"\"\n\n    feature_name: str\n    feature_value: str\n    random_person_index: int\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures","title":"<code>PeopleFeatures</code>","text":"<p>This class manipulates people and features together, making a deepcopy on init.</p> <p>It is only used by the legacy method.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class PeopleFeatures:\n    \"\"\"\n    This class manipulates people and features together, making a deepcopy on init.\n\n    It is only used by the legacy method.\n    \"\"\"\n\n    # TODO: consider naming: maybe SelectionState\n    # TODO: consider moving into committee_generation/legacy.py\n\n    def __init__(\n        self,\n        people: People,\n        features: FeatureCollection,\n        check_same_address_columns: list[str] | None = None,\n    ) -&gt; None:\n        self.people = deepcopy(people)\n        self.features = features\n        self.select_collection = select_from_feature_collection(self.features)\n        self.check_same_address_columns = check_same_address_columns or []\n\n    def update_features_remaining(self, person_key: str) -&gt; None:\n        # this will blow up if the person does not exist\n        person = self.people.get_person_dict(person_key)\n        for feature_name in self.features:\n            feature_value = person[feature_name]\n            self.select_collection[feature_name][feature_value].add_remaining()\n\n    def update_all_features_remaining(self) -&gt; None:\n        for person_key in self.people:\n            self.update_features_remaining(person_key)\n\n    def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n        \"\"\"\n        When a feature/value is \"full\" we delete everyone else in it.\n        \"Full\" means that the number selected equals the \"max\" amount - that\n        is detected elsewhere and then this method is called.\n        Returns count of those deleted, and count of those left\n        \"\"\"\n        # when a category is full we want to delete everyone in it\n        people_to_delete: list[str] = []\n        for pkey, person in self.people.items():\n            if person[feature_name].lower() == feature_value.lower():\n                people_to_delete.append(pkey)\n                for feature in self.features:\n                    current_feature_value = person[feature]\n                    try:\n                        self.select_collection[feature][current_feature_value].remove_remaining()\n                    except errors.SelectionError as e:\n                        msg = (\n                            f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                            f\"as after previous deletion no one/not enough left in {feature} \"\n                            f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                        )\n                        raise errors.RetryableSelectionError(msg) from e\n\n        self.people.remove_many(people_to_delete)\n        # return the number of people deleted and the number of people left\n        return len(people_to_delete), self.people.count\n\n    def prune_for_feature_max_0(self) -&gt; list[str]:\n        \"\"\"\n        Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n        NOT DONE: could then check if anyone is left.\n        \"\"\"\n        msg: list[str] = []\n        msg.append(f\"Number of people: {self.people.count}.\")\n        total_num_deleted = 0\n        for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(self.features):\n            if fv_minmax.max == 0:  # we don't want any of these people\n                # pass the message in as deleting them might throw an exception\n                msg.append(f\"Feature/value {feature_name}/{fvalue_name} full - deleting people...\")\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n                # if no exception was thrown above add this bit to the end of the previous message\n                msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n                total_num_deleted += num_deleted\n        # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n        # the 'remaining' file will be useless - remind the user of this!\n        if total_num_deleted &gt;= self.people.count / 2:\n            msg.append(\n                \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n                \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n            )\n        return msg\n\n    def select_person(self, person_key: str) -&gt; list[str]:\n        \"\"\"\n        Selecting a person means:\n        - remove the person from our copy of People\n        - update the `selected` and `remaining` counts of the FeatureCollection\n        - if check_same_address_columns has columns, also remove household members (without adding to selected)\n\n        Returns:\n            List of additional people removed due to same address (empty if check_same_address_columns is empty)\n        \"\"\"\n        # First, find household members if address checking is enabled (before removing the person)\n        household_members_removed = []\n        if self.check_same_address_columns:\n            household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n        # Handle the main person selection\n        person = self.people.get_person_dict(person_key)\n        for feature_name in self.features:\n            feature_value = person[feature_name]\n            self.select_collection[feature_name][feature_value].remove_remaining()\n            self.select_collection[feature_name][feature_value].add_selected()\n        self.people.remove(person_key)\n\n        # Then remove household members if any were found\n        for household_member_key in household_members_removed:\n            household_member = self.people.get_person_dict(household_member_key)\n            for feature_name in self.features:\n                feature_value = household_member[feature_name]\n                self.select_collection[feature_name][feature_value].remove_remaining()\n                # Note: we don't call add_selected() for household members\n            self.people.remove(household_member_key)\n\n        return household_members_removed\n\n    def find_max_ratio_category(self) -&gt; MaxRatioResult:\n        \"\"\"\n        Find the feature/value combination with the highest selection ratio.\n\n        The ratio is calculated as: (min - selected) / remaining\n        This represents how urgently we need people from this category.\n        Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n        Returns:\n            MaxRatioResult containing the feature name, value, and a random person index\n\n        Raises:\n            SelectionError: If insufficient people remain to meet minimum requirements\n        \"\"\"\n        max_ratio = -100.0\n        result_feature_name = \"\"\n        result_feature_value = \"\"\n        random_person_index = -1\n\n        for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n            # Check if we have insufficient people to meet minimum requirements\n            if not select_counts.sufficient_people():\n                msg = (\n                    f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{fvalue_name}. \"\n                    f\"Need {select_counts.people_still_needed} more, but only {select_counts.remaining} remaining.\"\n                )\n                raise errors.SelectionError(msg)\n\n            # Skip categories with no remaining people or max = 0\n            if select_counts.remaining == 0 or select_counts.min_max.max == 0:\n                continue\n\n            # Calculate the priority ratio\n            ratio = select_counts.people_still_needed / float(select_counts.remaining)\n\n            # Track the highest ratio category\n            if ratio &gt; max_ratio:\n                max_ratio = ratio\n                result_feature_name = feature_name\n                result_feature_value = fvalue_name\n                # from 1 to remaining\n                random_person_index = random_provider().randbelow(select_counts.remaining) + 1\n\n        # If no valid category found, all categories must be at their max or have max=0\n        if not result_feature_name:\n            msg = \"No valid categories found - all may be at maximum or have max=0\"\n            raise errors.SelectionError(msg)\n\n        return MaxRatioResult(\n            feature_name=result_feature_name,\n            feature_value=result_feature_value,\n            random_person_index=random_person_index,\n        )\n\n    def handle_category_full_deletions(self, selected_person_data: MutableMapping[str, str]) -&gt; RunReport:\n        \"\"\"\n        Check if any categories are now full after a selection and delete remaining people.\n\n        When a person is selected, some categories may reach their maximum quota.\n        This method identifies such categories and removes all remaining people from them.\n\n        Args:\n            selected_person_data: Dictionary of the selected person's feature values\n\n        Returns:\n            RunReport containing messages about categories that became full and people deleted\n\n        Raises:\n            SelectionError: If deletions would violate minimum constraints\n        \"\"\"\n        report = RunReport()\n\n        for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n            if (\n                fvalue_name.lower() == selected_person_data[feature_name].lower()\n                and select_counts.selected == select_counts.min_max.max\n            ):\n                num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n                if num_deleted &gt; 0:\n                    report.add_line(\n                        f\"Category {feature_name}/{fvalue_name} full - deleted {num_deleted} people, {num_left} left.\"\n                    )\n\n        return report\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.delete_all_with_feature_value","title":"<code>delete_all_with_feature_value(feature_name, feature_value)</code>","text":"<p>When a feature/value is \"full\" we delete everyone else in it. \"Full\" means that the number selected equals the \"max\" amount - that is detected elsewhere and then this method is called. Returns count of those deleted, and count of those left</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def delete_all_with_feature_value(self, feature_name: str, feature_value: str) -&gt; tuple[int, int]:\n    \"\"\"\n    When a feature/value is \"full\" we delete everyone else in it.\n    \"Full\" means that the number selected equals the \"max\" amount - that\n    is detected elsewhere and then this method is called.\n    Returns count of those deleted, and count of those left\n    \"\"\"\n    # when a category is full we want to delete everyone in it\n    people_to_delete: list[str] = []\n    for pkey, person in self.people.items():\n        if person[feature_name].lower() == feature_value.lower():\n            people_to_delete.append(pkey)\n            for feature in self.features:\n                current_feature_value = person[feature]\n                try:\n                    self.select_collection[feature][current_feature_value].remove_remaining()\n                except errors.SelectionError as e:\n                    msg = (\n                        f\"SELECTION IMPOSSIBLE: FAIL in delete_all_in_feature_value() \"\n                        f\"as after previous deletion no one/not enough left in {feature} \"\n                        f\"{person[feature]}. Tried to delete: {len(people_to_delete)}\"\n                    )\n                    raise errors.RetryableSelectionError(msg) from e\n\n    self.people.remove_many(people_to_delete)\n    # return the number of people deleted and the number of people left\n    return len(people_to_delete), self.people.count\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.find_max_ratio_category","title":"<code>find_max_ratio_category()</code>","text":"<p>Find the feature/value combination with the highest selection ratio.</p> <p>The ratio is calculated as: (min - selected) / remaining This represents how urgently we need people from this category. Higher ratio = more urgent need (fewer people available relative to what we still need).</p> <p>Returns:</p> Type Description <code>MaxRatioResult</code> <p>MaxRatioResult containing the feature name, value, and a random person index</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If insufficient people remain to meet minimum requirements</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def find_max_ratio_category(self) -&gt; MaxRatioResult:\n    \"\"\"\n    Find the feature/value combination with the highest selection ratio.\n\n    The ratio is calculated as: (min - selected) / remaining\n    This represents how urgently we need people from this category.\n    Higher ratio = more urgent need (fewer people available relative to what we still need).\n\n    Returns:\n        MaxRatioResult containing the feature name, value, and a random person index\n\n    Raises:\n        SelectionError: If insufficient people remain to meet minimum requirements\n    \"\"\"\n    max_ratio = -100.0\n    result_feature_name = \"\"\n    result_feature_value = \"\"\n    random_person_index = -1\n\n    for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n        # Check if we have insufficient people to meet minimum requirements\n        if not select_counts.sufficient_people():\n            msg = (\n                f\"SELECTION IMPOSSIBLE: Not enough people remaining in {feature_name}/{fvalue_name}. \"\n                f\"Need {select_counts.people_still_needed} more, but only {select_counts.remaining} remaining.\"\n            )\n            raise errors.SelectionError(msg)\n\n        # Skip categories with no remaining people or max = 0\n        if select_counts.remaining == 0 or select_counts.min_max.max == 0:\n            continue\n\n        # Calculate the priority ratio\n        ratio = select_counts.people_still_needed / float(select_counts.remaining)\n\n        # Track the highest ratio category\n        if ratio &gt; max_ratio:\n            max_ratio = ratio\n            result_feature_name = feature_name\n            result_feature_value = fvalue_name\n            # from 1 to remaining\n            random_person_index = random_provider().randbelow(select_counts.remaining) + 1\n\n    # If no valid category found, all categories must be at their max or have max=0\n    if not result_feature_name:\n        msg = \"No valid categories found - all may be at maximum or have max=0\"\n        raise errors.SelectionError(msg)\n\n    return MaxRatioResult(\n        feature_name=result_feature_name,\n        feature_value=result_feature_value,\n        random_person_index=random_person_index,\n    )\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.handle_category_full_deletions","title":"<code>handle_category_full_deletions(selected_person_data)</code>","text":"<p>Check if any categories are now full after a selection and delete remaining people.</p> <p>When a person is selected, some categories may reach their maximum quota. This method identifies such categories and removes all remaining people from them.</p> <p>Parameters:</p> Name Type Description Default <code>selected_person_data</code> <code>MutableMapping[str, str]</code> <p>Dictionary of the selected person's feature values</p> required <p>Returns:</p> Type Description <code>RunReport</code> <p>RunReport containing messages about categories that became full and people deleted</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If deletions would violate minimum constraints</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def handle_category_full_deletions(self, selected_person_data: MutableMapping[str, str]) -&gt; RunReport:\n    \"\"\"\n    Check if any categories are now full after a selection and delete remaining people.\n\n    When a person is selected, some categories may reach their maximum quota.\n    This method identifies such categories and removes all remaining people from them.\n\n    Args:\n        selected_person_data: Dictionary of the selected person's feature values\n\n    Returns:\n        RunReport containing messages about categories that became full and people deleted\n\n    Raises:\n        SelectionError: If deletions would violate minimum constraints\n    \"\"\"\n    report = RunReport()\n\n    for feature_name, fvalue_name, select_counts in iterate_select_collection(self.select_collection):\n        if (\n            fvalue_name.lower() == selected_person_data[feature_name].lower()\n            and select_counts.selected == select_counts.min_max.max\n        ):\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n            if num_deleted &gt; 0:\n                report.add_line(\n                    f\"Category {feature_name}/{fvalue_name} full - deleted {num_deleted} people, {num_left} left.\"\n                )\n\n    return report\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.prune_for_feature_max_0","title":"<code>prune_for_feature_max_0()</code>","text":"<p>Check if any feature_value.max is set to zero. if so delete everyone with that feature value NOT DONE: could then check if anyone is left.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def prune_for_feature_max_0(self) -&gt; list[str]:\n    \"\"\"\n    Check if any feature_value.max is set to zero. if so delete everyone with that feature value\n    NOT DONE: could then check if anyone is left.\n    \"\"\"\n    msg: list[str] = []\n    msg.append(f\"Number of people: {self.people.count}.\")\n    total_num_deleted = 0\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(self.features):\n        if fv_minmax.max == 0:  # we don't want any of these people\n            # pass the message in as deleting them might throw an exception\n            msg.append(f\"Feature/value {feature_name}/{fvalue_name} full - deleting people...\")\n            num_deleted, num_left = self.delete_all_with_feature_value(feature_name, fvalue_name)\n            # if no exception was thrown above add this bit to the end of the previous message\n            msg[-1] += f\" Deleted {num_deleted}, {num_left} left.\"\n            total_num_deleted += num_deleted\n    # if the total number of people deleted is lots then we're probably doing a replacement selection, which means\n    # the 'remaining' file will be useless - remind the user of this!\n    if total_num_deleted &gt;= self.people.count / 2:\n        msg.append(\n            \"&gt;&gt;&gt; WARNING &lt;&lt;&lt; That deleted MANY PEOPLE - are you doing a \"\n            \"replacement? If so your REMAINING FILE WILL BE USELESS!!!\"\n        )\n    return msg\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.PeopleFeatures.select_person","title":"<code>select_person(person_key)</code>","text":"<p>Selecting a person means: - remove the person from our copy of People - update the <code>selected</code> and <code>remaining</code> counts of the FeatureCollection - if check_same_address_columns has columns, also remove household members (without adding to selected)</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of additional people removed due to same address (empty if check_same_address_columns is empty)</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def select_person(self, person_key: str) -&gt; list[str]:\n    \"\"\"\n    Selecting a person means:\n    - remove the person from our copy of People\n    - update the `selected` and `remaining` counts of the FeatureCollection\n    - if check_same_address_columns has columns, also remove household members (without adding to selected)\n\n    Returns:\n        List of additional people removed due to same address (empty if check_same_address_columns is empty)\n    \"\"\"\n    # First, find household members if address checking is enabled (before removing the person)\n    household_members_removed = []\n    if self.check_same_address_columns:\n        household_members_removed = list(self.people.matching_address(person_key, self.check_same_address_columns))\n\n    # Handle the main person selection\n    person = self.people.get_person_dict(person_key)\n    for feature_name in self.features:\n        feature_value = person[feature_name]\n        self.select_collection[feature_name][feature_value].remove_remaining()\n        self.select_collection[feature_name][feature_value].add_selected()\n    self.people.remove(person_key)\n\n    # Then remove household members if any were found\n    for household_member_key in household_members_removed:\n        household_member = self.people.get_person_dict(household_member_key)\n        for feature_name in self.features:\n            feature_value = household_member[feature_name]\n            self.select_collection[feature_name][feature_value].remove_remaining()\n            # Note: we don't call add_selected() for household members\n        self.people.remove(household_member_key)\n\n    return household_members_removed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts","title":"<code>SelectCounts</code>","text":"Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>@define(kw_only=True, slots=True)\nclass SelectCounts:\n    min_max: FeatureValueMinMax\n    selected: int = 0\n    remaining: int = 0\n\n    def add_remaining(self) -&gt; None:\n        self.remaining += 1\n\n    def add_selected(self) -&gt; None:\n        self.selected += 1\n\n    def remove_remaining(self) -&gt; None:\n        self.remaining -= 1\n        if self.remaining == 0 and self.selected &lt; self.min_max.min:\n            msg = \"SELECTION IMPOSSIBLE: FAIL - no one/not enough left after deletion.\"\n            raise errors.RetryableSelectionError(msg)\n\n    @property\n    def hit_target(self) -&gt; bool:\n        \"\"\"Return true if selected is between min and max (inclusive)\"\"\"\n        return self.selected &gt;= self.min_max.min and self.selected &lt;= self.min_max.max\n\n    def percent_selected(self, number_people_wanted: int) -&gt; float:\n        return self.selected * 100 / float(number_people_wanted)\n\n    @property\n    def people_still_needed(self) -&gt; int:\n        \"\"\"The number of extra people to select to get to the minimum - it should never be negative\"\"\"\n        return max(self.min_max.min - self.selected, 0)\n\n    def sufficient_people(self) -&gt; bool:\n        \"\"\"\n        Return true if we can still make the minimum. So either:\n        - we have already selected at least the minimum, or\n        - the remaining number is at least as big as the number still required\n        \"\"\"\n        return self.selected &gt;= self.min_max.min or self.remaining &gt;= self.people_still_needed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.hit_target","title":"<code>hit_target</code>  <code>property</code>","text":"<p>Return true if selected is between min and max (inclusive)</p>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.people_still_needed","title":"<code>people_still_needed</code>  <code>property</code>","text":"<p>The number of extra people to select to get to the minimum - it should never be negative</p>"},{"location":"modules/#sortition_algorithms.people_features.SelectCounts.sufficient_people","title":"<code>sufficient_people()</code>","text":"<p>Return true if we can still make the minimum. So either: - we have already selected at least the minimum, or - the remaining number is at least as big as the number still required</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def sufficient_people(self) -&gt; bool:\n    \"\"\"\n    Return true if we can still make the minimum. So either:\n    - we have already selected at least the minimum, or\n    - the remaining number is at least as big as the number still required\n    \"\"\"\n    return self.selected &gt;= self.min_max.min or self.remaining &gt;= self.people_still_needed\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample","title":"<code>WeightedSample</code>","text":"Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>class WeightedSample:\n    def __init__(self, features: FeatureCollection) -&gt; None:\n        \"\"\"\n        This produces a set of lists of feature values for each feature.  Each value\n        is in the list `fv_minmax.max` times - so a random choice with represent the max.\n\n        So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n        \"black\" with max 2 we'd get:\n\n        [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n        Then making random choices from that list produces a weighted sample.\n        \"\"\"\n        self.weighted: dict[str, list[str]] = defaultdict(list)\n        for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n            self.weighted[feature_name] += [fvalue_name] * fv_minmax.max\n\n    def value_for(self, feature_name: str) -&gt; str:\n        # S311 is random numbers for crypto - but this is just for a sample file\n        return random_provider().choice(self.weighted[feature_name])\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.WeightedSample.__init__","title":"<code>__init__(features)</code>","text":"<p>This produces a set of lists of feature values for each feature.  Each value is in the list <code>fv_minmax.max</code> times - so a random choice with represent the max.</p> <p>So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and \"black\" with max 2 we'd get:</p> <p>[\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]</p> <p>Then making random choices from that list produces a weighted sample.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def __init__(self, features: FeatureCollection) -&gt; None:\n    \"\"\"\n    This produces a set of lists of feature values for each feature.  Each value\n    is in the list `fv_minmax.max` times - so a random choice with represent the max.\n\n    So if we had feature \"ethnicity\", value \"white\" w max 4, \"asian\" w max 3 and\n    \"black\" with max 2 we'd get:\n\n    [\"white\", \"white\", \"white\", \"white\", \"asian\", \"asian\", \"asian\", \"black\", \"black\"]\n\n    Then making random choices from that list produces a weighted sample.\n    \"\"\"\n    self.weighted: dict[str, list[str]] = defaultdict(list)\n    for feature_name, fvalue_name, fv_minmax in iterate_feature_collection(features):\n        self.weighted[feature_name] += [fvalue_name] * fv_minmax.max\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.iterate_select_collection","title":"<code>iterate_select_collection(select_collection)</code>","text":"<p>Helper function to iterate over select_collection.</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def iterate_select_collection(select_collection: SelectCollection) -&gt; Generator[tuple[str, str, SelectCounts]]:\n    \"\"\"Helper function to iterate over select_collection.\"\"\"\n    for feature_name, feature_values in select_collection.items():\n        for value_name, fv_counts in feature_values.items():\n            yield feature_name, value_name, fv_counts\n</code></pre>"},{"location":"modules/#sortition_algorithms.people_features.simple_add_selected","title":"<code>simple_add_selected(person_keys, people, features)</code>","text":"<p>Just add the person to the selected counts for the feature values for that person. Don't do the more complex handling of the full PeopleFeatures.add_selected()</p> Source code in <code>src/sortition_algorithms/people_features.py</code> <pre><code>def simple_add_selected(person_keys: Iterable[str], people: People, features: SelectCollection) -&gt; None:\n    \"\"\"\n    Just add the person to the selected counts for the feature values for that person.\n    Don't do the more complex handling of the full PeopleFeatures.add_selected()\n    \"\"\"\n    for person_key in person_keys:\n        person = people.get_person_dict(person_key)\n        for feature_name in features:\n            feature_value = person[feature_name]\n            features[feature_name][feature_value].add_selected()\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People","title":"<code>People</code>","text":"Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>class People:\n    def __init__(self, columns_to_keep: list[str]) -&gt; None:\n        self._columns_to_keep = columns_to_keep\n        self._full_data: dict[str, MutableMapping[str, str]] = {}\n\n    def __eq__(self, other: Any) -&gt; bool:\n        if not isinstance(other, self.__class__):\n            return False\n        return self._full_data == other._full_data and self._columns_to_keep == self._columns_to_keep\n\n    @property\n    def count(self) -&gt; int:\n        return len(self._full_data)\n\n    def __iter__(self) -&gt; Iterator[str]:\n        return iter(self._full_data)\n\n    def items(self) -&gt; ItemsView[str, MutableMapping[str, str]]:\n        return self._full_data.items()\n\n    def add(\n        self,\n        person_key: str,\n        data: MutableMapping[str, str],\n        features: FeatureCollection,\n        row_number: int,\n        feature_column_name: str = \"feature\",\n    ) -&gt; None:\n        person_full_data: MutableMapping[str, str] = CaseInsensitiveDict()\n        errors = ParseErrorsCollector()\n        # get the feature values: these are the most important and we must check them\n        for feature_name, feature_values in features.items():\n            # check for input errors here - if it's not in the list of feature values...\n            # allow for some unclean data - at least strip empty space, but only if a str!\n            # (some values will can be numbers)\n            p_value = data[feature_name]\n            if p_value in feature_values:\n                person_full_data[feature_name] = p_value\n            else:\n                if p_value:\n                    msg = f\"Value '{p_value}' not in {feature_column_name} {feature_name}\"\n                    error_code = \"value_not_in_feature\"\n                    error_params = {\n                        \"value\": p_value,\n                        \"feature_column_name\": feature_column_name,\n                        \"feature_name\": feature_name,\n                    }\n                else:\n                    msg = f\"Empty value in {feature_column_name} {feature_name}\"\n                    error_code = \"empty_value_in_feature\"\n                    error_params = {\"feature_column_name\": feature_column_name, \"feature_name\": feature_name}\n                errors.add(\n                    msg=msg,\n                    key=feature_name,\n                    value=p_value,\n                    row=row_number,\n                    row_name=person_key,\n                    error_code=error_code,\n                    error_params=error_params,\n                )\n        if errors:\n            raise errors.to_error()\n        # then get the other column values we need\n        # this is address, name etc that we need to keep for output file\n        # we don't check anything here - it's just for user convenience\n        for col in self._columns_to_keep:\n            person_full_data[col] = data[col]\n\n        # add all the data to our people object\n        self._full_data[person_key] = person_full_data\n\n    def remove(self, person_key: str) -&gt; None:\n        del self._full_data[person_key]\n\n    def remove_many(self, person_keys: Iterable[str]) -&gt; None:\n        for key in person_keys:\n            self.remove(key)\n\n    def get_person_dict(self, person_key: str) -&gt; MutableMapping[str, str]:\n        return self._full_data[person_key]\n\n    @staticmethod\n    def _address_tuple(person_dict: MutableMapping[str, str], address_columns: Iterable[str]) -&gt; tuple[str, ...]:\n        return tuple(person_dict[col].lower() for col in address_columns)\n\n    def get_address(self, person_key: str, address_columns: Iterable[str]) -&gt; tuple[str, ...]:\n        return self._address_tuple(self._full_data[person_key], address_columns)\n\n    def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n        \"\"\"\n        Generates a dict with:\n        - keys: a tuple containing the address strings\n        - values: a list of person_key for each person at that address\n        \"\"\"\n        households = defaultdict(list)\n        for person_key, person in self._full_data.items():\n            households[self._address_tuple(person, address_columns)].append(person_key)\n        return households\n\n    def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n        \"\"\"\n        Returns a list of person keys for all people who have an address matching\n        the address of the person passed in.\n        \"\"\"\n        person = self._full_data[person_key]\n        person_address = self._address_tuple(person, address_columns)\n        for loop_key, loop_person in self._full_data.items():\n            if loop_key == person_key:\n                continue  # skip the person we've been given\n            if person_address == self._address_tuple(loop_person, address_columns):\n                yield loop_key\n\n    def _iter_matching(self, feature_name: str, feature_value: str) -&gt; Generator[str]:\n        for person_key, person_dict in self._full_data.items():\n            if person_dict[feature_name].lower() == feature_value.lower():\n                yield person_key\n\n    def count_feature_value(self, feature_name: str, feature_value: str) -&gt; int:\n        return len(list(self._iter_matching(feature_name, feature_value)))\n\n    def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n        \"\"\"\n        Find the nth person (1-indexed) in a specific feature category.\n\n        Args:\n            feature_name: Name of the feature (e.g., \"gender\")\n            feature_value: Value of the feature (e.g., \"male\")\n            position: 1-indexed position within the category\n\n        Returns:\n            Person key of the person at the specified position\n\n        Raises:\n            SelectionError: If no person is found at the specified position\n        \"\"\"\n        people_in_category = list(self._iter_matching(feature_name, feature_value))\n        try:\n            return people_in_category[position - 1]\n        except IndexError:\n            # Should always find someone if position is valid\n            # If we hit this line it is a bug\n            msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n            raise SelectionError(\n                message=msg,\n                error_code=\"person_not_found\",\n                error_params={\"position\": position, \"feature_name\": feature_name, \"feature_value\": feature_value},\n            ) from None\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.find_person_by_position_in_category","title":"<code>find_person_by_position_in_category(feature_name, feature_value, position)</code>","text":"<p>Find the nth person (1-indexed) in a specific feature category.</p> <p>Parameters:</p> Name Type Description Default <code>feature_name</code> <code>str</code> <p>Name of the feature (e.g., \"gender\")</p> required <code>feature_value</code> <code>str</code> <p>Value of the feature (e.g., \"male\")</p> required <code>position</code> <code>int</code> <p>1-indexed position within the category</p> required <p>Returns:</p> Type Description <code>str</code> <p>Person key of the person at the specified position</p> <p>Raises:</p> Type Description <code>SelectionError</code> <p>If no person is found at the specified position</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def find_person_by_position_in_category(self, feature_name: str, feature_value: str, position: int) -&gt; str:\n    \"\"\"\n    Find the nth person (1-indexed) in a specific feature category.\n\n    Args:\n        feature_name: Name of the feature (e.g., \"gender\")\n        feature_value: Value of the feature (e.g., \"male\")\n        position: 1-indexed position within the category\n\n    Returns:\n        Person key of the person at the specified position\n\n    Raises:\n        SelectionError: If no person is found at the specified position\n    \"\"\"\n    people_in_category = list(self._iter_matching(feature_name, feature_value))\n    try:\n        return people_in_category[position - 1]\n    except IndexError:\n        # Should always find someone if position is valid\n        # If we hit this line it is a bug\n        msg = f\"Failed to find person at position {position} in {feature_name}/{feature_value}\"\n        raise SelectionError(\n            message=msg,\n            error_code=\"person_not_found\",\n            error_params={\"position\": position, \"feature_name\": feature_name, \"feature_value\": feature_value},\n        ) from None\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.households","title":"<code>households(address_columns)</code>","text":"<p>Generates a dict with: - keys: a tuple containing the address strings - values: a list of person_key for each person at that address</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def households(self, address_columns: list[str]) -&gt; dict[tuple[str, ...], list[str]]:\n    \"\"\"\n    Generates a dict with:\n    - keys: a tuple containing the address strings\n    - values: a list of person_key for each person at that address\n    \"\"\"\n    households = defaultdict(list)\n    for person_key, person in self._full_data.items():\n        households[self._address_tuple(person, address_columns)].append(person_key)\n    return households\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.People.matching_address","title":"<code>matching_address(person_key, address_columns)</code>","text":"<p>Returns a list of person keys for all people who have an address matching the address of the person passed in.</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def matching_address(self, person_key: str, address_columns: list[str]) -&gt; Iterable[str]:\n    \"\"\"\n    Returns a list of person keys for all people who have an address matching\n    the address of the person passed in.\n    \"\"\"\n    person = self._full_data[person_key]\n    person_address = self._address_tuple(person, address_columns)\n    for loop_key, loop_person in self._full_data.items():\n        if loop_key == person_key:\n            continue  # skip the person we've been given\n        if person_address == self._address_tuple(loop_person, address_columns):\n            yield loop_key\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.check_enough_people_for_every_feature_value","title":"<code>check_enough_people_for_every_feature_value(features, people)</code>","text":"<p>For each feature/value, if the min&gt;0, check there are enough people who have that feature/value</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def check_enough_people_for_every_feature_value(features: FeatureCollection, people: People) -&gt; None:\n    \"\"\"For each feature/value, if the min&gt;0, check there are enough people who have that feature/value\"\"\"\n    error_list: list[str] = []\n    for fname, fvalue, fv_minmax in iterate_feature_collection(features):\n        matching_count = people.count_feature_value(fname, fvalue)\n        if matching_count &lt; fv_minmax.min:\n            error_list.append(\n                f\"Not enough people with the value '{fvalue}' in category '{fname}' - \"\n                f\"the minimum is {fv_minmax.min} but we only have {matching_count}\"\n            )\n    if error_list:\n        raise SelectionMultilineError(error_list)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.check_for_duplicate_people","title":"<code>check_for_duplicate_people(people_body, settings)</code>","text":"<p>If we have rows with duplicate IDs things are going to go bad. First check for any duplicate IDs. If we find any, check if the duplicates are identical.</p> <p>Returns:</p> Type Description <code>RunReport</code> <p>RunReport containing warnings about duplicate people</p> <p>Raises:</p> Type Description <code>SelectionMultilineError</code> <p>If duplicate IDs have different data</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def check_for_duplicate_people(people_body: Iterable[MutableMapping[str, str]], settings: Settings) -&gt; RunReport:\n    \"\"\"\n    If we have rows with duplicate IDs things are going to go bad.\n    First check for any duplicate IDs. If we find any, check if the duplicates are identical.\n\n    Returns:\n        RunReport containing warnings about duplicate people\n\n    Raises:\n        SelectionMultilineError: If duplicate IDs have different data\n    \"\"\"\n    report = RunReport()\n\n    # first check for any duplicate_ids\n    id_counter = Counter(row[settings.id_column] for row in people_body)\n    duplicate_ids = {k for k, v in id_counter.items() if v &gt; 1}\n    if not duplicate_ids:\n        return report\n\n    # find the duplicate rows\n    duplicate_rows: dict[str, list[MutableMapping[str, str]]] = defaultdict(list)\n    for row in people_body:\n        pkey = row[settings.id_column]\n        if pkey in duplicate_ids:\n            duplicate_rows[pkey].append(row)\n\n    report.add_message(\"duplicate_ids_found\", count=len(duplicate_rows))\n    report.add_message(\"duplicate_ids_list\", ids=\" \".join(duplicate_rows))\n\n    # find rows where everything is not equal\n    duplicate_differing_rows: dict[str, list[MutableMapping[str, str]]] = {}\n    for key, value in duplicate_rows.items():\n        if not _all_in_list_equal(value):\n            duplicate_differing_rows[key] = value\n    if not duplicate_differing_rows:\n        report.add_message(\"duplicate_rows_identical\")\n        return report\n\n    # Build error message with full context\n    output: list[str] = []\n    output.append(f\"Found {len(duplicate_rows)} IDs that have more than one row\")\n    output.append(f\"Duplicated IDs are: {' '.join(duplicate_rows)}\")\n    output.append(f\"Found {len(duplicate_differing_rows)} IDs that have more than one row with different data\")\n    for key, value in duplicate_differing_rows.items():\n        for row in value:\n            output.append(f\"For ID '{key}' one row of data is: {row}\")\n    raise SelectionMultilineError(output)\n</code></pre>"},{"location":"modules/#sortition_algorithms.people.exclude_matching_selected_addresses","title":"<code>exclude_matching_selected_addresses(people, already_selected, settings)</code>","text":"<p>If we are checking the same addresses, then we should start by excluding people who have the same address as someone who is already selected.</p> Source code in <code>src/sortition_algorithms/people.py</code> <pre><code>def exclude_matching_selected_addresses(people: People, already_selected: People | None, settings: Settings) -&gt; People:\n    \"\"\"\n    If we are checking the same addresses, then we should start by excluding people\n    who have the same address as someone who is already selected.\n    \"\"\"\n    if already_selected is None or not already_selected.count or not settings.check_same_address:\n        return people\n    selected_addresses = {\n        already_selected.get_address(pkey, settings.check_same_address_columns) for pkey in already_selected\n    }\n    new_people = deepcopy(people)\n    for person_key in people:\n        if people.get_address(person_key, settings.check_same_address_columns) in selected_addresses:\n            new_people.remove(person_key)\n    return new_people\n</code></pre>"},{"location":"modules/#sortition_algorithms.settings.Settings","title":"<code>Settings</code>","text":"<p>Settings to use when selecting committees. Note that only the first two are required. A minimal example would be:</p> <p>Settings(id_column=\"my_id\", columns_to_keep=[\"name\", \"email\"])</p> Source code in <code>src/sortition_algorithms/settings.py</code> <pre><code>@define\nclass Settings:\n    \"\"\"\n    Settings to use when selecting committees. Note that only the first two are required.\n    A minimal example would be:\n\n    Settings(id_column=\"my_id\", columns_to_keep=[\"name\", \"email\"])\n    \"\"\"\n\n    # required\n    id_column: str = field(validator=validators.instance_of(str))\n    columns_to_keep: list[str] = field()\n\n    # fields with defaults\n    check_same_address: bool = field(validator=validators.instance_of(bool), default=False)\n    check_same_address_columns: list[str] = field(validator=check_columns_for_same_address, factory=list)\n    max_attempts: int = field(validator=validators.instance_of(int), default=100)\n    selection_algorithm: str = field(default=\"maximin\")\n    random_number_seed: int = field(validator=validators.instance_of(int), default=0)\n\n    @columns_to_keep.validator\n    def check_columns_to_keep(self, attribute: Any, value: Any) -&gt; None:\n        if not isinstance(value, list):\n            raise TypeError(\"columns_to_keep must be a LIST of strings\", \"columns_to_keep_not_list\", {})\n        if not all(isinstance(element, str) for element in value):\n            raise TypeError(\"columns_to_keep must be a list of STRINGS\", \"columns_to_keep_not_strings\", {})\n\n    @selection_algorithm.validator\n    def check_selection_algorithm(self, attribute: Any, value: str) -&gt; None:\n        if value not in SELECTION_ALGORITHMS:\n            algorithms_str = \", \".join(SELECTION_ALGORITHMS)\n            raise ValueError(\n                f\"selection_algorithm {value} is not one of: {algorithms_str}\",\n                \"invalid_selection_algorithm\",\n                {\"algorithm\": value, \"valid_algorithms\": algorithms_str},\n            )\n\n    @property\n    def normalised_address_columns(self) -&gt; list[str]:\n        \"\"\"\n        Returns an empty list if address columns should not be checked (or if the columns\n        specified was an empty list). Otherwise return the columns. That way other code can\n        just check if the columns are empty rather than checking the bool separately.\n        \"\"\"\n        return self.check_same_address_columns if self.check_same_address else []\n\n    @property\n    def full_columns_to_keep(self) -&gt; list[str]:\n        \"\"\"\n        We always need to keep the address columns, so in case they are not listed in\n        self.columns_to_keep we have this property to have the combined list.\n        \"\"\"\n        extra_address_columns = [col for col in self.check_same_address_columns if col not in self.columns_to_keep]\n        return [*self.columns_to_keep, *extra_address_columns]\n\n    def as_dict(self) -&gt; dict[str, Any]:\n        dict_repr = unstructure(self)\n        assert isinstance(dict_repr, dict)\n        assert all(isinstance(key, str) for key in dict_repr)\n        return dict_repr\n\n    @classmethod\n    def load_from_file(\n        cls,\n        settings_file_path: Path,\n    ) -&gt; tuple[\"Settings\", RunReport]:\n        report = RunReport()\n        if not settings_file_path.is_file():\n            with open(settings_file_path, \"w\", encoding=\"utf-8\") as settings_file:\n                settings_file.write(DEFAULT_SETTINGS)\n            report.add_message(\"wrote_default_settings\", file_path=str(settings_file_path.absolute()))\n        with open(settings_file_path, \"rb\") as settings_file:\n            settings = tomllib.load(settings_file)\n        # you can't check an address if there is no info about which columns to check...\n        if settings[\"check_same_address\"] is False:\n            report.add_message(\"address_checking_disabled_warning\", level=ReportLevel.IMPORTANT)\n            settings[\"check_same_address_columns\"] = []\n        return structure(settings, cls), report\n</code></pre>"},{"location":"modules/#sortition_algorithms.settings.Settings.full_columns_to_keep","title":"<code>full_columns_to_keep</code>  <code>property</code>","text":"<p>We always need to keep the address columns, so in case they are not listed in self.columns_to_keep we have this property to have the combined list.</p>"},{"location":"modules/#sortition_algorithms.settings.Settings.normalised_address_columns","title":"<code>normalised_address_columns</code>  <code>property</code>","text":"<p>Returns an empty list if address columns should not be checked (or if the columns specified was an empty list). Otherwise return the columns. That way other code can just check if the columns are empty rather than checking the bool separately.</p>"},{"location":"modules/#sortition_algorithms.utils.RandomProvider","title":"<code>RandomProvider</code>","text":"<p>               Bases: <code>ABC</code></p> <p>This is something of a hack. Mostly we want to use the <code>secrets</code> module. But for repeatable testing we might want to set the random.seed sometimes.</p> <p>So we have a global <code>_random_provider</code> which can be switched between an instance of this class that uses the <code>secrets</code> module and an instance that uses <code>random</code> with a seed. The switch is done by the <code>set_random_provider()</code> function.</p> <p>Then every time we want some randomness, we call <code>random_provider()</code> to get the current version of the global.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>class RandomProvider(ABC):\n    \"\"\"\n    This is something of a hack. Mostly we want to use the `secrets` module.\n    But for repeatable testing we might want to set the random.seed sometimes.\n\n    So we have a global `_random_provider` which can be switched between an\n    instance of this class that uses the `secrets` module and an instance that\n    uses `random` with a seed. The switch is done by the `set_random_provider()`\n    function.\n\n    Then every time we want some randomness, we call `random_provider()` to get\n    the current version of the global.\n    \"\"\"\n\n    # tests fail if we use sys.maxsize, so we use the max signed 32 bit int instead\n    max_int = 2**31 - 1\n\n    @classmethod\n    @abstractmethod\n    def uniform(cls, lower: float, upper: float) -&gt; float: ...\n\n    @classmethod\n    @abstractmethod\n    def randbelow(cls, upper: int) -&gt; int: ...\n\n    @classmethod\n    def randint(cls) -&gt; int:\n        return cls.randbelow(cls.max_int)\n\n    @classmethod\n    @abstractmethod\n    def choice(cls, seq: \"SupportsLenAndGetItem[str]\") -&gt; str: ...\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport","title":"<code>RunReport</code>","text":"<p>A class to hold a report to show to the user at the end</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>@define(eq=True)\nclass RunReport:\n    \"\"\"A class to hold a report to show to the user at the end\"\"\"\n\n    _data: list[RunLineLevel | RunTable | RunError] = field(factory=list)\n\n    def __bool__(self) -&gt; bool:\n        \"\"\"\n        Basically, False is the report is empty, or True if there is some content. So you can do\n        things like\n\n        ```\n        if run_report:\n            print(f\"Run Report\\n\\n{run_report.as_text()}\")\n        ```\n        \"\"\"\n        return self.has_content()\n\n    def serialize(self) -&gt; dict[str, Any]:\n        return _converter.unstructure(self)  # type: ignore[no-any-return]\n\n    @classmethod\n    def deserialize(cls, serialized_data: dict[str, Any]) -&gt; \"RunReport\":\n        return _converter.structure(serialized_data, cls)\n\n    def has_content(self) -&gt; bool:\n        \"\"\"\n        False is the report is empty, or True if there is some content. So you can do\n        things like\n\n        ```\n        if run_report.has_content():\n            print(f\"Run Report\\n\\n{run_report.as_text()}\")\n        ```\n        \"\"\"\n        return bool(self._data)\n\n    def add_line(\n        self,\n        line: str,\n        level: ReportLevel = ReportLevel.NORMAL,\n        message_code: str | None = None,\n        message_params: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n        Args:\n            line: The English message text (for backward compatibility and standalone use)\n            level: Importance level of the message\n            message_code: Optional translation key for i18n (e.g., \"loading_features_from_file\")\n            message_params: Optional parameters for message translation (e.g., {\"file_path\": \"features.csv\"})\n        \"\"\"\n        self._data.append(RunLineLevel(line, level, message_code=message_code, message_params=message_params or {}))\n\n    def add_line_and_log(\n        self,\n        line: str,\n        log_level: int,\n        message_code: str | None = None,\n        message_params: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n        This method will also log the message to the `user_logger`. This message can be shown to the user as\n        the run is happening, so the user has feedback on what is going on while the run is in progress.\n\n        When generating the report we can skip those messages, to avoid duplication. But if the user_logger\n        has not been set up to be shown to the user during the run, we do want those messages to be in the\n        final report.\n\n        Args:\n            line: The English message text (for backward compatibility and standalone use)\n            log_level: Logging level for the message\n            message_code: Optional translation key for i18n (e.g., \"trial_number\")\n            message_params: Optional parameters for message translation (e.g., {\"trial\": 3})\n        \"\"\"\n        self._data.append(\n            RunLineLevel(\n                line, ReportLevel.NORMAL, log_level, message_code=message_code, message_params=message_params or {}\n            )\n        )\n        user_logger.log(level=log_level, msg=line)\n\n    def add_message(self, code: str, level: ReportLevel = ReportLevel.NORMAL, **params: Any) -&gt; None:\n        \"\"\"\n        Add a translatable message using a message code and parameters.\n\n        This is a convenience method that combines get_message() and add_line() in one call,\n        making it simpler to add messages with translation support.\n\n        Args:\n            code: The message code from REPORT_MESSAGES (e.g., \"loading_features_from_file\")\n            level: Importance level of the message\n            **params: Parameters to substitute into the message template\n\n        Example:\n            &gt;&gt;&gt; report.add_message(\"features_found\", count=5)\n            &gt;&gt;&gt; report.add_message(\"trial_number\", ReportLevel.IMPORTANT, trial=3)\n        \"\"\"\n        message = get_message(code, **params)\n        self.add_line(message, level=level, message_code=code, message_params=params)\n\n    def add_message_and_log(self, code: str, log_level: int, **params: Any) -&gt; None:\n        \"\"\"\n        Add a translatable message using a message code and parameters, and log it.\n\n        This is a convenience method that combines get_message() and add_line_and_log() in one call,\n        making it simpler to add messages with translation support that are also logged.\n\n        Args:\n            code: The message code from REPORT_MESSAGES (e.g., \"trial_number\")\n            log_level: Logging level for the message\n            **params: Parameters to substitute into the message template\n\n        Example:\n            &gt;&gt;&gt; report.add_message_and_log(\"trial_number\", logging.WARNING, trial=3)\n            &gt;&gt;&gt; report.add_message_and_log(\"basic_solution_warning\", logging.WARNING, algorithm=\"maximin\", num_panels=150, num_agents=100, min_probs=0.001)\n        \"\"\"\n        message = get_message(code, **params)\n        self.add_line_and_log(message, log_level, message_code=code, message_params=params)\n\n    def add_lines(self, lines: Iterable[str], level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n        \"\"\"\n        Add multiple lines of text with the same level.\n\n        .. deprecated:: (next version)\n            This method is deprecated. Functions should return RunReport instead of list[str],\n            and callers should use add_report() to merge them. This provides better support\n            for translation and structured reporting.\n        \"\"\"\n        warnings.warn(\n            \"add_lines() is deprecated. Functions should return RunReport instead of list[str], \"\n            \"and use add_report() to merge them.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        for line in lines:\n            self._data.append(RunLineLevel(line, level))\n\n    def add_table(self, table_headings: list[str], table_data: list[list[str | int | float]]) -&gt; None:\n        self._data.append(RunTable(table_headings, table_data))\n\n    def add_error(self, error: Exception, is_fatal: bool = True) -&gt; None:\n        self._data.append(RunError(error, is_fatal=is_fatal))\n\n    def add_report(self, other: \"RunReport\") -&gt; None:\n        self._data += other._data\n\n    def _element_to_text(self, element: RunLineLevel | RunTable | RunError, include_logged: bool) -&gt; str | None:\n        if isinstance(element, RunLineLevel):\n            # we might want to skip lines that were already logged\n            if include_logged or element.log_level == logging.NOTSET:\n                return element.line\n            else:\n                # sometimes we want empty strings for blank lines, so here we return None\n                # instead so the logged lines can be filtered out\n                return None\n        elif isinstance(element, RunTable):\n            table_text = tabulate(element.data, headers=element.headers, tablefmt=\"simple\")\n            # we want a blank line before and after the table.\n            return f\"\\n{table_text}\\n\"\n        else:\n            return str(element.error)\n\n    def as_text(self, include_logged: bool = True) -&gt; str:\n        parts = [self._element_to_text(element, include_logged) for element in self._data]\n        return \"\\n\".join(p for p in parts if p is not None)\n\n    def _line_to_html(self, line_level: RunLineLevel) -&gt; str:\n        tags = {\n            ReportLevel.NORMAL: (\"\", \"\"),\n            ReportLevel.IMPORTANT: (\"&lt;b&gt;\", \"&lt;/b&gt;\"),\n            ReportLevel.CRITICAL: ('&lt;b style=\"color: red\"&gt;', \"&lt;/b&gt;\"),\n        }\n        start_tag, end_tag = tags[line_level.level]\n        escaped_line = html.escape(line_level.line)\n        return f\"{start_tag}{escaped_line}{end_tag}\"\n\n    def _error_to_html(self, run_error: RunError) -&gt; str:\n        start_tag, end_tag = (\"&lt;b&gt;\", \"&lt;/b&gt;\") if run_error.is_fatal else (\"\", \"\")\n        if isinstance(run_error.error, errors.SortitionBaseError):\n            return f\"{start_tag}{run_error.error.to_html()}{end_tag}\"\n        # default to the string representation\n        return f\"{start_tag}{run_error.error}{end_tag}\"\n\n    def _element_to_html(self, element: RunLineLevel | RunTable | RunError, include_logged: bool) -&gt; str | None:\n        if isinstance(element, RunLineLevel):\n            if include_logged or element.log_level == logging.NOTSET:\n                return self._line_to_html(element)\n            else:\n                return None\n        elif isinstance(element, RunTable):\n            return tabulate(element.data, headers=element.headers, tablefmt=\"html\")\n        else:\n            return self._error_to_html(element)\n\n    def as_html(self, include_logged: bool = True) -&gt; str:\n        parts = [self._element_to_html(element, include_logged) for element in self._data]\n        return \"&lt;br /&gt;\\n\".join(p for p in parts if p is not None)\n\n    def last_error(self) -&gt; Exception | None:\n        for element in reversed(self._data):\n            if isinstance(element, RunError):\n                return element.error\n        return None\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.__bool__","title":"<code>__bool__()</code>","text":"<pre><code>    Basically, False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report:\n        print(f\"Run Report\n</code></pre> <p>{run_report.as_text()}\")         ```</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def __bool__(self) -&gt; bool:\n    \"\"\"\n    Basically, False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report:\n        print(f\"Run Report\\n\\n{run_report.as_text()}\")\n    ```\n    \"\"\"\n    return self.has_content()\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_line","title":"<code>add_line(line, level=ReportLevel.NORMAL, message_code=None, message_params=None)</code>","text":"<p>Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The English message text (for backward compatibility and standalone use)</p> required <code>level</code> <code>ReportLevel</code> <p>Importance level of the message</p> <code>NORMAL</code> <code>message_code</code> <code>str | None</code> <p>Optional translation key for i18n (e.g., \"loading_features_from_file\")</p> <code>None</code> <code>message_params</code> <code>dict[str, Any] | None</code> <p>Optional parameters for message translation (e.g., {\"file_path\": \"features.csv\"})</p> <code>None</code> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_line(\n    self,\n    line: str,\n    level: ReportLevel = ReportLevel.NORMAL,\n    message_code: str | None = None,\n    message_params: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n    Args:\n        line: The English message text (for backward compatibility and standalone use)\n        level: Importance level of the message\n        message_code: Optional translation key for i18n (e.g., \"loading_features_from_file\")\n        message_params: Optional parameters for message translation (e.g., {\"file_path\": \"features.csv\"})\n    \"\"\"\n    self._data.append(RunLineLevel(line, level, message_code=message_code, message_params=message_params or {}))\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_line_and_log","title":"<code>add_line_and_log(line, log_level, message_code=None, message_params=None)</code>","text":"<p>Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.</p> <p>This method will also log the message to the <code>user_logger</code>. This message can be shown to the user as the run is happening, so the user has feedback on what is going on while the run is in progress.</p> <p>When generating the report we can skip those messages, to avoid duplication. But if the user_logger has not been set up to be shown to the user during the run, we do want those messages to be in the final report.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The English message text (for backward compatibility and standalone use)</p> required <code>log_level</code> <code>int</code> <p>Logging level for the message</p> required <code>message_code</code> <code>str | None</code> <p>Optional translation key for i18n (e.g., \"trial_number\")</p> <code>None</code> <code>message_params</code> <code>dict[str, Any] | None</code> <p>Optional parameters for message translation (e.g., {\"trial\": 3})</p> <code>None</code> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_line_and_log(\n    self,\n    line: str,\n    log_level: int,\n    message_code: str | None = None,\n    message_params: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Add a line of text, and a level - so important/critical messages can be highlighted in the HTML report.\n\n    This method will also log the message to the `user_logger`. This message can be shown to the user as\n    the run is happening, so the user has feedback on what is going on while the run is in progress.\n\n    When generating the report we can skip those messages, to avoid duplication. But if the user_logger\n    has not been set up to be shown to the user during the run, we do want those messages to be in the\n    final report.\n\n    Args:\n        line: The English message text (for backward compatibility and standalone use)\n        log_level: Logging level for the message\n        message_code: Optional translation key for i18n (e.g., \"trial_number\")\n        message_params: Optional parameters for message translation (e.g., {\"trial\": 3})\n    \"\"\"\n    self._data.append(\n        RunLineLevel(\n            line, ReportLevel.NORMAL, log_level, message_code=message_code, message_params=message_params or {}\n        )\n    )\n    user_logger.log(level=log_level, msg=line)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_lines","title":"<code>add_lines(lines, level=ReportLevel.NORMAL)</code>","text":"<p>Add multiple lines of text with the same level.</p> <p>.. deprecated:: (next version)     This method is deprecated. Functions should return RunReport instead of list[str],     and callers should use add_report() to merge them. This provides better support     for translation and structured reporting.</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_lines(self, lines: Iterable[str], level: ReportLevel = ReportLevel.NORMAL) -&gt; None:\n    \"\"\"\n    Add multiple lines of text with the same level.\n\n    .. deprecated:: (next version)\n        This method is deprecated. Functions should return RunReport instead of list[str],\n        and callers should use add_report() to merge them. This provides better support\n        for translation and structured reporting.\n    \"\"\"\n    warnings.warn(\n        \"add_lines() is deprecated. Functions should return RunReport instead of list[str], \"\n        \"and use add_report() to merge them.\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    for line in lines:\n        self._data.append(RunLineLevel(line, level))\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_message","title":"<code>add_message(code, level=ReportLevel.NORMAL, **params)</code>","text":"<p>Add a translatable message using a message code and parameters.</p> <p>This is a convenience method that combines get_message() and add_line() in one call, making it simpler to add messages with translation support.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The message code from REPORT_MESSAGES (e.g., \"loading_features_from_file\")</p> required <code>level</code> <code>ReportLevel</code> <p>Importance level of the message</p> <code>NORMAL</code> <code>**params</code> <code>Any</code> <p>Parameters to substitute into the message template</p> <code>{}</code> Example <p>report.add_message(\"features_found\", count=5) report.add_message(\"trial_number\", ReportLevel.IMPORTANT, trial=3)</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_message(self, code: str, level: ReportLevel = ReportLevel.NORMAL, **params: Any) -&gt; None:\n    \"\"\"\n    Add a translatable message using a message code and parameters.\n\n    This is a convenience method that combines get_message() and add_line() in one call,\n    making it simpler to add messages with translation support.\n\n    Args:\n        code: The message code from REPORT_MESSAGES (e.g., \"loading_features_from_file\")\n        level: Importance level of the message\n        **params: Parameters to substitute into the message template\n\n    Example:\n        &gt;&gt;&gt; report.add_message(\"features_found\", count=5)\n        &gt;&gt;&gt; report.add_message(\"trial_number\", ReportLevel.IMPORTANT, trial=3)\n    \"\"\"\n    message = get_message(code, **params)\n    self.add_line(message, level=level, message_code=code, message_params=params)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.add_message_and_log","title":"<code>add_message_and_log(code, log_level, **params)</code>","text":"<p>Add a translatable message using a message code and parameters, and log it.</p> <p>This is a convenience method that combines get_message() and add_line_and_log() in one call, making it simpler to add messages with translation support that are also logged.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>str</code> <p>The message code from REPORT_MESSAGES (e.g., \"trial_number\")</p> required <code>log_level</code> <code>int</code> <p>Logging level for the message</p> required <code>**params</code> <code>Any</code> <p>Parameters to substitute into the message template</p> <code>{}</code> Example <p>report.add_message_and_log(\"trial_number\", logging.WARNING, trial=3) report.add_message_and_log(\"basic_solution_warning\", logging.WARNING, algorithm=\"maximin\", num_panels=150, num_agents=100, min_probs=0.001)</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def add_message_and_log(self, code: str, log_level: int, **params: Any) -&gt; None:\n    \"\"\"\n    Add a translatable message using a message code and parameters, and log it.\n\n    This is a convenience method that combines get_message() and add_line_and_log() in one call,\n    making it simpler to add messages with translation support that are also logged.\n\n    Args:\n        code: The message code from REPORT_MESSAGES (e.g., \"trial_number\")\n        log_level: Logging level for the message\n        **params: Parameters to substitute into the message template\n\n    Example:\n        &gt;&gt;&gt; report.add_message_and_log(\"trial_number\", logging.WARNING, trial=3)\n        &gt;&gt;&gt; report.add_message_and_log(\"basic_solution_warning\", logging.WARNING, algorithm=\"maximin\", num_panels=150, num_agents=100, min_probs=0.001)\n    \"\"\"\n    message = get_message(code, **params)\n    self.add_line_and_log(message, log_level, message_code=code, message_params=params)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.RunReport.has_content","title":"<code>has_content()</code>","text":"<pre><code>    False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report.has_content():\n        print(f\"Run Report\n</code></pre> <p>{run_report.as_text()}\")         ```</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def has_content(self) -&gt; bool:\n    \"\"\"\n    False is the report is empty, or True if there is some content. So you can do\n    things like\n\n    ```\n    if run_report.has_content():\n        print(f\"Run Report\\n\\n{run_report.as_text()}\")\n    ```\n    \"\"\"\n    return bool(self._data)\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.default_logging_setup","title":"<code>default_logging_setup()</code>","text":"<p>Set both logger and user_logger to send output to stdout</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def default_logging_setup() -&gt; tuple[logging.Logger, logging.Logger]:\n    \"\"\"Set both logger and user_logger to send output to stdout\"\"\"\n    # we have two loggers\n    # - user_logger is used for messages that any user should see\n    # - logger is used for messages that only a developer or admin should need to see\n    user_logger = logging.getLogger(\"sortition_algorithms_user\")\n    user_logger.setLevel(logging.INFO)\n    if not user_logger.handlers:\n        # no set up has been done yet - so we do it here\n        user_logger.addHandler(logging.StreamHandler(sys.stdout))\n    logger = logging.getLogger(\"sortition_algorithms\")\n    logger.setLevel(logging.INFO)\n    if not logger.handlers:\n        # no set up has been done yet - so we do it here\n        # this logger just goes straight to stdout - no timestamps or anything\n        logger.addHandler(logging.StreamHandler(sys.stdout))\n    return user_logger, logger\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.get_cell_name","title":"<code>get_cell_name(row, col_name, headers)</code>","text":"<p>Given the column_name, get the spreadsheet cell name, eg \"A5\"</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def get_cell_name(row: int, col_name: str, headers: Sequence[str]) -&gt; str:\n    \"\"\"Given the column_name, get the spreadsheet cell name, eg \"A5\" \"\"\"\n    col_index = headers.index(col_name)\n    if col_index &gt; 25:\n        col1 = [\"\", *string.ascii_uppercase][col_index // 26]\n        col2 = string.ascii_uppercase[col_index % 26]\n        col_name = f\"{col1}{col2}\"\n    else:\n        col_name = string.ascii_uppercase[col_index]\n    return f\"{col_name}{row}\"\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.normalise_dict","title":"<code>normalise_dict(original)</code>","text":"<p>Wraps a dict, and whenever we get a value from it, we convert to str and strip() whitespace</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def normalise_dict(original: Mapping[str, str] | Mapping[str, str | int]) -&gt; MutableMapping[str, str]:\n    \"\"\"\n    Wraps a dict, and whenever we get a value from it, we convert to str and\n    strip() whitespace\n    \"\"\"\n    new_dict: MutableMapping[str, str] = CaseInsensitiveDict()\n    for key, original_value in original.items():\n        new_dict[key] = strip_str_int(original_value)\n    return new_dict\n</code></pre>"},{"location":"modules/#sortition_algorithms.utils.override_logging_handlers","title":"<code>override_logging_handlers(user_logger_handlers, logger_handlers)</code>","text":"<p>Replace the default handlers with other ones</p> Source code in <code>src/sortition_algorithms/utils.py</code> <pre><code>def override_logging_handlers(\n    user_logger_handlers: list[logging.Handler], logger_handlers: list[logging.Handler]\n) -&gt; None:\n    \"\"\"Replace the default handlers with other ones\"\"\"\n    if user_logger_handlers:\n        _override_handlers_for(logging.getLogger(\"sortition_algorithms_user\"), user_logger_handlers)\n    if logger_handlers:\n        _override_handlers_for(logging.getLogger(\"sortition_algorithms\"), logger_handlers)\n</code></pre>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>This guide will get you up and running with sortition algorithms in just a few minutes.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install sortition-algorithms\n\n# Optional: Install CLI support\npip install 'sortition-algorithms[cli]'\n\n# Optional: Install leximin algorithm support (requires commercial/academic license)\npip install 'sortition-algorithms[gurobi]'\n</code></pre>"},{"location":"quickstart/#basic-concepts","title":"Basic Concepts","text":"<p>Before diving in, understand these key concepts:</p> <ul> <li>Sortition: Random selection that maintains demographic representativeness</li> <li>Features: Demographic characteristics (e.g., Gender, Age, Location)</li> <li>Quotas: Min/max targets for each demographic group</li> <li>Stratified Selection: Random selection that respects quotas</li> </ul>"},{"location":"quickstart/#your-first-selection","title":"Your First Selection","text":""},{"location":"quickstart/#1-prepare-your-data","title":"1. Prepare Your Data","text":"<p>You'll need two CSV files:</p> <p>demographics.csv (features with quotas):</p> <pre><code>feature,value,min,max\nGender,Male,45,55\nGender,Female,45,55\nAge,18-30,20,30\nAge,31-50,30,40\nAge,51+,30,50\n</code></pre> <p>candidates.csv (people to select from):</p> <pre><code>id,Gender,Age,Location\nperson1,Male,18-30,Urban\nperson2,Female,31-50,Rural\nperson3,Male,51+,Urban\n...\n</code></pre>"},{"location":"quickstart/#2-run-your-first-selection","title":"2. Run Your First Selection","text":"<pre><code>from sortition_algorithms import (\n    run_stratification,\n    read_in_features,\n    read_in_people,\n    Settings\n)\n\n# Load your data\nsettings = Settings()\nfeatures = read_in_features(\"demographics.csv\")\npeople = read_in_people(\"candidates.csv\", settings, features)\n\n# Select a panel of 50 people\nsuccess, selected_panels, report = run_stratification(\n    features=features,\n    people=people,\n    number_people_wanted=50,\n    settings=settings\n)\n\nif success:\n    selected_people = selected_panels[0]  # frozenset of person IDs\n    print(f\"\u2705 Successfully selected {len(selected_people)} people\")\n    print(\"Selected IDs:\", list(selected_people)[:5], \"...\")\nelse:\n    print(\"\u274c Selection failed\")\n    if report.last_error():\n        print(str(report.last_error()))\n\n# Display the detailed report\nprint(report.as_text())\n</code></pre>"},{"location":"quickstart/#3-export-results","title":"3. Export Results","text":"<pre><code>from sortition_algorithms import selected_remaining_tables\n\n# Get formatted tables for export\nselected_table, remaining_table, info = selected_remaining_tables(\n    people, selected_panels[0], features, settings\n)\n\n# Save to CSV\nimport csv\n\nwith open(\"selected.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(selected_table)\n\nwith open(\"remaining.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(remaining_table)\n</code></pre>"},{"location":"quickstart/#using-the-command-line","title":"Using the Command Line","text":"<p>For quick operations, use the CLI:</p> <pre><code># CSV workflow\npython -m sortition_algorithms csv \\\n  --settings settings.toml \\\n  --features-csv demographics.csv \\\n  --people-csv candidates.csv \\\n  --selected-csv selected.csv \\\n  --remaining-csv remaining.csv \\\n  --number-wanted 50\n</code></pre>"},{"location":"quickstart/#configuration-with-settings","title":"Configuration with Settings","text":"<p>Customize behavior with a settings file:</p> <p>settings.toml:</p> <pre><code>id_column = \"my_id\"\n\n# Random seed for reproducible results (optional)\n# Set to zero to be properly random\nrandom_number_seed = 0\n\n# Ensure household diversity\ncheck_same_address = true\ncheck_same_address_columns = [\"Address\", \"Postcode\"]\n\n# Selection algorithm: \"maximin\", \"leximin\", \"nash\", \"diversimax\" or \"legacy\"\nselection_algorithm = \"maximin\"\n\n# Maximum selection attempts\nmax_attempts = 10\n\n# Output columns to include\ncolumns_to_keep = [\"Name\", \"Email\", \"Phone\"]\n</code></pre> <pre><code>settings, report = Settings.load_from_file(\"settings.toml\")\n</code></pre>"},{"location":"quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"quickstart/#working-with-google-sheets","title":"Working with Google Sheets","text":"<pre><code>from sortition_algorithms import GSheetDataSource, SelectionData\nfrom pathlib import Path\n\ndata_source = GSheetDataSource(\n    feature_tab_name=\"Demographics\",\n    people_tab_name=\"Candidates\",\n    auth_json_path=Path(\"credentials.json\"),\n    gen_rem_tab=True,\n)\ndata_source.set_g_sheet_name(\"My Spreadsheet\")\nselect_data = SelectionData(data_source)\nfeatures, report = select_data.load_features()\npeople, report = select_data.load_people(settings, features)\n</code></pre>"},{"location":"quickstart/#address-checking-for-household-diversity","title":"Address Checking for Household Diversity","text":"<pre><code># Ensure only one person per household is selected\nsettings = Settings(\n    check_same_address=True,\n    check_same_address_columns=[\"Address\", \"Postcode\"]\n)\n</code></pre>"},{"location":"quickstart/#multiple-selection-algorithms","title":"Multiple Selection Algorithms","text":"<pre><code># Maximin: Maximize the minimum probability\nsettings.selection_algorithm = \"maximin\"\n\n# Nash: Maximize the product of probabilities\nsettings.selection_algorithm = \"nash\"\n\n# Leximin: Lexicographic maximin (requires Gurobi)\nsettings.selection_algorithm = \"leximin\"\n\n# Diversimax: Maximize diversity of unique profiles\nsettings.selection_algorithm = \"diversimax\"\n</code></pre> <p>Read more about the algorithms.</p>"},{"location":"quickstart/#working-with-reports-and-logging","title":"Working with Reports and Logging","text":"<p>Most library functions return a <code>RunReport</code> object containing detailed status information:</p> <pre><code># Reports contain formatted messages and tables\nfeatures, report = adapter.load_features_from_file(Path(\"features.csv\"))\nprint(\"Loading report:\")\nprint(report.as_text())\n\n# Get HTML for web display\nhtml_report = report.as_html()\n\n# Control whether to show messages that were already logged\nsummary = report.as_text(include_logged=False)\n\n# Extract the last error added to the report (or None if there was no error)\nerror = report.last_error()\n</code></pre>"},{"location":"quickstart/#custom-logging-integration","title":"Custom Logging Integration","text":"<p>Redirect log messages for integration with your application:</p> <pre><code>from sortition_algorithms.utils import override_logging_handlers\nimport logging\n\n# Send logs to a file\nfile_handler = logging.FileHandler('sortition.log')\nfile_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n\noverride_logging_handlers([file_handler], [file_handler])\n\n# Now all library operations will log to the file\nsuccess, panels, report = run_stratification(features, people, 50, settings)\n</code></pre> <p>See the API Reference for complete logging documentation.</p>"},{"location":"quickstart/#whats-next","title":"What's Next?","text":"<ul> <li>Core Concepts - Deep dive into sortition theory</li> <li>API Reference - Complete function documentation</li> <li>CLI Usage - Advanced command line examples</li> <li>Data Adapters - CSV, Google Sheets, and custom adapters</li> <li>Advanced Usage - Complex scenarios and troubleshooting</li> </ul>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>\"Selection failed\" errors: Check that your quotas are achievable given your candidate pool. The sum of minimum quotas shouldn't exceed your target panel size.</p> <p>Import errors: Ensure you've installed the package correctly. For Gurobi features, you need a valid license.</p> <p>Empty results: Verify your CSV files have the correct format and column names match between demographics and candidates files.</p>"}]}